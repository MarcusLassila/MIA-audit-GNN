This job can be monitored from: https://job.c3se.chalmers.se/alvis/4351588
/usr/share/lmod/lmod/init/bash: /usr/share/lmod/lmod/libexec/addto: /usr/bin/lua: bad interpreter: No such file or directory
no change     /opt/conda/condabin/conda
no change     /opt/conda/bin/conda
no change     /opt/conda/bin/conda-env
no change     /opt/conda/bin/activate
no change     /opt/conda/bin/deactivate
no change     /opt/conda/etc/profile.d/conda.sh
no change     /opt/conda/etc/fish/conf.d/conda.fish
no change     /opt/conda/shell/condabin/Conda.psm1
no change     /opt/conda/shell/condabin/conda-hook.ps1
no change     /opt/conda/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /opt/conda/etc/profile.d/conda.csh
no change     /cephyr/users/lassila/Alvis/.bashrc
No action taken.
Overwriting config seed with seed=62
Running MIA...

attacks:
  MLP-attack-0hop:
    attack: mlp-attack
    edge_dropout: 0.0
    mlp_attack_queries:
    - 0
    mlp_hidden_dim:
    - 128
    - 64
  MLP-attack-comb:
    attack: mlp-attack
    edge_dropout: 0.5
    mlp_attack_queries:
    - 0
    - 2
    mlp_hidden_dim:
    - 128
    - 64
  graph-lset-MIA:
    attack: graph-lset
    num_sampled_graphs: 16
    prior: 0.5
    sampling_strategy: MIA
  graph-lset-MIA-offline:
    attack: graph-lset
    num_sampled_graphs: 16
    offline: true
    prior: 0.5
    sampling_strategy: MIA
    threshold_scale_factor: 0.9
  lira:
    attack: lira
  lira-offline:
    attack: lira
    offline: true
  lset:
    attack: lset
  lset-offline:
    attack: lset
    offline: true
  rmia:
    Z_frac: 0.5
    attack: rmia
    rmia_gamma: 1
  rmia-offline:
    Z_frac: 0.5
    attack: rmia
    offline: true
    rmia_gamma: 1
batch_size: 524288
datadir: ./data
dataset: github
device: cuda
dropout: 0.0
early_stopping: 0
epochs: 300
epochs_mlp: 1000
frac_target_nodes: 0.2
hidden_dim:
- 64
hidden_dim_mlp:
- 128
hyperparam_search: false
inductive_inference: true
inductive_split: true
lr: 0.001
max_num_nodes: null
model: GraphSAGE
name: github-GraphSAGE
num_audits: 1
num_processes: 1
num_shadow_models: 128
offline: false
optimizer: Adam
pretrain_shadow_models: true
savedir: large_N_results
seed: 62
target_fpr:
- 0.01
- 0.001
train_frac: 0.5
val_frac: 0.0
weight_decay: 1.0e-05

Dataset properties
#Nodes: 37700
#Edges: 578006
#Features: 128
#Classes: 2
#Class distribution: [0.7417, 0.2583]
Average degree: 15.3317
Fraction isolated nodes: 0.0

Training 128 shadow models:   0%|          | 0/128 [00:00<?, ?it/s]Training 128 shadow models:   1%|          | 1/128 [00:02<05:52,  2.77s/it]Training 128 shadow models:   2%|▏         | 2/128 [00:04<04:43,  2.25s/it]Training 128 shadow models:   2%|▏         | 3/128 [00:06<04:20,  2.09s/it]Training 128 shadow models:   3%|▎         | 4/128 [00:08<04:08,  2.00s/it]Training 128 shadow models:   4%|▍         | 5/128 [00:10<04:01,  1.96s/it]Training 128 shadow models:   5%|▍         | 6/128 [00:12<03:56,  1.94s/it]Training 128 shadow models:   5%|▌         | 7/128 [00:14<03:52,  1.92s/it]Training 128 shadow models:   6%|▋         | 8/128 [00:15<03:49,  1.91s/it]Training 128 shadow models:   7%|▋         | 9/128 [00:17<03:46,  1.90s/it]Training 128 shadow models:   8%|▊         | 10/128 [00:19<03:43,  1.90s/it]Training 128 shadow models:   9%|▊         | 11/128 [00:21<03:41,  1.89s/it]Training 128 shadow models:   9%|▉         | 12/128 [00:23<03:38,  1.89s/it]Training 128 shadow models:  10%|█         | 13/128 [00:25<03:36,  1.89s/it]Training 128 shadow models:  11%|█         | 14/128 [00:27<03:34,  1.88s/it]Training 128 shadow models:  12%|█▏        | 15/128 [00:29<03:33,  1.89s/it]Training 128 shadow models:  12%|█▎        | 16/128 [00:31<03:32,  1.90s/it]Training 128 shadow models:  13%|█▎        | 17/128 [00:32<03:30,  1.89s/it]Training 128 shadow models:  14%|█▍        | 18/128 [00:34<03:27,  1.88s/it]Training 128 shadow models:  15%|█▍        | 19/128 [00:36<03:26,  1.89s/it]Training 128 shadow models:  16%|█▌        | 20/128 [00:38<03:24,  1.89s/it]Training 128 shadow models:  16%|█▋        | 21/128 [00:40<03:22,  1.89s/it]Training 128 shadow models:  17%|█▋        | 22/128 [00:42<03:20,  1.89s/it]Training 128 shadow models:  18%|█▊        | 23/128 [00:44<03:18,  1.89s/it]Training 128 shadow models:  19%|█▉        | 24/128 [00:46<03:16,  1.89s/it]Training 128 shadow models:  20%|█▉        | 25/128 [00:48<03:13,  1.88s/it]Training 128 shadow models:  20%|██        | 26/128 [00:49<03:11,  1.88s/it]Training 128 shadow models:  21%|██        | 27/128 [00:51<03:10,  1.88s/it]Training 128 shadow models:  22%|██▏       | 28/128 [00:53<03:13,  1.93s/it]Training 128 shadow models:  23%|██▎       | 29/128 [00:55<03:09,  1.92s/it]Training 128 shadow models:  23%|██▎       | 30/128 [00:57<03:06,  1.91s/it]Training 128 shadow models:  24%|██▍       | 31/128 [00:59<03:04,  1.90s/it]Training 128 shadow models:  25%|██▌       | 32/128 [01:01<03:01,  1.89s/it]Training 128 shadow models:  26%|██▌       | 33/128 [01:03<02:59,  1.89s/it]Training 128 shadow models:  27%|██▋       | 34/128 [01:05<02:57,  1.89s/it]Training 128 shadow models:  27%|██▋       | 35/128 [01:07<02:56,  1.89s/it]Training 128 shadow models:  28%|██▊       | 36/128 [01:08<02:53,  1.89s/it]Training 128 shadow models:  29%|██▉       | 37/128 [01:10<02:52,  1.89s/it]Training 128 shadow models:  30%|██▉       | 38/128 [01:12<02:49,  1.88s/it]Training 128 shadow models:  30%|███       | 39/128 [01:14<02:47,  1.88s/it]Training 128 shadow models:  31%|███▏      | 40/128 [01:16<02:45,  1.88s/it]Training 128 shadow models:  32%|███▏      | 41/128 [01:18<02:44,  1.89s/it]Training 128 shadow models:  33%|███▎      | 42/128 [01:20<02:42,  1.89s/it]Training 128 shadow models:  34%|███▎      | 43/128 [01:22<02:40,  1.89s/it]Training 128 shadow models:  34%|███▍      | 44/128 [01:24<02:38,  1.89s/it]Training 128 shadow models:  35%|███▌      | 45/128 [01:25<02:36,  1.88s/it]Training 128 shadow models:  36%|███▌      | 46/128 [01:27<02:34,  1.88s/it]Training 128 shadow models:  37%|███▋      | 47/128 [01:29<02:32,  1.89s/it]Training 128 shadow models:  38%|███▊      | 48/128 [01:31<02:31,  1.89s/it]Training 128 shadow models:  38%|███▊      | 49/128 [01:33<02:29,  1.89s/it]Training 128 shadow models:  39%|███▉      | 50/128 [01:35<02:27,  1.89s/it]Training 128 shadow models:  40%|███▉      | 51/128 [01:37<02:25,  1.89s/it]Training 128 shadow models:  41%|████      | 52/128 [01:39<02:23,  1.88s/it]Training 128 shadow models:  41%|████▏     | 53/128 [01:40<02:21,  1.88s/it]Training 128 shadow models:  42%|████▏     | 54/128 [01:42<02:19,  1.88s/it]Training 128 shadow models:  43%|████▎     | 55/128 [01:44<02:17,  1.89s/it]Training 128 shadow models:  44%|████▍     | 56/128 [01:46<02:15,  1.89s/it]Training 128 shadow models:  45%|████▍     | 57/128 [01:48<02:14,  1.89s/it]Training 128 shadow models:  45%|████▌     | 58/128 [01:50<02:12,  1.89s/it]Training 128 shadow models:  46%|████▌     | 59/128 [01:52<02:10,  1.88s/it]Training 128 shadow models:  47%|████▋     | 60/128 [01:54<02:08,  1.88s/it]Training 128 shadow models:  48%|████▊     | 61/128 [01:56<02:08,  1.91s/it]Training 128 shadow models:  48%|████▊     | 62/128 [01:58<02:05,  1.90s/it]Training 128 shadow models:  49%|████▉     | 63/128 [01:59<02:03,  1.90s/it]Training 128 shadow models:  50%|█████     | 64/128 [02:01<02:02,  1.92s/it]Training 128 shadow models:  51%|█████     | 65/128 [02:03<02:00,  1.91s/it]Training 128 shadow models:  52%|█████▏    | 66/128 [02:05<01:57,  1.90s/it]Training 128 shadow models:  52%|█████▏    | 67/128 [02:07<01:55,  1.90s/it]Training 128 shadow models:  53%|█████▎    | 68/128 [02:09<01:53,  1.89s/it]Training 128 shadow models:  54%|█████▍    | 69/128 [02:11<01:51,  1.89s/it]Training 128 shadow models:  55%|█████▍    | 70/128 [02:13<01:49,  1.89s/it]Training 128 shadow models:  55%|█████▌    | 71/128 [02:15<01:47,  1.89s/it]Training 128 shadow models:  56%|█████▋    | 72/128 [02:17<01:45,  1.89s/it]Training 128 shadow models:  57%|█████▋    | 73/128 [02:18<01:43,  1.89s/it]Training 128 shadow models:  58%|█████▊    | 74/128 [02:20<01:41,  1.88s/it]Training 128 shadow models:  59%|█████▊    | 75/128 [02:22<01:39,  1.89s/it]Training 128 shadow models:  59%|█████▉    | 76/128 [02:24<01:37,  1.88s/it]Training 128 shadow models:  60%|██████    | 77/128 [02:26<01:36,  1.89s/it]Training 128 shadow models:  61%|██████    | 78/128 [02:28<01:34,  1.88s/it]Training 128 shadow models:  62%|██████▏   | 79/128 [02:30<01:33,  1.91s/it]Training 128 shadow models:  62%|██████▎   | 80/128 [02:32<01:31,  1.91s/it]Training 128 shadow models:  63%|██████▎   | 81/128 [02:34<01:29,  1.90s/it]Training 128 shadow models:  64%|██████▍   | 82/128 [02:35<01:27,  1.89s/it]Training 128 shadow models:  65%|██████▍   | 83/128 [02:37<01:25,  1.89s/it]Training 128 shadow models:  66%|██████▌   | 84/128 [02:39<01:23,  1.89s/it]Training 128 shadow models:  66%|██████▋   | 85/128 [02:41<01:21,  1.89s/it]Training 128 shadow models:  67%|██████▋   | 86/128 [02:43<01:18,  1.88s/it]Training 128 shadow models:  68%|██████▊   | 87/128 [02:45<01:17,  1.88s/it]Training 128 shadow models:  69%|██████▉   | 88/128 [02:47<01:15,  1.88s/it]Training 128 shadow models:  70%|██████▉   | 89/128 [02:49<01:13,  1.88s/it]Training 128 shadow models:  70%|███████   | 90/128 [02:50<01:11,  1.88s/it]Training 128 shadow models:  71%|███████   | 91/128 [02:52<01:09,  1.89s/it]Training 128 shadow models:  72%|███████▏  | 92/128 [02:54<01:07,  1.88s/it]Training 128 shadow models:  73%|███████▎  | 93/128 [02:56<01:05,  1.88s/it]Training 128 shadow models:  73%|███████▎  | 94/128 [02:58<01:03,  1.88s/it]Training 128 shadow models:  74%|███████▍  | 95/128 [03:00<01:02,  1.88s/it]Training 128 shadow models:  75%|███████▌  | 96/128 [03:02<01:00,  1.88s/it]Training 128 shadow models:  76%|███████▌  | 97/128 [03:04<00:58,  1.88s/it]Training 128 shadow models:  77%|███████▋  | 98/128 [03:06<00:56,  1.88s/it]Training 128 shadow models:  77%|███████▋  | 99/128 [03:07<00:54,  1.88s/it]Training 128 shadow models:  78%|███████▊  | 100/128 [03:09<00:52,  1.88s/it]Training 128 shadow models:  79%|███████▉  | 101/128 [03:11<00:50,  1.88s/it]Training 128 shadow models:  80%|███████▉  | 102/128 [03:13<00:48,  1.88s/it]Training 128 shadow models:  80%|████████  | 103/128 [03:15<00:47,  1.88s/it]Training 128 shadow models:  81%|████████▏ | 104/128 [03:17<00:45,  1.88s/it]Training 128 shadow models:  82%|████████▏ | 105/128 [03:19<00:43,  1.88s/it]Training 128 shadow models:  83%|████████▎ | 106/128 [03:21<00:41,  1.88s/it]Training 128 shadow models:  84%|████████▎ | 107/128 [03:22<00:39,  1.88s/it]Training 128 shadow models:  84%|████████▍ | 108/128 [03:24<00:37,  1.88s/it]Training 128 shadow models:  85%|████████▌ | 109/128 [03:26<00:35,  1.88s/it]Training 128 shadow models:  86%|████████▌ | 110/128 [03:28<00:33,  1.88s/it]Training 128 shadow models:  87%|████████▋ | 111/128 [03:30<00:32,  1.89s/it]Training 128 shadow models:  88%|████████▊ | 112/128 [03:32<00:30,  1.88s/it]Training 128 shadow models:  88%|████████▊ | 113/128 [03:34<00:28,  1.88s/it]Training 128 shadow models:  89%|████████▉ | 114/128 [03:36<00:26,  1.88s/it]Training 128 shadow models:  90%|████████▉ | 115/128 [03:38<00:24,  1.88s/it]Training 128 shadow models:  91%|█████████ | 116/128 [03:39<00:22,  1.89s/it]Training 128 shadow models:  91%|█████████▏| 117/128 [03:41<00:20,  1.89s/it]Training 128 shadow models:  92%|█████████▏| 118/128 [03:43<00:18,  1.88s/it]Training 128 shadow models:  93%|█████████▎| 119/128 [03:45<00:16,  1.88s/it]Training 128 shadow models:  94%|█████████▍| 120/128 [03:47<00:15,  1.88s/it]Training 128 shadow models:  95%|█████████▍| 121/128 [03:49<00:13,  1.88s/it]Training 128 shadow models:  95%|█████████▌| 122/128 [03:51<00:11,  1.88s/it]Training 128 shadow models:  96%|█████████▌| 123/128 [03:53<00:09,  1.89s/it]Training 128 shadow models:  97%|█████████▋| 124/128 [03:55<00:07,  1.89s/it]Training 128 shadow models:  98%|█████████▊| 125/128 [03:56<00:05,  1.89s/it]Training 128 shadow models:  98%|█████████▊| 126/128 [03:58<00:03,  1.88s/it]Training 128 shadow models:  99%|█████████▉| 127/128 [04:00<00:01,  1.88s/it]Training 128 shadow models: 100%|██████████| 128/128 [04:02<00:00,  1.88s/it]Training 128 shadow models: 100%|██████████| 128/128 [04:02<00:00,  1.89s/it]
[I 2025-05-15 03:12:14,320] A new study created in memory with name: no-name-ce5cb3aa-68da-4dcf-b920-6739099b2d90
Tuning interpolation parameter for offline RMIA using optuna
  0%|          | 0/100 [00:00<?, ?it/s]                                         0%|          | 0/100 [00:07<?, ?it/s]Best trial: 0. Best value: 0.535965:   0%|          | 0/100 [00:07<?, ?it/s]Best trial: 0. Best value: 0.535965:   1%|          | 1/100 [00:07<12:18,  7.46s/it]                                                                                    Best trial: 0. Best value: 0.535965:   1%|          | 1/100 [00:14<12:18,  7.46s/it]Best trial: 0. Best value: 0.535965:   1%|          | 1/100 [00:14<12:18,  7.46s/it]Best trial: 0. Best value: 0.535965:   2%|▏         | 2/100 [00:14<12:08,  7.44s/it]                                                                                    Best trial: 0. Best value: 0.535965:   2%|▏         | 2/100 [00:22<12:08,  7.44s/it]Best trial: 2. Best value: 0.539338:   2%|▏         | 2/100 [00:22<12:08,  7.44s/it]Best trial: 2. Best value: 0.539338:   3%|▎         | 3/100 [00:22<12:01,  7.44s/it]                                                                                    Best trial: 2. Best value: 0.539338:   3%|▎         | 3/100 [00:29<12:01,  7.44s/it]Best trial: 2. Best value: 0.539338:   3%|▎         | 3/100 [00:29<12:01,  7.44s/it]Best trial: 2. Best value: 0.539338:   4%|▍         | 4/100 [00:29<11:53,  7.43s/it]                                                                                    Best trial: 2. Best value: 0.539338:   4%|▍         | 4/100 [00:37<11:53,  7.43s/it]Best trial: 2. Best value: 0.539338:   4%|▍         | 4/100 [00:37<11:53,  7.43s/it]Best trial: 2. Best value: 0.539338:   5%|▌         | 5/100 [00:37<11:50,  7.48s/it]                                                                                    Best trial: 2. Best value: 0.539338:   5%|▌         | 5/100 [00:44<11:50,  7.48s/it]Best trial: 2. Best value: 0.539338:   5%|▌         | 5/100 [00:44<11:50,  7.48s/it]Best trial: 2. Best value: 0.539338:   6%|▌         | 6/100 [00:44<11:41,  7.46s/it]                                                                                    Best trial: 2. Best value: 0.539338:   6%|▌         | 6/100 [00:52<11:41,  7.46s/it]Best trial: 2. Best value: 0.539338:   6%|▌         | 6/100 [00:52<11:41,  7.46s/it]Best trial: 2. Best value: 0.539338:   7%|▋         | 7/100 [00:52<11:32,  7.44s/it]                                                                                    Best trial: 2. Best value: 0.539338:   7%|▋         | 7/100 [00:59<11:32,  7.44s/it]Best trial: 2. Best value: 0.539338:   7%|▋         | 7/100 [00:59<11:32,  7.44s/it]Best trial: 2. Best value: 0.539338:   8%|▊         | 8/100 [00:59<11:23,  7.43s/it]                                                                                    Best trial: 2. Best value: 0.539338:   8%|▊         | 8/100 [01:06<11:23,  7.43s/it]Best trial: 2. Best value: 0.539338:   8%|▊         | 8/100 [01:06<11:23,  7.43s/it]Best trial: 2. Best value: 0.539338:   9%|▉         | 9/100 [01:06<11:15,  7.42s/it]                                                                                    Best trial: 2. Best value: 0.539338:   9%|▉         | 9/100 [01:14<11:15,  7.42s/it]Best trial: 2. Best value: 0.539338:   9%|▉         | 9/100 [01:14<11:15,  7.42s/it]Best trial: 2. Best value: 0.539338:  10%|█         | 10/100 [01:14<11:07,  7.42s/it]                                                                                     Best trial: 2. Best value: 0.539338:  10%|█         | 10/100 [01:21<11:07,  7.42s/it]Best trial: 10. Best value: 0.539878:  10%|█         | 10/100 [01:21<11:07,  7.42s/it]Best trial: 10. Best value: 0.539878:  11%|█         | 11/100 [01:21<11:00,  7.42s/it]                                                                                      Best trial: 10. Best value: 0.539878:  11%|█         | 11/100 [01:29<11:00,  7.42s/it]Best trial: 10. Best value: 0.539878:  11%|█         | 11/100 [01:29<11:00,  7.42s/it]Best trial: 10. Best value: 0.539878:  12%|█▏        | 12/100 [01:29<10:53,  7.42s/it]                                                                                      Best trial: 10. Best value: 0.539878:  12%|█▏        | 12/100 [01:36<10:53,  7.42s/it]Best trial: 10. Best value: 0.539878:  12%|█▏        | 12/100 [01:36<10:53,  7.42s/it]Best trial: 10. Best value: 0.539878:  13%|█▎        | 13/100 [01:36<10:46,  7.43s/it]                                                                                      Best trial: 10. Best value: 0.539878:  13%|█▎        | 13/100 [01:44<10:46,  7.43s/it]Best trial: 10. Best value: 0.539878:  13%|█▎        | 13/100 [01:44<10:46,  7.43s/it]Best trial: 10. Best value: 0.539878:  14%|█▍        | 14/100 [01:44<10:39,  7.43s/it]                                                                                      Best trial: 10. Best value: 0.539878:  14%|█▍        | 14/100 [01:51<10:39,  7.43s/it]Best trial: 10. Best value: 0.539878:  14%|█▍        | 14/100 [01:51<10:39,  7.43s/it]Best trial: 10. Best value: 0.539878:  15%|█▌        | 15/100 [01:51<10:31,  7.42s/it]                                                                                      Best trial: 10. Best value: 0.539878:  15%|█▌        | 15/100 [01:58<10:31,  7.42s/it]Best trial: 15. Best value: 0.539933:  15%|█▌        | 15/100 [01:58<10:31,  7.42s/it]Best trial: 15. Best value: 0.539933:  16%|█▌        | 16/100 [01:58<10:23,  7.42s/it]                                                                                      Best trial: 15. Best value: 0.539933:  16%|█▌        | 16/100 [02:06<10:23,  7.42s/it]Best trial: 15. Best value: 0.539933:  16%|█▌        | 16/100 [02:06<10:23,  7.42s/it]Best trial: 15. Best value: 0.539933:  17%|█▋        | 17/100 [02:06<10:16,  7.42s/it]                                                                                      Best trial: 15. Best value: 0.539933:  17%|█▋        | 17/100 [02:13<10:16,  7.42s/it]Best trial: 15. Best value: 0.539933:  17%|█▋        | 17/100 [02:13<10:16,  7.42s/it]Best trial: 15. Best value: 0.539933:  18%|█▊        | 18/100 [02:13<10:08,  7.42s/it]                                                                                      Best trial: 15. Best value: 0.539933:  18%|█▊        | 18/100 [02:21<10:08,  7.42s/it]Best trial: 15. Best value: 0.539933:  18%|█▊        | 18/100 [02:21<10:08,  7.42s/it]Best trial: 15. Best value: 0.539933:  19%|█▉        | 19/100 [02:21<10:05,  7.47s/it]                                                                                      Best trial: 15. Best value: 0.539933:  19%|█▉        | 19/100 [02:28<10:05,  7.47s/it]Best trial: 15. Best value: 0.539933:  19%|█▉        | 19/100 [02:28<10:05,  7.47s/it]Best trial: 15. Best value: 0.539933:  20%|██        | 20/100 [02:28<09:56,  7.45s/it]                                                                                      Best trial: 15. Best value: 0.539933:  20%|██        | 20/100 [02:36<09:56,  7.45s/it]Best trial: 15. Best value: 0.539933:  20%|██        | 20/100 [02:36<09:56,  7.45s/it]Best trial: 15. Best value: 0.539933:  21%|██        | 21/100 [02:36<09:48,  7.44s/it]                                                                                      Best trial: 15. Best value: 0.539933:  21%|██        | 21/100 [02:43<09:48,  7.44s/it]Best trial: 15. Best value: 0.539933:  21%|██        | 21/100 [02:43<09:48,  7.44s/it]Best trial: 15. Best value: 0.539933:  22%|██▏       | 22/100 [02:43<09:39,  7.43s/it]                                                                                      Best trial: 15. Best value: 0.539933:  22%|██▏       | 22/100 [02:50<09:39,  7.43s/it]Best trial: 15. Best value: 0.539933:  22%|██▏       | 22/100 [02:50<09:39,  7.43s/it]Best trial: 15. Best value: 0.539933:  23%|██▎       | 23/100 [02:50<09:31,  7.42s/it]                                                                                      Best trial: 15. Best value: 0.539933:  23%|██▎       | 23/100 [02:58<09:31,  7.42s/it]Best trial: 15. Best value: 0.539933:  23%|██▎       | 23/100 [02:58<09:31,  7.42s/it]Best trial: 15. Best value: 0.539933:  24%|██▍       | 24/100 [02:58<09:23,  7.42s/it]                                                                                      Best trial: 15. Best value: 0.539933:  24%|██▍       | 24/100 [03:05<09:23,  7.42s/it]Best trial: 15. Best value: 0.539933:  24%|██▍       | 24/100 [03:05<09:23,  7.42s/it]Best trial: 15. Best value: 0.539933:  25%|██▌       | 25/100 [03:05<09:15,  7.41s/it]                                                                                      Best trial: 15. Best value: 0.539933:  25%|██▌       | 25/100 [03:13<09:15,  7.41s/it]Best trial: 15. Best value: 0.539933:  25%|██▌       | 25/100 [03:13<09:15,  7.41s/it]Best trial: 15. Best value: 0.539933:  26%|██▌       | 26/100 [03:13<09:08,  7.41s/it]                                                                                      Best trial: 15. Best value: 0.539933:  26%|██▌       | 26/100 [03:20<09:08,  7.41s/it]Best trial: 26. Best value: 0.539958:  26%|██▌       | 26/100 [03:20<09:08,  7.41s/it]Best trial: 26. Best value: 0.539958:  27%|██▋       | 27/100 [03:20<09:00,  7.40s/it]                                                                                      Best trial: 26. Best value: 0.539958:  27%|██▋       | 27/100 [03:28<09:00,  7.40s/it]Best trial: 26. Best value: 0.539958:  27%|██▋       | 27/100 [03:28<09:00,  7.40s/it]Best trial: 26. Best value: 0.539958:  28%|██▊       | 28/100 [03:28<08:53,  7.41s/it]                                                                                      Best trial: 26. Best value: 0.539958:  28%|██▊       | 28/100 [03:35<08:53,  7.41s/it]Best trial: 26. Best value: 0.539958:  28%|██▊       | 28/100 [03:35<08:53,  7.41s/it]Best trial: 26. Best value: 0.539958:  29%|██▉       | 29/100 [03:35<08:46,  7.41s/it]                                                                                      Best trial: 26. Best value: 0.539958:  29%|██▉       | 29/100 [03:42<08:46,  7.41s/it]Best trial: 26. Best value: 0.539958:  29%|██▉       | 29/100 [03:42<08:46,  7.41s/it]Best trial: 26. Best value: 0.539958:  30%|███       | 30/100 [03:42<08:38,  7.41s/it]                                                                                      Best trial: 26. Best value: 0.539958:  30%|███       | 30/100 [03:50<08:38,  7.41s/it]Best trial: 26. Best value: 0.539958:  30%|███       | 30/100 [03:50<08:38,  7.41s/it]Best trial: 26. Best value: 0.539958:  31%|███       | 31/100 [03:50<08:31,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  31%|███       | 31/100 [03:57<08:31,  7.42s/it]Best trial: 26. Best value: 0.539958:  31%|███       | 31/100 [03:57<08:31,  7.42s/it]Best trial: 26. Best value: 0.539958:  32%|███▏      | 32/100 [03:57<08:24,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  32%|███▏      | 32/100 [04:05<08:24,  7.42s/it]Best trial: 26. Best value: 0.539958:  32%|███▏      | 32/100 [04:05<08:24,  7.42s/it]Best trial: 26. Best value: 0.539958:  33%|███▎      | 33/100 [04:05<08:16,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  33%|███▎      | 33/100 [04:12<08:16,  7.42s/it]Best trial: 26. Best value: 0.539958:  33%|███▎      | 33/100 [04:12<08:16,  7.42s/it]Best trial: 26. Best value: 0.539958:  34%|███▍      | 34/100 [04:12<08:12,  7.46s/it]                                                                                      Best trial: 26. Best value: 0.539958:  34%|███▍      | 34/100 [04:20<08:12,  7.46s/it]Best trial: 26. Best value: 0.539958:  34%|███▍      | 34/100 [04:20<08:12,  7.46s/it]Best trial: 26. Best value: 0.539958:  35%|███▌      | 35/100 [04:20<08:03,  7.44s/it]                                                                                      Best trial: 26. Best value: 0.539958:  35%|███▌      | 35/100 [04:27<08:03,  7.44s/it]Best trial: 26. Best value: 0.539958:  35%|███▌      | 35/100 [04:27<08:03,  7.44s/it]Best trial: 26. Best value: 0.539958:  36%|███▌      | 36/100 [04:27<07:55,  7.44s/it]                                                                                      Best trial: 26. Best value: 0.539958:  36%|███▌      | 36/100 [04:34<07:55,  7.44s/it]Best trial: 26. Best value: 0.539958:  36%|███▌      | 36/100 [04:34<07:55,  7.44s/it]Best trial: 26. Best value: 0.539958:  37%|███▋      | 37/100 [04:34<07:48,  7.43s/it]                                                                                      Best trial: 26. Best value: 0.539958:  37%|███▋      | 37/100 [04:42<07:48,  7.43s/it]Best trial: 26. Best value: 0.539958:  37%|███▋      | 37/100 [04:42<07:48,  7.43s/it]Best trial: 26. Best value: 0.539958:  38%|███▊      | 38/100 [04:42<07:40,  7.43s/it]                                                                                      Best trial: 26. Best value: 0.539958:  38%|███▊      | 38/100 [04:49<07:40,  7.43s/it]Best trial: 26. Best value: 0.539958:  38%|███▊      | 38/100 [04:49<07:40,  7.43s/it]Best trial: 26. Best value: 0.539958:  39%|███▉      | 39/100 [04:49<07:33,  7.43s/it]                                                                                      Best trial: 26. Best value: 0.539958:  39%|███▉      | 39/100 [04:57<07:33,  7.43s/it]Best trial: 26. Best value: 0.539958:  39%|███▉      | 39/100 [04:57<07:33,  7.43s/it]Best trial: 26. Best value: 0.539958:  40%|████      | 40/100 [04:57<07:25,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  40%|████      | 40/100 [05:04<07:25,  7.42s/it]Best trial: 26. Best value: 0.539958:  40%|████      | 40/100 [05:04<07:25,  7.42s/it]Best trial: 26. Best value: 0.539958:  41%|████      | 41/100 [05:04<07:17,  7.41s/it]                                                                                      Best trial: 26. Best value: 0.539958:  41%|████      | 41/100 [05:11<07:17,  7.41s/it]Best trial: 26. Best value: 0.539958:  41%|████      | 41/100 [05:11<07:17,  7.41s/it]Best trial: 26. Best value: 0.539958:  42%|████▏     | 42/100 [05:11<07:10,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  42%|████▏     | 42/100 [05:19<07:10,  7.42s/it]Best trial: 26. Best value: 0.539958:  42%|████▏     | 42/100 [05:19<07:10,  7.42s/it]Best trial: 26. Best value: 0.539958:  43%|████▎     | 43/100 [05:19<07:02,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  43%|████▎     | 43/100 [05:26<07:02,  7.42s/it]Best trial: 26. Best value: 0.539958:  43%|████▎     | 43/100 [05:26<07:02,  7.42s/it]Best trial: 26. Best value: 0.539958:  44%|████▍     | 44/100 [05:26<06:55,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  44%|████▍     | 44/100 [05:34<06:55,  7.42s/it]Best trial: 26. Best value: 0.539958:  44%|████▍     | 44/100 [05:34<06:55,  7.42s/it]Best trial: 26. Best value: 0.539958:  45%|████▌     | 45/100 [05:34<06:47,  7.41s/it]                                                                                      Best trial: 26. Best value: 0.539958:  45%|████▌     | 45/100 [05:41<06:47,  7.41s/it]Best trial: 26. Best value: 0.539958:  45%|████▌     | 45/100 [05:41<06:47,  7.41s/it]Best trial: 26. Best value: 0.539958:  46%|████▌     | 46/100 [05:41<06:40,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  46%|████▌     | 46/100 [05:49<06:40,  7.42s/it]Best trial: 26. Best value: 0.539958:  46%|████▌     | 46/100 [05:49<06:40,  7.42s/it]Best trial: 26. Best value: 0.539958:  47%|████▋     | 47/100 [05:49<06:33,  7.43s/it]                                                                                      Best trial: 26. Best value: 0.539958:  47%|████▋     | 47/100 [05:56<06:33,  7.43s/it]Best trial: 26. Best value: 0.539958:  47%|████▋     | 47/100 [05:56<06:33,  7.43s/it]Best trial: 26. Best value: 0.539958:  48%|████▊     | 48/100 [05:56<06:25,  7.42s/it]                                                                                      Best trial: 26. Best value: 0.539958:  48%|████▊     | 48/100 [06:04<06:25,  7.42s/it]Best trial: 48. Best value: 0.539967:  48%|████▊     | 48/100 [06:04<06:25,  7.42s/it]Best trial: 48. Best value: 0.539967:  49%|████▉     | 49/100 [06:04<06:21,  7.47s/it]                                                                                      Best trial: 48. Best value: 0.539967:  49%|████▉     | 49/100 [06:11<06:21,  7.47s/it]Best trial: 48. Best value: 0.539967:  49%|████▉     | 49/100 [06:11<06:21,  7.47s/it]Best trial: 48. Best value: 0.539967:  50%|█████     | 50/100 [06:11<06:12,  7.45s/it]                                                                                      Best trial: 48. Best value: 0.539967:  50%|█████     | 50/100 [06:18<06:12,  7.45s/it]Best trial: 48. Best value: 0.539967:  50%|█████     | 50/100 [06:18<06:12,  7.45s/it]Best trial: 48. Best value: 0.539967:  51%|█████     | 51/100 [06:18<06:04,  7.44s/it]                                                                                      Best trial: 48. Best value: 0.539967:  51%|█████     | 51/100 [06:26<06:04,  7.44s/it]Best trial: 48. Best value: 0.539967:  51%|█████     | 51/100 [06:26<06:04,  7.44s/it]Best trial: 48. Best value: 0.539967:  52%|█████▏    | 52/100 [06:26<05:57,  7.44s/it]                                                                                      Best trial: 48. Best value: 0.539967:  52%|█████▏    | 52/100 [06:33<05:57,  7.44s/it]Best trial: 48. Best value: 0.539967:  52%|█████▏    | 52/100 [06:33<05:57,  7.44s/it]Best trial: 48. Best value: 0.539967:  53%|█████▎    | 53/100 [06:33<05:49,  7.44s/it]                                                                                      Best trial: 48. Best value: 0.539967:  53%|█████▎    | 53/100 [06:41<05:49,  7.44s/it]Best trial: 53. Best value: 0.539973:  53%|█████▎    | 53/100 [06:41<05:49,  7.44s/it]Best trial: 53. Best value: 0.539973:  54%|█████▍    | 54/100 [06:41<05:41,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  54%|█████▍    | 54/100 [06:48<05:41,  7.43s/it]Best trial: 53. Best value: 0.539973:  54%|█████▍    | 54/100 [06:48<05:41,  7.43s/it]Best trial: 53. Best value: 0.539973:  55%|█████▌    | 55/100 [06:48<05:34,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  55%|█████▌    | 55/100 [06:56<05:34,  7.43s/it]Best trial: 53. Best value: 0.539973:  55%|█████▌    | 55/100 [06:56<05:34,  7.43s/it]Best trial: 53. Best value: 0.539973:  56%|█████▌    | 56/100 [06:56<05:26,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  56%|█████▌    | 56/100 [07:03<05:26,  7.43s/it]Best trial: 53. Best value: 0.539973:  56%|█████▌    | 56/100 [07:03<05:26,  7.43s/it]Best trial: 53. Best value: 0.539973:  57%|█████▋    | 57/100 [07:03<05:19,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  57%|█████▋    | 57/100 [07:10<05:19,  7.43s/it]Best trial: 53. Best value: 0.539973:  57%|█████▋    | 57/100 [07:10<05:19,  7.43s/it]Best trial: 53. Best value: 0.539973:  58%|█████▊    | 58/100 [07:10<05:12,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  58%|█████▊    | 58/100 [07:18<05:12,  7.43s/it]Best trial: 53. Best value: 0.539973:  58%|█████▊    | 58/100 [07:18<05:12,  7.43s/it]Best trial: 53. Best value: 0.539973:  59%|█████▉    | 59/100 [07:18<05:04,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  59%|█████▉    | 59/100 [07:25<05:04,  7.43s/it]Best trial: 53. Best value: 0.539973:  59%|█████▉    | 59/100 [07:25<05:04,  7.43s/it]Best trial: 53. Best value: 0.539973:  60%|██████    | 60/100 [07:25<04:57,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  60%|██████    | 60/100 [07:33<04:57,  7.43s/it]Best trial: 53. Best value: 0.539973:  60%|██████    | 60/100 [07:33<04:57,  7.43s/it]Best trial: 53. Best value: 0.539973:  61%|██████    | 61/100 [07:33<04:49,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  61%|██████    | 61/100 [07:40<04:49,  7.43s/it]Best trial: 53. Best value: 0.539973:  61%|██████    | 61/100 [07:40<04:49,  7.43s/it]Best trial: 53. Best value: 0.539973:  62%|██████▏   | 62/100 [07:40<04:42,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  62%|██████▏   | 62/100 [07:48<04:42,  7.43s/it]Best trial: 53. Best value: 0.539973:  62%|██████▏   | 62/100 [07:48<04:42,  7.43s/it]Best trial: 53. Best value: 0.539973:  63%|██████▎   | 63/100 [07:48<04:34,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  63%|██████▎   | 63/100 [07:55<04:34,  7.42s/it]Best trial: 53. Best value: 0.539973:  63%|██████▎   | 63/100 [07:55<04:34,  7.42s/it]Best trial: 53. Best value: 0.539973:  64%|██████▍   | 64/100 [07:55<04:28,  7.47s/it]                                                                                      Best trial: 53. Best value: 0.539973:  64%|██████▍   | 64/100 [08:03<04:28,  7.47s/it]Best trial: 53. Best value: 0.539973:  64%|██████▍   | 64/100 [08:03<04:28,  7.47s/it]Best trial: 53. Best value: 0.539973:  65%|██████▌   | 65/100 [08:03<04:21,  7.46s/it]                                                                                      Best trial: 53. Best value: 0.539973:  65%|██████▌   | 65/100 [08:10<04:21,  7.46s/it]Best trial: 53. Best value: 0.539973:  65%|██████▌   | 65/100 [08:10<04:21,  7.46s/it]Best trial: 53. Best value: 0.539973:  66%|██████▌   | 66/100 [08:10<04:12,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  66%|██████▌   | 66/100 [08:17<04:12,  7.43s/it]Best trial: 53. Best value: 0.539973:  66%|██████▌   | 66/100 [08:17<04:12,  7.43s/it]Best trial: 53. Best value: 0.539973:  67%|██████▋   | 67/100 [08:17<04:05,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  67%|██████▋   | 67/100 [08:25<04:05,  7.43s/it]Best trial: 53. Best value: 0.539973:  67%|██████▋   | 67/100 [08:25<04:05,  7.43s/it]Best trial: 53. Best value: 0.539973:  68%|██████▊   | 68/100 [08:25<03:57,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  68%|██████▊   | 68/100 [08:32<03:57,  7.42s/it]Best trial: 53. Best value: 0.539973:  68%|██████▊   | 68/100 [08:32<03:57,  7.42s/it]Best trial: 53. Best value: 0.539973:  69%|██████▉   | 69/100 [08:32<03:50,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  69%|██████▉   | 69/100 [08:40<03:50,  7.43s/it]Best trial: 53. Best value: 0.539973:  69%|██████▉   | 69/100 [08:40<03:50,  7.43s/it]Best trial: 53. Best value: 0.539973:  70%|███████   | 70/100 [08:40<03:42,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  70%|███████   | 70/100 [08:47<03:42,  7.42s/it]Best trial: 53. Best value: 0.539973:  70%|███████   | 70/100 [08:47<03:42,  7.42s/it]Best trial: 53. Best value: 0.539973:  71%|███████   | 71/100 [08:47<03:35,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  71%|███████   | 71/100 [08:54<03:35,  7.42s/it]Best trial: 53. Best value: 0.539973:  71%|███████   | 71/100 [08:54<03:35,  7.42s/it]Best trial: 53. Best value: 0.539973:  72%|███████▏  | 72/100 [08:54<03:27,  7.41s/it]                                                                                      Best trial: 53. Best value: 0.539973:  72%|███████▏  | 72/100 [09:02<03:27,  7.41s/it]Best trial: 53. Best value: 0.539973:  72%|███████▏  | 72/100 [09:02<03:27,  7.41s/it]Best trial: 53. Best value: 0.539973:  73%|███████▎  | 73/100 [09:02<03:20,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  73%|███████▎  | 73/100 [09:09<03:20,  7.42s/it]Best trial: 53. Best value: 0.539973:  73%|███████▎  | 73/100 [09:09<03:20,  7.42s/it]Best trial: 53. Best value: 0.539973:  74%|███████▍  | 74/100 [09:09<03:12,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  74%|███████▍  | 74/100 [09:17<03:12,  7.42s/it]Best trial: 53. Best value: 0.539973:  74%|███████▍  | 74/100 [09:17<03:12,  7.42s/it]Best trial: 53. Best value: 0.539973:  75%|███████▌  | 75/100 [09:17<03:05,  7.41s/it]                                                                                      Best trial: 53. Best value: 0.539973:  75%|███████▌  | 75/100 [09:24<03:05,  7.41s/it]Best trial: 53. Best value: 0.539973:  75%|███████▌  | 75/100 [09:24<03:05,  7.41s/it]Best trial: 53. Best value: 0.539973:  76%|███████▌  | 76/100 [09:24<02:57,  7.41s/it]                                                                                      Best trial: 53. Best value: 0.539973:  76%|███████▌  | 76/100 [09:31<02:57,  7.41s/it]Best trial: 53. Best value: 0.539973:  76%|███████▌  | 76/100 [09:31<02:57,  7.41s/it]Best trial: 53. Best value: 0.539973:  77%|███████▋  | 77/100 [09:31<02:50,  7.41s/it]                                                                                      Best trial: 53. Best value: 0.539973:  77%|███████▋  | 77/100 [09:39<02:50,  7.41s/it]Best trial: 53. Best value: 0.539973:  77%|███████▋  | 77/100 [09:39<02:50,  7.41s/it]Best trial: 53. Best value: 0.539973:  78%|███████▊  | 78/100 [09:39<02:44,  7.46s/it]                                                                                      Best trial: 53. Best value: 0.539973:  78%|███████▊  | 78/100 [09:46<02:44,  7.46s/it]Best trial: 53. Best value: 0.539973:  78%|███████▊  | 78/100 [09:46<02:44,  7.46s/it]Best trial: 53. Best value: 0.539973:  79%|███████▉  | 79/100 [09:46<02:36,  7.45s/it]                                                                                      Best trial: 53. Best value: 0.539973:  79%|███████▉  | 79/100 [09:54<02:36,  7.45s/it]Best trial: 53. Best value: 0.539973:  79%|███████▉  | 79/100 [09:54<02:36,  7.45s/it]Best trial: 53. Best value: 0.539973:  80%|████████  | 80/100 [09:54<02:28,  7.44s/it]                                                                                      Best trial: 53. Best value: 0.539973:  80%|████████  | 80/100 [10:01<02:28,  7.44s/it]Best trial: 53. Best value: 0.539973:  80%|████████  | 80/100 [10:01<02:28,  7.44s/it]Best trial: 53. Best value: 0.539973:  81%|████████  | 81/100 [10:01<02:21,  7.44s/it]                                                                                      Best trial: 53. Best value: 0.539973:  81%|████████  | 81/100 [10:09<02:21,  7.44s/it]Best trial: 53. Best value: 0.539973:  81%|████████  | 81/100 [10:09<02:21,  7.44s/it]Best trial: 53. Best value: 0.539973:  82%|████████▏ | 82/100 [10:09<02:13,  7.44s/it]                                                                                      Best trial: 53. Best value: 0.539973:  82%|████████▏ | 82/100 [10:16<02:13,  7.44s/it]Best trial: 53. Best value: 0.539973:  82%|████████▏ | 82/100 [10:16<02:13,  7.44s/it]Best trial: 53. Best value: 0.539973:  83%|████████▎ | 83/100 [10:16<02:06,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  83%|████████▎ | 83/100 [10:24<02:06,  7.43s/it]Best trial: 53. Best value: 0.539973:  83%|████████▎ | 83/100 [10:24<02:06,  7.43s/it]Best trial: 53. Best value: 0.539973:  84%|████████▍ | 84/100 [10:24<01:58,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  84%|████████▍ | 84/100 [10:31<01:58,  7.42s/it]Best trial: 53. Best value: 0.539973:  84%|████████▍ | 84/100 [10:31<01:58,  7.42s/it]Best trial: 53. Best value: 0.539973:  85%|████████▌ | 85/100 [10:31<01:51,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  85%|████████▌ | 85/100 [10:38<01:51,  7.42s/it]Best trial: 53. Best value: 0.539973:  85%|████████▌ | 85/100 [10:38<01:51,  7.42s/it]Best trial: 53. Best value: 0.539973:  86%|████████▌ | 86/100 [10:38<01:43,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  86%|████████▌ | 86/100 [10:46<01:43,  7.42s/it]Best trial: 53. Best value: 0.539973:  86%|████████▌ | 86/100 [10:46<01:43,  7.42s/it]Best trial: 53. Best value: 0.539973:  87%|████████▋ | 87/100 [10:46<01:36,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  87%|████████▋ | 87/100 [10:53<01:36,  7.42s/it]Best trial: 53. Best value: 0.539973:  87%|████████▋ | 87/100 [10:53<01:36,  7.42s/it]Best trial: 53. Best value: 0.539973:  88%|████████▊ | 88/100 [10:53<01:29,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  88%|████████▊ | 88/100 [11:01<01:29,  7.42s/it]Best trial: 53. Best value: 0.539973:  88%|████████▊ | 88/100 [11:01<01:29,  7.42s/it]Best trial: 53. Best value: 0.539973:  89%|████████▉ | 89/100 [11:01<01:21,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  89%|████████▉ | 89/100 [11:08<01:21,  7.43s/it]Best trial: 53. Best value: 0.539973:  89%|████████▉ | 89/100 [11:08<01:21,  7.43s/it]Best trial: 53. Best value: 0.539973:  90%|█████████ | 90/100 [11:08<01:14,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  90%|█████████ | 90/100 [11:16<01:14,  7.43s/it]Best trial: 53. Best value: 0.539973:  90%|█████████ | 90/100 [11:16<01:14,  7.43s/it]Best trial: 53. Best value: 0.539973:  91%|█████████ | 91/100 [11:16<01:06,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  91%|█████████ | 91/100 [11:23<01:06,  7.43s/it]Best trial: 53. Best value: 0.539973:  91%|█████████ | 91/100 [11:23<01:06,  7.43s/it]Best trial: 53. Best value: 0.539973:  92%|█████████▏| 92/100 [11:23<00:59,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  92%|█████████▏| 92/100 [11:31<00:59,  7.43s/it]Best trial: 53. Best value: 0.539973:  92%|█████████▏| 92/100 [11:31<00:59,  7.43s/it]Best trial: 53. Best value: 0.539973:  93%|█████████▎| 93/100 [11:31<00:52,  7.47s/it]                                                                                      Best trial: 53. Best value: 0.539973:  93%|█████████▎| 93/100 [11:38<00:52,  7.47s/it]Best trial: 53. Best value: 0.539973:  93%|█████████▎| 93/100 [11:38<00:52,  7.47s/it]Best trial: 53. Best value: 0.539973:  94%|█████████▍| 94/100 [11:38<00:44,  7.46s/it]                                                                                      Best trial: 53. Best value: 0.539973:  94%|█████████▍| 94/100 [11:45<00:44,  7.46s/it]Best trial: 53. Best value: 0.539973:  94%|█████████▍| 94/100 [11:45<00:44,  7.46s/it]Best trial: 53. Best value: 0.539973:  95%|█████████▌| 95/100 [11:45<00:37,  7.45s/it]                                                                                      Best trial: 53. Best value: 0.539973:  95%|█████████▌| 95/100 [11:53<00:37,  7.45s/it]Best trial: 53. Best value: 0.539973:  95%|█████████▌| 95/100 [11:53<00:37,  7.45s/it]Best trial: 53. Best value: 0.539973:  96%|█████████▌| 96/100 [11:53<00:29,  7.44s/it]                                                                                      Best trial: 53. Best value: 0.539973:  96%|█████████▌| 96/100 [12:00<00:29,  7.44s/it]Best trial: 53. Best value: 0.539973:  96%|█████████▌| 96/100 [12:00<00:29,  7.44s/it]Best trial: 53. Best value: 0.539973:  97%|█████████▋| 97/100 [12:00<00:22,  7.44s/it]                                                                                      Best trial: 53. Best value: 0.539973:  97%|█████████▋| 97/100 [12:08<00:22,  7.44s/it]Best trial: 53. Best value: 0.539973:  97%|█████████▋| 97/100 [12:08<00:22,  7.44s/it]Best trial: 53. Best value: 0.539973:  98%|█████████▊| 98/100 [12:08<00:14,  7.43s/it]                                                                                      Best trial: 53. Best value: 0.539973:  98%|█████████▊| 98/100 [12:15<00:14,  7.43s/it]Best trial: 53. Best value: 0.539973:  98%|█████████▊| 98/100 [12:15<00:14,  7.43s/it]Best trial: 53. Best value: 0.539973:  99%|█████████▉| 99/100 [12:15<00:07,  7.42s/it]                                                                                      Best trial: 53. Best value: 0.539973:  99%|█████████▉| 99/100 [12:23<00:07,  7.42s/it]Best trial: 53. Best value: 0.539973:  99%|█████████▉| 99/100 [12:23<00:07,  7.42s/it]Best trial: 53. Best value: 0.539973: 100%|██████████| 100/100 [12:23<00:00,  7.42s/it]Best trial: 53. Best value: 0.539973: 100%|██████████| 100/100 [12:23<00:00,  7.43s/it]
[I 2025-05-15 03:24:37,327] A new study created in memory with name: no-name-bf8eecb1-fb07-4b0b-9f92-b5fa3bfd7dd8
[I 2025-05-15 03:12:21,784] Trial 0 finished with value: 0.5359647700328575 and parameters: {'interp_param': 0.7731585687530032}. Best is trial 0 with value: 0.5359647700328575.
[I 2025-05-15 03:12:29,205] Trial 1 finished with value: 0.5347396801497231 and parameters: {'interp_param': 0.7176911181203249}. Best is trial 0 with value: 0.5359647700328575.
[I 2025-05-15 03:12:36,641] Trial 2 finished with value: 0.5393378733404162 and parameters: {'interp_param': 0.9558920809067486}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:12:44,062] Trial 3 finished with value: 0.5291161831856974 and parameters: {'interp_param': 0.3867916270308802}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:12:51,628] Trial 4 finished with value: 0.5321965890142054 and parameters: {'interp_param': 0.5738750838324816}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:12:59,050] Trial 5 finished with value: 0.525992104355902 and parameters: {'interp_param': 0.2044896334021744}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:13:06,457] Trial 6 finished with value: 0.5293557852373547 and parameters: {'interp_param': 0.4018865656148285}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:13:13,866] Trial 7 finished with value: 0.5379178886785948 and parameters: {'interp_param': 0.8709608125775461}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:13:21,275] Trial 8 finished with value: 0.5265601333999395 and parameters: {'interp_param': 0.2355842068648868}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:13:28,679] Trial 9 finished with value: 0.5357265244953529 and parameters: {'interp_param': 0.7625310519643244}. Best is trial 2 with value: 0.5393378733404162.
[I 2025-05-15 03:13:36,098] Trial 10 finished with value: 0.5398777898950953 and parameters: {'interp_param': 0.9908462235486316}. Best is trial 10 with value: 0.5398777898950953.
[I 2025-05-15 03:13:43,534] Trial 11 finished with value: 0.5395199600363051 and parameters: {'interp_param': 0.965175350149458}. Best is trial 10 with value: 0.5398777898950953.
[I 2025-05-15 03:13:50,971] Trial 12 finished with value: 0.5395855610044397 and parameters: {'interp_param': 0.9697063587164865}. Best is trial 10 with value: 0.5398777898950953.
[I 2025-05-15 03:13:58,412] Trial 13 finished with value: 0.5323867641368053 and parameters: {'interp_param': 0.5861768344224838}. Best is trial 10 with value: 0.5398777898950953.
[I 2025-05-15 03:14:05,821] Trial 14 finished with value: 0.5237309190946253 and parameters: {'interp_param': 0.04983920373053097}. Best is trial 10 with value: 0.5398777898950953.
[I 2025-05-15 03:14:13,243] Trial 15 finished with value: 0.5399332029353615 and parameters: {'interp_param': 0.9941108686350009}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:20,668] Trial 16 finished with value: 0.5373311020270317 and parameters: {'interp_param': 0.8429088845561025}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:28,090] Trial 17 finished with value: 0.5339854160656868 and parameters: {'interp_param': 0.6824216496584525}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:35,672] Trial 18 finished with value: 0.5376539087730161 and parameters: {'interp_param': 0.8591781707141556}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:43,075] Trial 19 finished with value: 0.5325499468792435 and parameters: {'interp_param': 0.596268005827196}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:50,501] Trial 20 finished with value: 0.5300898845415081 and parameters: {'interp_param': 0.443824735144569}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:14:57,914] Trial 21 finished with value: 0.5396561518057539 and parameters: {'interp_param': 0.9734056948562175}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:15:05,311] Trial 22 finished with value: 0.5397426380260186 and parameters: {'interp_param': 0.9826804793591498}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:15:12,726] Trial 23 finished with value: 0.538012260692751 and parameters: {'interp_param': 0.8746728350968842}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:15:20,116] Trial 24 finished with value: 0.5386694847638412 and parameters: {'interp_param': 0.9016861559684552}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:15:27,523] Trial 25 finished with value: 0.5364933884006783 and parameters: {'interp_param': 0.7986156554964637}. Best is trial 15 with value: 0.5399332029353615.
[I 2025-05-15 03:15:34,913] Trial 26 finished with value: 0.5399584870082813 and parameters: {'interp_param': 0.9981557603957796}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:15:42,327] Trial 27 finished with value: 0.5387536195990966 and parameters: {'interp_param': 0.9066711121972616}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:15:49,749] Trial 28 finished with value: 0.5338135932849735 and parameters: {'interp_param': 0.6732052308042776}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:15:57,166] Trial 29 finished with value: 0.5362399679164702 and parameters: {'interp_param': 0.7867878834113867}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:04,596] Trial 30 finished with value: 0.5355386529139021 and parameters: {'interp_param': 0.7532107547030326}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:12,016] Trial 31 finished with value: 0.5391818066685898 and parameters: {'interp_param': 0.9303504049043042}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:19,424] Trial 32 finished with value: 0.5398600679664248 and parameters: {'interp_param': 0.9899519770893301}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:26,999] Trial 33 finished with value: 0.537062115402205 and parameters: {'interp_param': 0.8282346113659806}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:34,388] Trial 34 finished with value: 0.5399552476975142 and parameters: {'interp_param': 0.995968367480796}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:41,815] Trial 35 finished with value: 0.5391701046232648 and parameters: {'interp_param': 0.9291803990020123}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:49,241] Trial 36 finished with value: 0.5399105981186105 and parameters: {'interp_param': 0.9928498427699446}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:16:56,656] Trial 37 finished with value: 0.538815449345313 and parameters: {'interp_param': 0.9103607298883621}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:04,080] Trial 38 finished with value: 0.5268097390398864 and parameters: {'interp_param': 0.24812955688334692}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:11,481] Trial 39 finished with value: 0.5312204335498033 and parameters: {'interp_param': 0.5141468151083721}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:18,886] Trial 40 finished with value: 0.5369908829302956 and parameters: {'interp_param': 0.823903533213285}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:26,306] Trial 41 finished with value: 0.5399474153761723 and parameters: {'interp_param': 0.9991428981954218}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:33,728] Trial 42 finished with value: 0.539945142792815 and parameters: {'interp_param': 0.9949019007886533}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:41,144] Trial 43 finished with value: 0.5391580437489887 and parameters: {'interp_param': 0.9278767607776054}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:48,553] Trial 44 finished with value: 0.5382926285276052 and parameters: {'interp_param': 0.8850247360728488}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:17:55,984] Trial 45 finished with value: 0.5348981741938662 and parameters: {'interp_param': 0.7247303968944951}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:18:03,428] Trial 46 finished with value: 0.5392458287893394 and parameters: {'interp_param': 0.9412113641026819}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:18:10,837] Trial 47 finished with value: 0.5280258694566204 and parameters: {'interp_param': 0.3182609093158616}. Best is trial 26 with value: 0.5399584870082813.
[I 2025-05-15 03:18:18,425] Trial 48 finished with value: 0.5399665740278198 and parameters: {'interp_param': 0.9963141786934431}. Best is trial 48 with value: 0.5399665740278198.
[I 2025-05-15 03:18:25,831] Trial 49 finished with value: 0.537737400530504 and parameters: {'interp_param': 0.8630980206650247}. Best is trial 48 with value: 0.5399665740278198.
[I 2025-05-15 03:18:33,245] Trial 50 finished with value: 0.523690033701778 and parameters: {'interp_param': 0.04569960199216749}. Best is trial 48 with value: 0.5399665740278198.
[I 2025-05-15 03:18:40,688] Trial 51 finished with value: 0.5399643900963209 and parameters: {'interp_param': 0.9976738183892867}. Best is trial 48 with value: 0.5399665740278198.
[I 2025-05-15 03:18:48,110] Trial 52 finished with value: 0.539248236461243 and parameters: {'interp_param': 0.9417696408668925}. Best is trial 48 with value: 0.5399665740278198.
[I 2025-05-15 03:18:55,543] Trial 53 finished with value: 0.5399731863307278 and parameters: {'interp_param': 0.9971635795184981}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:02,955] Trial 54 finished with value: 0.5393107458717081 and parameters: {'interp_param': 0.9529351850048634}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:10,395] Trial 55 finished with value: 0.524962725411422 and parameters: {'interp_param': 0.1457582855643227}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:17,837] Trial 56 finished with value: 0.5382851803643169 and parameters: {'interp_param': 0.8847104174234239}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:25,252] Trial 57 finished with value: 0.5393312863666105 and parameters: {'interp_param': 0.9553147777299229}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:32,681] Trial 58 finished with value: 0.5372265406778349 and parameters: {'interp_param': 0.8375575267938807}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:40,122] Trial 59 finished with value: 0.5399545061176818 and parameters: {'interp_param': 0.9986196942423584}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:47,539] Trial 60 finished with value: 0.5387020256246087 and parameters: {'interp_param': 0.9034141051156954}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:19:54,959] Trial 61 finished with value: 0.5394243581535084 and parameters: {'interp_param': 0.9602489512069003}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:02,373] Trial 62 finished with value: 0.5395214277170739 and parameters: {'interp_param': 0.9652628489389146}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:09,959] Trial 63 finished with value: 0.539940867803193 and parameters: {'interp_param': 0.9945812723508081}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:17,389] Trial 64 finished with value: 0.5399556796994279 and parameters: {'interp_param': 0.9985081832120586}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:24,768] Trial 65 finished with value: 0.5388425965144341 and parameters: {'interp_param': 0.9117748726792907}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:32,186] Trial 66 finished with value: 0.5379801476123803 and parameters: {'interp_param': 0.8733947572041827}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:39,586] Trial 67 finished with value: 0.5365835768914156 and parameters: {'interp_param': 0.8027238595271803}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:47,032] Trial 68 finished with value: 0.5393877519718002 and parameters: {'interp_param': 0.9586046089848784}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:20:54,432] Trial 69 finished with value: 0.539108860260749 and parameters: {'interp_param': 0.924374458531224}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:01,851] Trial 70 finished with value: 0.5329832307270157 and parameters: {'interp_param': 0.6242408566422032}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:09,255] Trial 71 finished with value: 0.5399409283116043 and parameters: {'interp_param': 0.9945830943441413}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:16,681] Trial 72 finished with value: 0.5396115430348486 and parameters: {'interp_param': 0.9711050682631228}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:24,097] Trial 73 finished with value: 0.5392505259306686 and parameters: {'interp_param': 0.9421765074250302}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:31,500] Trial 74 finished with value: 0.5375002188153015 and parameters: {'interp_param': 0.8517438588409446}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:38,899] Trial 75 finished with value: 0.5385059192705218 and parameters: {'interp_param': 0.8939078092993411}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:46,303] Trial 76 finished with value: 0.5396693285677097 and parameters: {'interp_param': 0.9743793142321557}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:21:53,874] Trial 77 finished with value: 0.5399709489266793 and parameters: {'interp_param': 0.9973263843226002}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:01,298] Trial 78 finished with value: 0.5390083037240816 and parameters: {'interp_param': 0.9195768979631608}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:08,731] Trial 79 finished with value: 0.5396154338664171 and parameters: {'interp_param': 0.9712868565716279}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:16,169] Trial 80 finished with value: 0.5399546862357436 and parameters: {'interp_param': 0.9985868222827278}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:23,593] Trial 81 finished with value: 0.5399537265441957 and parameters: {'interp_param': 0.9986676361835505}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:31,001] Trial 82 finished with value: 0.5392432958790958 and parameters: {'interp_param': 0.9407380157729313}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:38,414] Trial 83 finished with value: 0.5395785969084423 and parameters: {'interp_param': 0.9692445932424468}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:45,820] Trial 84 finished with value: 0.5388962083740827 and parameters: {'interp_param': 0.9146804942450638}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:22:53,234] Trial 85 finished with value: 0.530708529575245 and parameters: {'interp_param': 0.4813565310423099}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:00,659] Trial 86 finished with value: 0.539944796628415 and parameters: {'interp_param': 0.9995040315295275}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:08,074] Trial 87 finished with value: 0.5392408108127124 and parameters: {'interp_param': 0.9401216785788166}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:15,519] Trial 88 finished with value: 0.5383904467068649 and parameters: {'interp_param': 0.8890913815514287}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:22,948] Trial 89 finished with value: 0.5377139246740636 and parameters: {'interp_param': 0.8620027031754149}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:30,386] Trial 90 finished with value: 0.5287744330854365 and parameters: {'interp_param': 0.36600354278892333}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:37,811] Trial 91 finished with value: 0.5399475504647187 and parameters: {'interp_param': 0.9991350039253174}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:45,370] Trial 92 finished with value: 0.5396657262064743 and parameters: {'interp_param': 0.9740291080665126}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:23:52,798] Trial 93 finished with value: 0.5392879342006206 and parameters: {'interp_param': 0.9498968381974151}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:00,234] Trial 94 finished with value: 0.5397037522250913 and parameters: {'interp_param': 0.9795472457230575}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:07,655] Trial 95 finished with value: 0.5391392678482223 and parameters: {'interp_param': 0.9262029881628724}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:15,085] Trial 96 finished with value: 0.5399426084753991 and parameters: {'interp_param': 0.9998862742453668}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:22,496] Trial 97 finished with value: 0.5393213672086625 and parameters: {'interp_param': 0.9544064570467082}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:29,905] Trial 98 finished with value: 0.5396954710157673 and parameters: {'interp_param': 0.9781536586329742}. Best is trial 53 with value: 0.5399731863307278.
[I 2025-05-15 03:24:37,325] Trial 99 finished with value: 0.5384744675611592 and parameters: {'interp_param': 0.8924818993144525}. Best is trial 53 with value: 0.5399731863307278.
Best hyperparameters: {'interp_param': 0.9971635795184981}
Best optimized value: 0.5399731863307278
Tuning threshold scale factor for offline LSET using optuna
  0%|          | 0/100 [00:00<?, ?it/s]                                         0%|          | 0/100 [00:06<?, ?it/s]Best trial: 0. Best value: 0.53535:   0%|          | 0/100 [00:06<?, ?it/s]Best trial: 0. Best value: 0.53535:   1%|          | 1/100 [00:06<09:55,  6.02s/it]                                                                                   Best trial: 0. Best value: 0.53535:   1%|          | 1/100 [00:12<09:55,  6.02s/it]Best trial: 0. Best value: 0.53535:   1%|          | 1/100 [00:12<09:55,  6.02s/it]Best trial: 0. Best value: 0.53535:   2%|▏         | 2/100 [00:12<09:48,  6.01s/it]                                                                                   Best trial: 0. Best value: 0.53535:   2%|▏         | 2/100 [00:17<09:48,  6.01s/it]Best trial: 2. Best value: 0.53831:   2%|▏         | 2/100 [00:17<09:48,  6.01s/it]Best trial: 2. Best value: 0.53831:   3%|▎         | 3/100 [00:17<09:41,  5.99s/it]                                                                                   Best trial: 2. Best value: 0.53831:   3%|▎         | 3/100 [00:24<09:41,  5.99s/it]Best trial: 2. Best value: 0.53831:   3%|▎         | 3/100 [00:24<09:41,  5.99s/it]Best trial: 2. Best value: 0.53831:   4%|▍         | 4/100 [00:24<09:36,  6.01s/it]                                                                                   Best trial: 2. Best value: 0.53831:   4%|▍         | 4/100 [00:29<09:36,  6.01s/it]Best trial: 2. Best value: 0.53831:   4%|▍         | 4/100 [00:29<09:36,  6.01s/it]Best trial: 2. Best value: 0.53831:   5%|▌         | 5/100 [00:29<09:29,  5.99s/it]                                                                                   Best trial: 2. Best value: 0.53831:   5%|▌         | 5/100 [00:35<09:29,  5.99s/it]Best trial: 2. Best value: 0.53831:   5%|▌         | 5/100 [00:35<09:29,  5.99s/it]Best trial: 2. Best value: 0.53831:   6%|▌         | 6/100 [00:35<09:23,  6.00s/it]                                                                                   Best trial: 2. Best value: 0.53831:   6%|▌         | 6/100 [00:41<09:23,  6.00s/it]Best trial: 2. Best value: 0.53831:   6%|▌         | 6/100 [00:41<09:23,  6.00s/it]Best trial: 2. Best value: 0.53831:   7%|▋         | 7/100 [00:41<09:17,  5.99s/it]                                                                                   Best trial: 2. Best value: 0.53831:   7%|▋         | 7/100 [00:47<09:17,  5.99s/it]Best trial: 7. Best value: 0.538859:   7%|▋         | 7/100 [00:47<09:17,  5.99s/it]Best trial: 7. Best value: 0.538859:   8%|▊         | 8/100 [00:47<09:09,  5.98s/it]                                                                                    Best trial: 7. Best value: 0.538859:   8%|▊         | 8/100 [00:54<09:09,  5.98s/it]Best trial: 7. Best value: 0.538859:   8%|▊         | 8/100 [00:54<09:09,  5.98s/it]Best trial: 7. Best value: 0.538859:   9%|▉         | 9/100 [00:54<09:09,  6.04s/it]                                                                                    Best trial: 7. Best value: 0.538859:   9%|▉         | 9/100 [01:00<09:09,  6.04s/it]Best trial: 7. Best value: 0.538859:   9%|▉         | 9/100 [01:00<09:09,  6.04s/it]Best trial: 7. Best value: 0.538859:  10%|█         | 10/100 [01:00<09:02,  6.03s/it]                                                                                     Best trial: 7. Best value: 0.538859:  10%|█         | 10/100 [01:06<09:02,  6.03s/it]Best trial: 10. Best value: 0.539894:  10%|█         | 10/100 [01:06<09:02,  6.03s/it]Best trial: 10. Best value: 0.539894:  11%|█         | 11/100 [01:06<08:56,  6.03s/it]                                                                                      Best trial: 10. Best value: 0.539894:  11%|█         | 11/100 [01:12<08:56,  6.03s/it]Best trial: 11. Best value: 0.539897:  11%|█         | 11/100 [01:12<08:56,  6.03s/it]Best trial: 11. Best value: 0.539897:  12%|█▏        | 12/100 [01:12<08:50,  6.03s/it]                                                                                      Best trial: 11. Best value: 0.539897:  12%|█▏        | 12/100 [01:18<08:50,  6.03s/it]Best trial: 11. Best value: 0.539897:  12%|█▏        | 12/100 [01:18<08:50,  6.03s/it]Best trial: 11. Best value: 0.539897:  13%|█▎        | 13/100 [01:18<08:43,  6.02s/it]                                                                                      Best trial: 11. Best value: 0.539897:  13%|█▎        | 13/100 [01:24<08:43,  6.02s/it]Best trial: 13. Best value: 0.539905:  13%|█▎        | 13/100 [01:24<08:43,  6.02s/it]Best trial: 13. Best value: 0.539905:  14%|█▍        | 14/100 [01:24<08:37,  6.02s/it]                                                                                      Best trial: 13. Best value: 0.539905:  14%|█▍        | 14/100 [01:30<08:37,  6.02s/it]Best trial: 13. Best value: 0.539905:  14%|█▍        | 14/100 [01:30<08:37,  6.02s/it]Best trial: 13. Best value: 0.539905:  15%|█▌        | 15/100 [01:30<08:30,  6.01s/it]                                                                                      Best trial: 13. Best value: 0.539905:  15%|█▌        | 15/100 [01:36<08:30,  6.01s/it]Best trial: 13. Best value: 0.539905:  15%|█▌        | 15/100 [01:36<08:30,  6.01s/it]Best trial: 13. Best value: 0.539905:  16%|█▌        | 16/100 [01:36<08:24,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  16%|█▌        | 16/100 [01:42<08:24,  6.00s/it]Best trial: 13. Best value: 0.539905:  16%|█▌        | 16/100 [01:42<08:24,  6.00s/it]Best trial: 13. Best value: 0.539905:  17%|█▋        | 17/100 [01:42<08:17,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  17%|█▋        | 17/100 [01:48<08:17,  6.00s/it]Best trial: 13. Best value: 0.539905:  17%|█▋        | 17/100 [01:48<08:17,  6.00s/it]Best trial: 13. Best value: 0.539905:  18%|█▊        | 18/100 [01:48<08:11,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  18%|█▊        | 18/100 [01:54<08:11,  6.00s/it]Best trial: 13. Best value: 0.539905:  18%|█▊        | 18/100 [01:54<08:11,  6.00s/it]Best trial: 13. Best value: 0.539905:  19%|█▉        | 19/100 [01:54<08:05,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  19%|█▉        | 19/100 [02:00<08:05,  6.00s/it]Best trial: 13. Best value: 0.539905:  19%|█▉        | 19/100 [02:00<08:05,  6.00s/it]Best trial: 13. Best value: 0.539905:  20%|██        | 20/100 [02:00<07:59,  5.99s/it]                                                                                      Best trial: 13. Best value: 0.539905:  20%|██        | 20/100 [02:06<07:59,  5.99s/it]Best trial: 13. Best value: 0.539905:  20%|██        | 20/100 [02:06<07:59,  5.99s/it]Best trial: 13. Best value: 0.539905:  21%|██        | 21/100 [02:06<07:53,  5.99s/it]                                                                                      Best trial: 13. Best value: 0.539905:  21%|██        | 21/100 [02:12<07:53,  5.99s/it]Best trial: 13. Best value: 0.539905:  21%|██        | 21/100 [02:12<07:53,  5.99s/it]Best trial: 13. Best value: 0.539905:  22%|██▏       | 22/100 [02:12<07:47,  5.99s/it]                                                                                      Best trial: 13. Best value: 0.539905:  22%|██▏       | 22/100 [02:18<07:47,  5.99s/it]Best trial: 13. Best value: 0.539905:  22%|██▏       | 22/100 [02:18<07:47,  5.99s/it]Best trial: 13. Best value: 0.539905:  23%|██▎       | 23/100 [02:18<07:41,  5.99s/it]                                                                                      Best trial: 13. Best value: 0.539905:  23%|██▎       | 23/100 [02:24<07:41,  5.99s/it]Best trial: 13. Best value: 0.539905:  23%|██▎       | 23/100 [02:24<07:41,  5.99s/it]Best trial: 13. Best value: 0.539905:  24%|██▍       | 24/100 [02:24<07:35,  5.99s/it]                                                                                      Best trial: 13. Best value: 0.539905:  24%|██▍       | 24/100 [02:30<07:35,  5.99s/it]Best trial: 13. Best value: 0.539905:  24%|██▍       | 24/100 [02:30<07:35,  5.99s/it]Best trial: 13. Best value: 0.539905:  25%|██▌       | 25/100 [02:30<07:32,  6.04s/it]                                                                                      Best trial: 13. Best value: 0.539905:  25%|██▌       | 25/100 [02:36<07:32,  6.04s/it]Best trial: 13. Best value: 0.539905:  25%|██▌       | 25/100 [02:36<07:32,  6.04s/it]Best trial: 13. Best value: 0.539905:  26%|██▌       | 26/100 [02:36<07:25,  6.02s/it]                                                                                      Best trial: 13. Best value: 0.539905:  26%|██▌       | 26/100 [02:42<07:25,  6.02s/it]Best trial: 13. Best value: 0.539905:  26%|██▌       | 26/100 [02:42<07:25,  6.02s/it]Best trial: 13. Best value: 0.539905:  27%|██▋       | 27/100 [02:42<07:19,  6.01s/it]                                                                                      Best trial: 13. Best value: 0.539905:  27%|██▋       | 27/100 [02:48<07:19,  6.01s/it]Best trial: 13. Best value: 0.539905:  27%|██▋       | 27/100 [02:48<07:19,  6.01s/it]Best trial: 13. Best value: 0.539905:  28%|██▊       | 28/100 [02:48<07:12,  6.01s/it]                                                                                      Best trial: 13. Best value: 0.539905:  28%|██▊       | 28/100 [02:54<07:12,  6.01s/it]Best trial: 13. Best value: 0.539905:  28%|██▊       | 28/100 [02:54<07:12,  6.01s/it]Best trial: 13. Best value: 0.539905:  29%|██▉       | 29/100 [02:54<07:06,  6.01s/it]                                                                                      Best trial: 13. Best value: 0.539905:  29%|██▉       | 29/100 [03:00<07:06,  6.01s/it]Best trial: 13. Best value: 0.539905:  29%|██▉       | 29/100 [03:00<07:06,  6.01s/it]Best trial: 13. Best value: 0.539905:  30%|███       | 30/100 [03:00<07:00,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  30%|███       | 30/100 [03:06<07:00,  6.00s/it]Best trial: 13. Best value: 0.539905:  30%|███       | 30/100 [03:06<07:00,  6.00s/it]Best trial: 13. Best value: 0.539905:  31%|███       | 31/100 [03:06<06:54,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  31%|███       | 31/100 [03:12<06:54,  6.00s/it]Best trial: 13. Best value: 0.539905:  31%|███       | 31/100 [03:12<06:54,  6.00s/it]Best trial: 13. Best value: 0.539905:  32%|███▏      | 32/100 [03:12<06:48,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  32%|███▏      | 32/100 [03:18<06:48,  6.00s/it]Best trial: 13. Best value: 0.539905:  32%|███▏      | 32/100 [03:18<06:48,  6.00s/it]Best trial: 13. Best value: 0.539905:  33%|███▎      | 33/100 [03:18<06:42,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  33%|███▎      | 33/100 [03:24<06:42,  6.00s/it]Best trial: 13. Best value: 0.539905:  33%|███▎      | 33/100 [03:24<06:42,  6.00s/it]Best trial: 13. Best value: 0.539905:  34%|███▍      | 34/100 [03:24<06:35,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  34%|███▍      | 34/100 [03:30<06:35,  6.00s/it]Best trial: 13. Best value: 0.539905:  34%|███▍      | 34/100 [03:30<06:35,  6.00s/it]Best trial: 13. Best value: 0.539905:  35%|███▌      | 35/100 [03:30<06:30,  6.00s/it]                                                                                      Best trial: 13. Best value: 0.539905:  35%|███▌      | 35/100 [03:36<06:30,  6.00s/it]Best trial: 35. Best value: 0.539942:  35%|███▌      | 35/100 [03:36<06:30,  6.00s/it]Best trial: 35. Best value: 0.539942:  36%|███▌      | 36/100 [03:36<06:23,  6.00s/it]                                                                                      Best trial: 35. Best value: 0.539942:  36%|███▌      | 36/100 [03:42<06:23,  6.00s/it]Best trial: 35. Best value: 0.539942:  36%|███▌      | 36/100 [03:42<06:23,  6.00s/it]Best trial: 35. Best value: 0.539942:  37%|███▋      | 37/100 [03:42<06:18,  6.00s/it]                                                                                      Best trial: 35. Best value: 0.539942:  37%|███▋      | 37/100 [03:48<06:18,  6.00s/it]Best trial: 35. Best value: 0.539942:  37%|███▋      | 37/100 [03:48<06:18,  6.00s/it]Best trial: 35. Best value: 0.539942:  38%|███▊      | 38/100 [03:48<06:12,  6.00s/it]                                                                                      Best trial: 35. Best value: 0.539942:  38%|███▊      | 38/100 [03:54<06:12,  6.00s/it]Best trial: 35. Best value: 0.539942:  38%|███▊      | 38/100 [03:54<06:12,  6.00s/it]Best trial: 35. Best value: 0.539942:  39%|███▉      | 39/100 [03:54<06:06,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  39%|███▉      | 39/100 [04:00<06:06,  6.01s/it]Best trial: 35. Best value: 0.539942:  39%|███▉      | 39/100 [04:00<06:06,  6.01s/it]Best trial: 35. Best value: 0.539942:  40%|████      | 40/100 [04:00<06:00,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  40%|████      | 40/100 [04:06<06:00,  6.01s/it]Best trial: 35. Best value: 0.539942:  40%|████      | 40/100 [04:06<06:00,  6.01s/it]Best trial: 35. Best value: 0.539942:  41%|████      | 41/100 [04:06<05:54,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  41%|████      | 41/100 [04:12<05:54,  6.01s/it]Best trial: 35. Best value: 0.539942:  41%|████      | 41/100 [04:12<05:54,  6.01s/it]Best trial: 35. Best value: 0.539942:  42%|████▏     | 42/100 [04:12<05:51,  6.06s/it]                                                                                      Best trial: 35. Best value: 0.539942:  42%|████▏     | 42/100 [04:18<05:51,  6.06s/it]Best trial: 35. Best value: 0.539942:  42%|████▏     | 42/100 [04:18<05:51,  6.06s/it]Best trial: 35. Best value: 0.539942:  43%|████▎     | 43/100 [04:18<05:44,  6.04s/it]                                                                                      Best trial: 35. Best value: 0.539942:  43%|████▎     | 43/100 [04:24<05:44,  6.04s/it]Best trial: 35. Best value: 0.539942:  43%|████▎     | 43/100 [04:24<05:44,  6.04s/it]Best trial: 35. Best value: 0.539942:  44%|████▍     | 44/100 [04:24<05:37,  6.03s/it]                                                                                      Best trial: 35. Best value: 0.539942:  44%|████▍     | 44/100 [04:30<05:37,  6.03s/it]Best trial: 35. Best value: 0.539942:  44%|████▍     | 44/100 [04:30<05:37,  6.03s/it]Best trial: 35. Best value: 0.539942:  45%|████▌     | 45/100 [04:30<05:31,  6.03s/it]                                                                                      Best trial: 35. Best value: 0.539942:  45%|████▌     | 45/100 [04:36<05:31,  6.03s/it]Best trial: 35. Best value: 0.539942:  45%|████▌     | 45/100 [04:36<05:31,  6.03s/it]Best trial: 35. Best value: 0.539942:  46%|████▌     | 46/100 [04:36<05:25,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  46%|████▌     | 46/100 [04:42<05:25,  6.02s/it]Best trial: 35. Best value: 0.539942:  46%|████▌     | 46/100 [04:42<05:25,  6.02s/it]Best trial: 35. Best value: 0.539942:  47%|████▋     | 47/100 [04:42<05:19,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  47%|████▋     | 47/100 [04:48<05:19,  6.02s/it]Best trial: 35. Best value: 0.539942:  47%|████▋     | 47/100 [04:48<05:19,  6.02s/it]Best trial: 35. Best value: 0.539942:  48%|████▊     | 48/100 [04:48<05:12,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  48%|████▊     | 48/100 [04:54<05:12,  6.02s/it]Best trial: 35. Best value: 0.539942:  48%|████▊     | 48/100 [04:54<05:12,  6.02s/it]Best trial: 35. Best value: 0.539942:  49%|████▉     | 49/100 [04:54<05:06,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  49%|████▉     | 49/100 [05:00<05:06,  6.02s/it]Best trial: 35. Best value: 0.539942:  49%|████▉     | 49/100 [05:00<05:06,  6.02s/it]Best trial: 35. Best value: 0.539942:  50%|█████     | 50/100 [05:00<05:00,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  50%|█████     | 50/100 [05:06<05:00,  6.02s/it]Best trial: 35. Best value: 0.539942:  50%|█████     | 50/100 [05:06<05:00,  6.02s/it]Best trial: 35. Best value: 0.539942:  51%|█████     | 51/100 [05:06<04:54,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  51%|█████     | 51/100 [05:12<04:54,  6.02s/it]Best trial: 35. Best value: 0.539942:  51%|█████     | 51/100 [05:12<04:54,  6.02s/it]Best trial: 35. Best value: 0.539942:  52%|█████▏    | 52/100 [05:12<04:48,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  52%|█████▏    | 52/100 [05:18<04:48,  6.01s/it]Best trial: 35. Best value: 0.539942:  52%|█████▏    | 52/100 [05:18<04:48,  6.01s/it]Best trial: 35. Best value: 0.539942:  53%|█████▎    | 53/100 [05:18<04:42,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  53%|█████▎    | 53/100 [05:24<04:42,  6.01s/it]Best trial: 35. Best value: 0.539942:  53%|█████▎    | 53/100 [05:24<04:42,  6.01s/it]Best trial: 35. Best value: 0.539942:  54%|█████▍    | 54/100 [05:24<04:36,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  54%|█████▍    | 54/100 [05:30<04:36,  6.01s/it]Best trial: 35. Best value: 0.539942:  54%|█████▍    | 54/100 [05:30<04:36,  6.01s/it]Best trial: 35. Best value: 0.539942:  55%|█████▌    | 55/100 [05:30<04:30,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  55%|█████▌    | 55/100 [05:36<04:30,  6.01s/it]Best trial: 35. Best value: 0.539942:  55%|█████▌    | 55/100 [05:36<04:30,  6.01s/it]Best trial: 35. Best value: 0.539942:  56%|█████▌    | 56/100 [05:36<04:24,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  56%|█████▌    | 56/100 [05:42<04:24,  6.01s/it]Best trial: 35. Best value: 0.539942:  56%|█████▌    | 56/100 [05:42<04:24,  6.01s/it]Best trial: 35. Best value: 0.539942:  57%|█████▋    | 57/100 [05:42<04:18,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  57%|█████▋    | 57/100 [05:48<04:18,  6.01s/it]Best trial: 35. Best value: 0.539942:  57%|█████▋    | 57/100 [05:48<04:18,  6.01s/it]Best trial: 35. Best value: 0.539942:  58%|█████▊    | 58/100 [05:48<04:11,  5.98s/it]                                                                                      Best trial: 35. Best value: 0.539942:  58%|█████▊    | 58/100 [05:54<04:11,  5.98s/it]Best trial: 35. Best value: 0.539942:  58%|█████▊    | 58/100 [05:54<04:11,  5.98s/it]Best trial: 35. Best value: 0.539942:  59%|█████▉    | 59/100 [05:54<04:07,  6.04s/it]                                                                                      Best trial: 35. Best value: 0.539942:  59%|█████▉    | 59/100 [06:00<04:07,  6.04s/it]Best trial: 35. Best value: 0.539942:  59%|█████▉    | 59/100 [06:00<04:07,  6.04s/it]Best trial: 35. Best value: 0.539942:  60%|██████    | 60/100 [06:00<04:01,  6.03s/it]                                                                                      Best trial: 35. Best value: 0.539942:  60%|██████    | 60/100 [06:06<04:01,  6.03s/it]Best trial: 35. Best value: 0.539942:  60%|██████    | 60/100 [06:06<04:01,  6.03s/it]Best trial: 35. Best value: 0.539942:  61%|██████    | 61/100 [06:06<03:54,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  61%|██████    | 61/100 [06:12<03:54,  6.02s/it]Best trial: 35. Best value: 0.539942:  61%|██████    | 61/100 [06:12<03:54,  6.02s/it]Best trial: 35. Best value: 0.539942:  62%|██████▏   | 62/100 [06:12<03:48,  6.02s/it]                                                                                      Best trial: 35. Best value: 0.539942:  62%|██████▏   | 62/100 [06:18<03:48,  6.02s/it]Best trial: 35. Best value: 0.539942:  62%|██████▏   | 62/100 [06:18<03:48,  6.02s/it]Best trial: 35. Best value: 0.539942:  63%|██████▎   | 63/100 [06:18<03:42,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  63%|██████▎   | 63/100 [06:24<03:42,  6.01s/it]Best trial: 35. Best value: 0.539942:  63%|██████▎   | 63/100 [06:24<03:42,  6.01s/it]Best trial: 35. Best value: 0.539942:  64%|██████▍   | 64/100 [06:24<03:36,  6.01s/it]                                                                                      Best trial: 35. Best value: 0.539942:  64%|██████▍   | 64/100 [06:30<03:36,  6.01s/it]Best trial: 64. Best value: 0.539942:  64%|██████▍   | 64/100 [06:30<03:36,  6.01s/it]Best trial: 64. Best value: 0.539942:  65%|██████▌   | 65/100 [06:30<03:30,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  65%|██████▌   | 65/100 [06:36<03:30,  6.01s/it]Best trial: 64. Best value: 0.539942:  65%|██████▌   | 65/100 [06:36<03:30,  6.01s/it]Best trial: 64. Best value: 0.539942:  66%|██████▌   | 66/100 [06:36<03:24,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  66%|██████▌   | 66/100 [06:42<03:24,  6.01s/it]Best trial: 64. Best value: 0.539942:  66%|██████▌   | 66/100 [06:42<03:24,  6.01s/it]Best trial: 64. Best value: 0.539942:  67%|██████▋   | 67/100 [06:42<03:18,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  67%|██████▋   | 67/100 [06:48<03:18,  6.01s/it]Best trial: 64. Best value: 0.539942:  67%|██████▋   | 67/100 [06:48<03:18,  6.01s/it]Best trial: 64. Best value: 0.539942:  68%|██████▊   | 68/100 [06:48<03:12,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  68%|██████▊   | 68/100 [06:54<03:12,  6.01s/it]Best trial: 64. Best value: 0.539942:  68%|██████▊   | 68/100 [06:54<03:12,  6.01s/it]Best trial: 64. Best value: 0.539942:  69%|██████▉   | 69/100 [06:54<03:06,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  69%|██████▉   | 69/100 [07:00<03:06,  6.01s/it]Best trial: 64. Best value: 0.539942:  69%|██████▉   | 69/100 [07:00<03:06,  6.01s/it]Best trial: 64. Best value: 0.539942:  70%|███████   | 70/100 [07:00<03:00,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  70%|███████   | 70/100 [07:06<03:00,  6.01s/it]Best trial: 64. Best value: 0.539942:  70%|███████   | 70/100 [07:06<03:00,  6.01s/it]Best trial: 64. Best value: 0.539942:  71%|███████   | 71/100 [07:06<02:54,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  71%|███████   | 71/100 [07:12<02:54,  6.01s/it]Best trial: 64. Best value: 0.539942:  71%|███████   | 71/100 [07:12<02:54,  6.01s/it]Best trial: 64. Best value: 0.539942:  72%|███████▏  | 72/100 [07:12<02:48,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  72%|███████▏  | 72/100 [07:18<02:48,  6.01s/it]Best trial: 64. Best value: 0.539942:  72%|███████▏  | 72/100 [07:18<02:48,  6.01s/it]Best trial: 64. Best value: 0.539942:  73%|███████▎  | 73/100 [07:18<02:42,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  73%|███████▎  | 73/100 [07:24<02:42,  6.01s/it]Best trial: 64. Best value: 0.539942:  73%|███████▎  | 73/100 [07:24<02:42,  6.01s/it]Best trial: 64. Best value: 0.539942:  74%|███████▍  | 74/100 [07:24<02:36,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  74%|███████▍  | 74/100 [07:30<02:36,  6.01s/it]Best trial: 64. Best value: 0.539942:  74%|███████▍  | 74/100 [07:30<02:36,  6.01s/it]Best trial: 64. Best value: 0.539942:  75%|███████▌  | 75/100 [07:30<02:31,  6.05s/it]                                                                                      Best trial: 64. Best value: 0.539942:  75%|███████▌  | 75/100 [07:36<02:31,  6.05s/it]Best trial: 64. Best value: 0.539942:  75%|███████▌  | 75/100 [07:36<02:31,  6.05s/it]Best trial: 64. Best value: 0.539942:  76%|███████▌  | 76/100 [07:36<02:24,  6.04s/it]                                                                                      Best trial: 64. Best value: 0.539942:  76%|███████▌  | 76/100 [07:42<02:24,  6.04s/it]Best trial: 64. Best value: 0.539942:  76%|███████▌  | 76/100 [07:42<02:24,  6.04s/it]Best trial: 64. Best value: 0.539942:  77%|███████▋  | 77/100 [07:42<02:18,  6.03s/it]                                                                                      Best trial: 64. Best value: 0.539942:  77%|███████▋  | 77/100 [07:48<02:18,  6.03s/it]Best trial: 64. Best value: 0.539942:  77%|███████▋  | 77/100 [07:48<02:18,  6.03s/it]Best trial: 64. Best value: 0.539942:  78%|███████▊  | 78/100 [07:48<02:12,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  78%|███████▊  | 78/100 [07:54<02:12,  6.02s/it]Best trial: 64. Best value: 0.539942:  78%|███████▊  | 78/100 [07:54<02:12,  6.02s/it]Best trial: 64. Best value: 0.539942:  79%|███████▉  | 79/100 [07:54<02:06,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  79%|███████▉  | 79/100 [08:00<02:06,  6.01s/it]Best trial: 64. Best value: 0.539942:  79%|███████▉  | 79/100 [08:00<02:06,  6.01s/it]Best trial: 64. Best value: 0.539942:  80%|████████  | 80/100 [08:00<02:00,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  80%|████████  | 80/100 [08:06<02:00,  6.02s/it]Best trial: 64. Best value: 0.539942:  80%|████████  | 80/100 [08:06<02:00,  6.02s/it]Best trial: 64. Best value: 0.539942:  81%|████████  | 81/100 [08:06<01:54,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  81%|████████  | 81/100 [08:13<01:54,  6.01s/it]Best trial: 64. Best value: 0.539942:  81%|████████  | 81/100 [08:13<01:54,  6.01s/it]Best trial: 64. Best value: 0.539942:  82%|████████▏ | 82/100 [08:13<01:48,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  82%|████████▏ | 82/100 [08:18<01:48,  6.02s/it]Best trial: 64. Best value: 0.539942:  82%|████████▏ | 82/100 [08:18<01:48,  6.02s/it]Best trial: 64. Best value: 0.539942:  83%|████████▎ | 83/100 [08:18<01:42,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  83%|████████▎ | 83/100 [08:25<01:42,  6.01s/it]Best trial: 64. Best value: 0.539942:  83%|████████▎ | 83/100 [08:25<01:42,  6.01s/it]Best trial: 64. Best value: 0.539942:  84%|████████▍ | 84/100 [08:25<01:36,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  84%|████████▍ | 84/100 [08:31<01:36,  6.02s/it]Best trial: 64. Best value: 0.539942:  84%|████████▍ | 84/100 [08:31<01:36,  6.02s/it]Best trial: 64. Best value: 0.539942:  85%|████████▌ | 85/100 [08:31<01:30,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  85%|████████▌ | 85/100 [08:37<01:30,  6.01s/it]Best trial: 64. Best value: 0.539942:  85%|████████▌ | 85/100 [08:37<01:30,  6.01s/it]Best trial: 64. Best value: 0.539942:  86%|████████▌ | 86/100 [08:37<01:24,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  86%|████████▌ | 86/100 [08:43<01:24,  6.02s/it]Best trial: 64. Best value: 0.539942:  86%|████████▌ | 86/100 [08:43<01:24,  6.02s/it]Best trial: 64. Best value: 0.539942:  87%|████████▋ | 87/100 [08:43<01:18,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  87%|████████▋ | 87/100 [08:49<01:18,  6.00s/it]Best trial: 64. Best value: 0.539942:  87%|████████▋ | 87/100 [08:49<01:18,  6.00s/it]Best trial: 64. Best value: 0.539942:  88%|████████▊ | 88/100 [08:49<01:12,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  88%|████████▊ | 88/100 [08:55<01:12,  6.00s/it]Best trial: 64. Best value: 0.539942:  88%|████████▊ | 88/100 [08:55<01:12,  6.00s/it]Best trial: 64. Best value: 0.539942:  89%|████████▉ | 89/100 [08:55<01:06,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  89%|████████▉ | 89/100 [09:01<01:06,  6.00s/it]Best trial: 64. Best value: 0.539942:  89%|████████▉ | 89/100 [09:01<01:06,  6.00s/it]Best trial: 64. Best value: 0.539942:  90%|█████████ | 90/100 [09:01<01:00,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  90%|█████████ | 90/100 [09:07<01:00,  6.00s/it]Best trial: 64. Best value: 0.539942:  90%|█████████ | 90/100 [09:07<01:00,  6.00s/it]Best trial: 64. Best value: 0.539942:  91%|█████████ | 91/100 [09:07<00:53,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  91%|█████████ | 91/100 [09:13<00:53,  6.00s/it]Best trial: 64. Best value: 0.539942:  91%|█████████ | 91/100 [09:13<00:53,  6.00s/it]Best trial: 64. Best value: 0.539942:  92%|█████████▏| 92/100 [09:13<00:48,  6.06s/it]                                                                                      Best trial: 64. Best value: 0.539942:  92%|█████████▏| 92/100 [09:19<00:48,  6.06s/it]Best trial: 64. Best value: 0.539942:  92%|█████████▏| 92/100 [09:19<00:48,  6.06s/it]Best trial: 64. Best value: 0.539942:  93%|█████████▎| 93/100 [09:19<00:42,  6.04s/it]                                                                                      Best trial: 64. Best value: 0.539942:  93%|█████████▎| 93/100 [09:25<00:42,  6.04s/it]Best trial: 64. Best value: 0.539942:  93%|█████████▎| 93/100 [09:25<00:42,  6.04s/it]Best trial: 64. Best value: 0.539942:  94%|█████████▍| 94/100 [09:25<00:36,  6.03s/it]                                                                                      Best trial: 64. Best value: 0.539942:  94%|█████████▍| 94/100 [09:31<00:36,  6.03s/it]Best trial: 64. Best value: 0.539942:  94%|█████████▍| 94/100 [09:31<00:36,  6.03s/it]Best trial: 64. Best value: 0.539942:  95%|█████████▌| 95/100 [09:31<00:30,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  95%|█████████▌| 95/100 [09:37<00:30,  6.02s/it]Best trial: 64. Best value: 0.539942:  95%|█████████▌| 95/100 [09:37<00:30,  6.02s/it]Best trial: 64. Best value: 0.539942:  96%|█████████▌| 96/100 [09:37<00:24,  6.02s/it]                                                                                      Best trial: 64. Best value: 0.539942:  96%|█████████▌| 96/100 [09:43<00:24,  6.02s/it]Best trial: 64. Best value: 0.539942:  96%|█████████▌| 96/100 [09:43<00:24,  6.02s/it]Best trial: 64. Best value: 0.539942:  97%|█████████▋| 97/100 [09:43<00:18,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  97%|█████████▋| 97/100 [09:49<00:18,  6.01s/it]Best trial: 64. Best value: 0.539942:  97%|█████████▋| 97/100 [09:49<00:18,  6.01s/it]Best trial: 64. Best value: 0.539942:  98%|█████████▊| 98/100 [09:49<00:12,  6.01s/it]                                                                                      Best trial: 64. Best value: 0.539942:  98%|█████████▊| 98/100 [09:55<00:12,  6.01s/it]Best trial: 64. Best value: 0.539942:  98%|█████████▊| 98/100 [09:55<00:12,  6.01s/it]Best trial: 64. Best value: 0.539942:  99%|█████████▉| 99/100 [09:55<00:05,  6.00s/it]                                                                                      Best trial: 64. Best value: 0.539942:  99%|█████████▉| 99/100 [10:01<00:05,  6.00s/it]Best trial: 99. Best value: 0.539942:  99%|█████████▉| 99/100 [10:01<00:05,  6.00s/it]Best trial: 99. Best value: 0.539942: 100%|██████████| 100/100 [10:01<00:00,  6.00s/it]Best trial: 99. Best value: 0.539942: 100%|██████████| 100/100 [10:01<00:00,  6.01s/it]
[I 2025-05-15 03:24:43,346] Trial 0 finished with value: 0.5353502353495768 and parameters: {'threshold_scale_factor': 0.6895315247810737}. Best is trial 0 with value: 0.5353502353495768.
[I 2025-05-15 03:24:49,342] Trial 1 finished with value: 0.5259382138761266 and parameters: {'threshold_scale_factor': 0.42650254987349023}. Best is trial 0 with value: 0.5353502353495768.
[I 2025-05-15 03:24:55,318] Trial 2 finished with value: 0.5383102350681424 and parameters: {'threshold_scale_factor': 0.8474337142675871}. Best is trial 2 with value: 0.5383102350681424.
[I 2025-05-15 03:25:01,343] Trial 3 finished with value: 0.5146828149075839 and parameters: {'threshold_scale_factor': 0.05897897231429472}. Best is trial 2 with value: 0.5383102350681424.
[I 2025-05-15 03:25:07,318] Trial 4 finished with value: 0.5362700194893372 and parameters: {'threshold_scale_factor': 0.7385642391252337}. Best is trial 2 with value: 0.5383102350681424.
[I 2025-05-15 03:25:13,325] Trial 5 finished with value: 0.5218112742649283 and parameters: {'threshold_scale_factor': 0.29800197407513207}. Best is trial 2 with value: 0.5383102350681424.
[I 2025-05-15 03:25:19,312] Trial 6 finished with value: 0.5241583111117365 and parameters: {'threshold_scale_factor': 0.3797210828684212}. Best is trial 2 with value: 0.5383102350681424.
[I 2025-05-15 03:25:25,245] Trial 7 finished with value: 0.5388589957010885 and parameters: {'threshold_scale_factor': 0.8791793721452607}. Best is trial 7 with value: 0.5388589957010885.
[I 2025-05-15 03:25:31,418] Trial 8 finished with value: 0.5337089714273653 and parameters: {'threshold_scale_factor': 0.6282630008853262}. Best is trial 7 with value: 0.5388589957010885.
[I 2025-05-15 03:25:37,440] Trial 9 finished with value: 0.5157055125977106 and parameters: {'threshold_scale_factor': 0.11043596293074687}. Best is trial 7 with value: 0.5388589957010885.
[I 2025-05-15 03:25:43,459] Trial 10 finished with value: 0.5398940497716862 and parameters: {'threshold_scale_factor': 0.9890337544567849}. Best is trial 10 with value: 0.5398940497716862.
[I 2025-05-15 03:25:49,481] Trial 11 finished with value: 0.5398966248971006 and parameters: {'threshold_scale_factor': 0.9898070806021264}. Best is trial 11 with value: 0.5398966248971006.
[I 2025-05-15 03:25:55,483] Trial 12 finished with value: 0.5398936923499076 and parameters: {'threshold_scale_factor': 0.9889036654006327}. Best is trial 11 with value: 0.5398966248971006.
[I 2025-05-15 03:26:01,496] Trial 13 finished with value: 0.5399046640727789 and parameters: {'threshold_scale_factor': 0.9918632806870328}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:07,482] Trial 14 finished with value: 0.5310855982945071 and parameters: {'threshold_scale_factor': 0.5612064025408752}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:13,475] Trial 15 finished with value: 0.5378345601531004 and parameters: {'threshold_scale_factor': 0.8213711789345599}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:19,461] Trial 16 finished with value: 0.5395194900407376 and parameters: {'threshold_scale_factor': 0.9224491503113404}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:25,465] Trial 17 finished with value: 0.5363429560469715 and parameters: {'threshold_scale_factor': 0.7419543649261368}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:31,450] Trial 18 finished with value: 0.5192791323375243 and parameters: {'threshold_scale_factor': 0.23062810894889785}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:37,436] Trial 19 finished with value: 0.5284579726867846 and parameters: {'threshold_scale_factor': 0.49323525972650045}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:43,435] Trial 20 finished with value: 0.5369778342210245 and parameters: {'threshold_scale_factor': 0.7721588674611689}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:49,429] Trial 21 finished with value: 0.5398821056927158 and parameters: {'threshold_scale_factor': 0.9839255691560869}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:26:55,424] Trial 22 finished with value: 0.5395018764643387 and parameters: {'threshold_scale_factor': 0.9205059837574104}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:01,397] Trial 23 finished with value: 0.5398744830400551 and parameters: {'threshold_scale_factor': 0.9806143967852486}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:07,548] Trial 24 finished with value: 0.5386346994631637 and parameters: {'threshold_scale_factor': 0.8676465087232773}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:13,535] Trial 25 finished with value: 0.5373813577806078 and parameters: {'threshold_scale_factor': 0.7924020509961444}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:19,533] Trial 26 finished with value: 0.533700031661378 and parameters: {'threshold_scale_factor': 0.6279617502846674}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:25,530] Trial 27 finished with value: 0.539527757178338 and parameters: {'threshold_scale_factor': 0.9233661153113574}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:31,531] Trial 28 finished with value: 0.5349470846906683 and parameters: {'threshold_scale_factor': 0.6727010584764184}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:37,522] Trial 29 finished with value: 0.5394952163175707 and parameters: {'threshold_scale_factor': 0.9197329842533484}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:43,525] Trial 30 finished with value: 0.5353513976739441 and parameters: {'threshold_scale_factor': 0.6895900209137931}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:49,533] Trial 31 finished with value: 0.5398810432775858 and parameters: {'threshold_scale_factor': 0.9831568598530067}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:27:55,528] Trial 32 finished with value: 0.5399014824560786 and parameters: {'threshold_scale_factor': 0.9909942681492002}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:28:01,519] Trial 33 finished with value: 0.5383140738343336 and parameters: {'threshold_scale_factor': 0.8477010332474029}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:28:07,539] Trial 34 finished with value: 0.5391645462924526 and parameters: {'threshold_scale_factor': 0.8973836750292248}. Best is trial 13 with value: 0.5399046640727789.
[I 2025-05-15 03:28:13,519] Trial 35 finished with value: 0.5399415151024773 and parameters: {'threshold_scale_factor': 0.9999288992137907}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:19,538] Trial 36 finished with value: 0.5377103546777927 and parameters: {'threshold_scale_factor': 0.814113812741754}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:25,539] Trial 37 finished with value: 0.5397300818270726 and parameters: {'threshold_scale_factor': 0.9464559456342906}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:31,563] Trial 38 finished with value: 0.538467428885027 and parameters: {'threshold_scale_factor': 0.8590606852149136}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:37,567] Trial 39 finished with value: 0.536856703417318 and parameters: {'threshold_scale_factor': 0.7657297930920981}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:43,584] Trial 40 finished with value: 0.5243339402936769 and parameters: {'threshold_scale_factor': 0.38635649873207034}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:49,749] Trial 41 finished with value: 0.5399301057490027 and parameters: {'threshold_scale_factor': 0.9977546224700107}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:28:55,755] Trial 42 finished with value: 0.5397704212370452 and parameters: {'threshold_scale_factor': 0.9508679410215751}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:01,760] Trial 43 finished with value: 0.5390377769491096 and parameters: {'threshold_scale_factor': 0.8899716443765073}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:07,779] Trial 44 finished with value: 0.5380809236679355 and parameters: {'threshold_scale_factor': 0.8351326574694663}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:13,788] Trial 45 finished with value: 0.5399211870906008 and parameters: {'threshold_scale_factor': 0.9952333879056016}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:19,804] Trial 46 finished with value: 0.5396153466217309 and parameters: {'threshold_scale_factor': 0.932045196423736}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:25,815] Trial 47 finished with value: 0.5133869414405223 and parameters: {'threshold_scale_factor': 0.0015214502287914655}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:31,832] Trial 48 finished with value: 0.539809812212849 and parameters: {'threshold_scale_factor': 0.9585488154571825}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:37,842] Trial 49 finished with value: 0.5399251370234084 and parameters: {'threshold_scale_factor': 0.9963377859401183}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:43,866] Trial 50 finished with value: 0.5389754392136721 and parameters: {'threshold_scale_factor': 0.8862371942216822}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:49,864] Trial 51 finished with value: 0.5399318295351405 and parameters: {'threshold_scale_factor': 0.997974591752093}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:29:55,881] Trial 52 finished with value: 0.5399265033877674 and parameters: {'threshold_scale_factor': 0.9966536100583904}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:01,894] Trial 53 finished with value: 0.5396627992879708 and parameters: {'threshold_scale_factor': 0.9386785132440941}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:07,909] Trial 54 finished with value: 0.5392526901617545 and parameters: {'threshold_scale_factor': 0.9015500798518246}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:13,916] Trial 55 finished with value: 0.5398019489337151 and parameters: {'threshold_scale_factor': 0.9568126635508356}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:19,926] Trial 56 finished with value: 0.53853598350794 and parameters: {'threshold_scale_factor': 0.8628496576423752}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:25,844] Trial 57 finished with value: 0.5399355768351287 and parameters: {'threshold_scale_factor': 0.9986359300131435}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:32,005] Trial 58 finished with value: 0.5194527534845106 and parameters: {'threshold_scale_factor': 0.2359897604893011}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:38,005] Trial 59 finished with value: 0.5397970238304638 and parameters: {'threshold_scale_factor': 0.9556288944210325}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:44,018] Trial 60 finished with value: 0.5376742635211674 and parameters: {'threshold_scale_factor': 0.8120358006363748}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:50,038] Trial 61 finished with value: 0.5399077879954126 and parameters: {'threshold_scale_factor': 0.9925097461267086}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:30:56,029] Trial 62 finished with value: 0.5399123134617143 and parameters: {'threshold_scale_factor': 0.9933763676313496}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:31:02,027] Trial 63 finished with value: 0.5393358920417368 and parameters: {'threshold_scale_factor': 0.9056705962193955}. Best is trial 35 with value: 0.5399415151024773.
[I 2025-05-15 03:31:08,034] Trial 64 finished with value: 0.539941592496957 and parameters: {'threshold_scale_factor': 0.999948715636114}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:14,066] Trial 65 finished with value: 0.5302067797564184 and parameters: {'threshold_scale_factor': 0.538279463061476}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:20,067] Trial 66 finished with value: 0.5397884569651513 and parameters: {'threshold_scale_factor': 0.9539752838715188}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:26,082] Trial 67 finished with value: 0.5398167509797437 and parameters: {'threshold_scale_factor': 0.960812529236374}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:32,078] Trial 68 finished with value: 0.5387824244172548 and parameters: {'threshold_scale_factor': 0.874951110758599}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:38,108] Trial 69 finished with value: 0.5394922725129987 and parameters: {'threshold_scale_factor': 0.9194204088862661}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:44,116] Trial 70 finished with value: 0.5360548459498062 and parameters: {'threshold_scale_factor': 0.7289870477271772}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:50,126] Trial 71 finished with value: 0.5399395028460061 and parameters: {'threshold_scale_factor': 0.9994383176967798}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:31:56,117] Trial 72 finished with value: 0.5398375926095308 and parameters: {'threshold_scale_factor': 0.9735292220357574}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:02,130] Trial 73 finished with value: 0.5395808905993851 and parameters: {'threshold_scale_factor': 0.9290503840819027}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:08,278] Trial 74 finished with value: 0.5399407172357507 and parameters: {'threshold_scale_factor': 0.9997117480686375}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:14,293] Trial 75 finished with value: 0.5399374174165723 and parameters: {'threshold_scale_factor': 0.9989454227160128}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:20,286] Trial 76 finished with value: 0.5398160727226675 and parameters: {'threshold_scale_factor': 0.9612248471953271}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:26,290] Trial 77 finished with value: 0.5393429785617291 and parameters: {'threshold_scale_factor': 0.9060447485041313}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:32,288] Trial 78 finished with value: 0.5270392333724996 and parameters: {'threshold_scale_factor': 0.45555975496620815}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:38,311] Trial 79 finished with value: 0.5168060255120348 and parameters: {'threshold_scale_factor': 0.1537827509016113}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:44,302] Trial 80 finished with value: 0.5396615708265027 and parameters: {'threshold_scale_factor': 0.9385129506990245}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:50,334] Trial 81 finished with value: 0.539932185549747 and parameters: {'threshold_scale_factor': 0.9980856929920207}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:32:56,323] Trial 82 finished with value: 0.539941548874614 and parameters: {'threshold_scale_factor': 0.9999440181059135}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:02,355] Trial 83 finished with value: 0.5398208936951643 and parameters: {'threshold_scale_factor': 0.9686665795970688}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:08,352] Trial 84 finished with value: 0.5395839751211927 and parameters: {'threshold_scale_factor': 0.9293710169159622}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:14,386] Trial 85 finished with value: 0.5398254107184318 and parameters: {'threshold_scale_factor': 0.9713344157464328}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:20,356] Trial 86 finished with value: 0.538210847891704 and parameters: {'threshold_scale_factor': 0.8423289269906526}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:26,360] Trial 87 finished with value: 0.538975805078485 and parameters: {'threshold_scale_factor': 0.8862677834068519}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:32,357] Trial 88 finished with value: 0.5394332979194956 and parameters: {'threshold_scale_factor': 0.912249729722913}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:38,369] Trial 89 finished with value: 0.539834731828128 and parameters: {'threshold_scale_factor': 0.972950415592402}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:44,352] Trial 90 finished with value: 0.5396715687861027 and parameters: {'threshold_scale_factor': 0.9396135197555526}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:50,559] Trial 91 finished with value: 0.5398399285156442 and parameters: {'threshold_scale_factor': 0.9743676195569821}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:33:56,546] Trial 92 finished with value: 0.539940915647053 and parameters: {'threshold_scale_factor': 0.9997382726893878}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:02,560] Trial 93 finished with value: 0.5397363550014423 and parameters: {'threshold_scale_factor': 0.9471907432865002}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:08,554] Trial 94 finished with value: 0.5398371240211357 and parameters: {'threshold_scale_factor': 0.9732175376512532}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:14,573] Trial 95 finished with value: 0.5394856236236095 and parameters: {'threshold_scale_factor': 0.9185638576177712}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:20,551] Trial 96 finished with value: 0.5388151088096025 and parameters: {'threshold_scale_factor': 0.8767384457718554}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:26,568] Trial 97 finished with value: 0.5398747574386649 and parameters: {'threshold_scale_factor': 0.9806706206571734}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:32,542] Trial 98 finished with value: 0.5399396857784126 and parameters: {'threshold_scale_factor': 0.9995741619066559}. Best is trial 64 with value: 0.539941592496957.
[I 2025-05-15 03:34:38,548] Trial 99 finished with value: 0.5399418514166707 and parameters: {'threshold_scale_factor': 0.9999792064027991}. Best is trial 99 with value: 0.5399418514166707.
Best hyperparameters: {'threshold_scale_factor': 0.9999792064027991}
Best optimized value: 0.5399418514166707
Running audit 1/1
Training a GraphSAGE target model on github...
Training GraphSAGE on cuda:   0%|          | 0/300 [00:00<?, ?it/s]Training GraphSAGE on cuda:   5%|▍         | 14/300 [00:00<00:02, 135.13it/s]Training GraphSAGE on cuda:  10%|▉         | 29/300 [00:00<00:01, 142.47it/s]Training GraphSAGE on cuda:  15%|█▍        | 44/300 [00:00<00:01, 145.09it/s]Training GraphSAGE on cuda:  20%|██        | 60/300 [00:00<00:01, 150.71it/s]Training GraphSAGE on cuda:  25%|██▌       | 76/300 [00:00<00:01, 154.01it/s]Training GraphSAGE on cuda:  31%|███       | 93/300 [00:00<00:01, 156.36it/s]Training GraphSAGE on cuda:  37%|███▋      | 110/300 [00:00<00:01, 157.93it/s]Training GraphSAGE on cuda:  42%|████▏     | 127/300 [00:00<00:01, 158.74it/s]Training GraphSAGE on cuda:  48%|████▊     | 144/300 [00:00<00:00, 159.30it/s]Training GraphSAGE on cuda:  54%|█████▎    | 161/300 [00:01<00:00, 159.72it/s]Training GraphSAGE on cuda:  59%|█████▉    | 178/300 [00:01<00:00, 159.90it/s]Training GraphSAGE on cuda:  65%|██████▌   | 195/300 [00:01<00:00, 160.18it/s]Training GraphSAGE on cuda:  71%|███████   | 212/300 [00:01<00:00, 160.45it/s]Training GraphSAGE on cuda:  76%|███████▋  | 229/300 [00:01<00:00, 160.54it/s]Training GraphSAGE on cuda:  82%|████████▏ | 246/300 [00:01<00:00, 160.55it/s]Training GraphSAGE on cuda:  88%|████████▊ | 263/300 [00:01<00:00, 160.61it/s]Training GraphSAGE on cuda:  93%|█████████▎| 280/300 [00:01<00:00, 160.77it/s]Training GraphSAGE on cuda:  99%|█████████▉| 297/300 [00:01<00:00, 160.77it/s]Training GraphSAGE on cuda: 100%|██████████| 300/300 [00:01<00:00, 157.85it/s]
Train accuracy: 0.9619 | Test accuracy: 0.8420
Training MLP on cuda:   0%|          | 0/1000 [00:00<?, ?it/s]Training MLP on cuda:   0%|          | 1/1000 [00:39<10:59:13, 39.59s/it]Training MLP on cuda:   0%|          | 2/1000 [01:18<10:48:39, 39.00s/it]Training MLP on cuda:   0%|          | 3/1000 [01:56<10:45:33, 38.85s/it]Training MLP on cuda:   0%|          | 4/1000 [02:35<10:43:57, 38.79s/it]Training MLP on cuda:   0%|          | 5/1000 [03:14<10:43:04, 38.78s/it]Training MLP on cuda:   1%|          | 6/1000 [03:52<10:40:41, 38.67s/it]Training MLP on cuda:   1%|          | 7/1000 [04:31<10:41:24, 38.76s/it]Training MLP on cuda:   1%|          | 8/1000 [05:10<10:39:41, 38.69s/it]Training MLP on cuda:   1%|          | 9/1000 [05:48<10:38:43, 38.67s/it]Training MLP on cuda:   1%|          | 10/1000 [06:27<10:37:42, 38.65s/it]Training MLP on cuda:   1%|          | 11/1000 [07:06<10:37:58, 38.70s/it]Training MLP on cuda:   1%|          | 12/1000 [07:44<10:36:17, 38.64s/it]Training MLP on cuda:   1%|▏         | 13/1000 [08:23<10:36:12, 38.68s/it]Training MLP on cuda:   1%|▏         | 14/1000 [09:02<10:34:52, 38.63s/it]Training MLP on cuda:   2%|▏         | 15/1000 [09:40<10:34:08, 38.63s/it]Training MLP on cuda:   2%|▏         | 16/1000 [10:19<10:33:27, 38.63s/it]Training MLP on cuda:   2%|▏         | 17/1000 [10:58<10:33:39, 38.68s/it]Training MLP on cuda:   2%|▏         | 18/1000 [11:36<10:32:11, 38.63s/it]Training MLP on cuda:   2%|▏         | 19/1000 [12:15<10:31:32, 38.63s/it]Training MLP on cuda:   2%|▏         | 20/1000 [12:53<10:30:39, 38.61s/it]Training MLP on cuda:   2%|▏         | 21/1000 [13:32<10:30:54, 38.67s/it]Training MLP on cuda:   2%|▏         | 22/1000 [14:11<10:29:51, 38.64s/it]Training MLP on cuda:   2%|▏         | 23/1000 [14:50<10:30:24, 38.71s/it]Training MLP on cuda:   2%|▏         | 24/1000 [15:28<10:29:17, 38.69s/it]Training MLP on cuda:   2%|▎         | 25/1000 [16:07<10:28:36, 38.68s/it]Training MLP on cuda:   3%|▎         | 26/1000 [16:46<10:28:00, 38.69s/it]Training MLP on cuda:   3%|▎         | 27/1000 [17:24<10:25:57, 38.60s/it]Training MLP on cuda:   3%|▎         | 28/1000 [18:03<10:26:20, 38.66s/it]Training MLP on cuda:   3%|▎         | 29/1000 [18:41<10:25:22, 38.64s/it]Training MLP on cuda:   3%|▎         | 30/1000 [19:20<10:25:41, 38.70s/it]Training MLP on cuda:   3%|▎         | 31/1000 [19:59<10:24:20, 38.66s/it]Training MLP on cuda:   3%|▎         | 32/1000 [20:38<10:24:04, 38.68s/it]Training MLP on cuda:   3%|▎         | 33/1000 [21:16<10:22:31, 38.63s/it]Training MLP on cuda:   3%|▎         | 34/1000 [21:55<10:22:38, 38.67s/it]Training MLP on cuda:   4%|▎         | 35/1000 [22:33<10:21:55, 38.67s/it]Training MLP on cuda:   4%|▎         | 36/1000 [23:12<10:21:12, 38.66s/it]Training MLP on cuda:   4%|▎         | 37/1000 [23:51<10:20:08, 38.64s/it]Training MLP on cuda:   4%|▍         | 38/1000 [24:30<10:20:52, 38.72s/it]Training MLP on cuda:   4%|▍         | 39/1000 [25:08<10:19:16, 38.66s/it]Training MLP on cuda:   4%|▍         | 40/1000 [25:47<10:19:10, 38.70s/it]Training MLP on cuda:   4%|▍         | 41/1000 [26:26<10:17:55, 38.66s/it]Training MLP on cuda:   4%|▍         | 42/1000 [27:04<10:17:40, 38.69s/it]Training MLP on cuda:   4%|▍         | 43/1000 [27:43<10:15:48, 38.61s/it]Training MLP on cuda:   4%|▍         | 44/1000 [28:21<10:15:05, 38.60s/it]Training MLP on cuda:   4%|▍         | 45/1000 [29:00<10:14:03, 38.58s/it]Training MLP on cuda:   5%|▍         | 46/1000 [29:38<10:13:32, 38.59s/it]Training MLP on cuda:   5%|▍         | 47/1000 [30:17<10:11:48, 38.52s/it]Training MLP on cuda:   5%|▍         | 48/1000 [30:55<10:11:29, 38.54s/it]Training MLP on cuda:   5%|▍         | 49/1000 [31:34<10:09:41, 38.47s/it]Training MLP on cuda:   5%|▌         | 50/1000 [32:12<10:09:10, 38.47s/it]Training MLP on cuda:   5%|▌         | 51/1000 [32:50<10:07:51, 38.43s/it]Training MLP on cuda:   5%|▌         | 52/1000 [33:29<10:08:05, 38.49s/it]Training MLP on cuda:   5%|▌         | 53/1000 [34:07<10:06:14, 38.41s/it]Training MLP on cuda:   5%|▌         | 54/1000 [34:46<10:06:25, 38.46s/it]Training MLP on cuda:   6%|▌         | 55/1000 [35:24<10:05:28, 38.44s/it]Training MLP on cuda:   6%|▌         | 56/1000 [36:03<10:05:22, 38.48s/it]Training MLP on cuda:   6%|▌         | 57/1000 [36:41<10:04:08, 38.44s/it]Training MLP on cuda:   6%|▌         | 58/1000 [37:20<10:04:11, 38.48s/it]Training MLP on cuda:   6%|▌         | 59/1000 [37:58<10:03:21, 38.47s/it]Training MLP on cuda:   6%|▌         | 60/1000 [38:37<10:02:54, 38.48s/it]Training MLP on cuda:   6%|▌         | 61/1000 [39:15<10:02:05, 38.47s/it]Training MLP on cuda:   6%|▌         | 62/1000 [39:54<10:01:43, 38.49s/it]Training MLP on cuda:   6%|▋         | 63/1000 [40:32<10:00:29, 38.45s/it]Training MLP on cuda:   6%|▋         | 64/1000 [41:11<10:00:33, 38.50s/it]Training MLP on cuda:   6%|▋         | 65/1000 [41:49<9:59:27, 38.47s/it] Training MLP on cuda:   7%|▋         | 66/1000 [42:28<9:58:37, 38.46s/it]Training MLP on cuda:   7%|▋         | 67/1000 [43:06<9:57:51, 38.45s/it]Training MLP on cuda:   7%|▋         | 68/1000 [43:44<9:57:39, 38.48s/it]Training MLP on cuda:   7%|▋         | 69/1000 [44:23<9:56:27, 38.44s/it]Training MLP on cuda:   7%|▋         | 70/1000 [45:01<9:56:07, 38.46s/it]Training MLP on cuda:   7%|▋         | 71/1000 [45:40<9:55:15, 38.45s/it]Training MLP on cuda:   7%|▋         | 72/1000 [46:18<9:55:26, 38.50s/it]Training MLP on cuda:   7%|▋         | 73/1000 [46:57<9:53:46, 38.43s/it]Training MLP on cuda:   7%|▋         | 74/1000 [47:35<9:53:46, 38.47s/it]Training MLP on cuda:   8%|▊         | 75/1000 [48:14<9:52:53, 38.46s/it]Training MLP on cuda:   8%|▊         | 76/1000 [48:52<9:52:22, 38.47s/it]Training MLP on cuda:   8%|▊         | 77/1000 [49:31<9:51:33, 38.45s/it]Training MLP on cuda:   8%|▊         | 78/1000 [50:09<9:51:57, 38.52s/it]Training MLP on cuda:   8%|▊         | 79/1000 [50:48<9:51:23, 38.53s/it]Training MLP on cuda:   8%|▊         | 80/1000 [51:27<9:51:54, 38.60s/it]Training MLP on cuda:   8%|▊         | 81/1000 [52:05<9:51:25, 38.61s/it]Training MLP on cuda:   8%|▊         | 82/1000 [52:44<9:50:41, 38.61s/it]Training MLP on cuda:   8%|▊         | 83/1000 [53:22<9:49:16, 38.56s/it]Training MLP on cuda:   8%|▊         | 84/1000 [54:01<9:49:11, 38.59s/it]Training MLP on cuda:   8%|▊         | 85/1000 [54:39<9:48:21, 38.58s/it]Training MLP on cuda:   9%|▊         | 86/1000 [55:18<9:48:08, 38.61s/it]Training MLP on cuda:   9%|▊         | 87/1000 [55:57<9:47:03, 38.58s/it]Training MLP on cuda:   9%|▉         | 88/1000 [56:35<9:47:03, 38.62s/it]Training MLP on cuda:   9%|▉         | 89/1000 [57:14<9:46:06, 38.60s/it]Training MLP on cuda:   9%|▉         | 90/1000 [57:53<9:45:40, 38.62s/it]Training MLP on cuda:   9%|▉         | 91/1000 [58:31<9:44:38, 38.59s/it]Training MLP on cuda:   9%|▉         | 92/1000 [59:10<9:44:07, 38.60s/it]Training MLP on cuda:   9%|▉         | 93/1000 [59:48<9:43:14, 38.58s/it]Training MLP on cuda:   9%|▉         | 94/1000 [1:00:27<9:43:16, 38.63s/it]Training MLP on cuda:  10%|▉         | 95/1000 [1:01:05<9:41:28, 38.55s/it]Training MLP on cuda:  10%|▉         | 96/1000 [1:01:44<9:41:34, 38.60s/it]Training MLP on cuda:  10%|▉         | 97/1000 [1:02:23<9:40:38, 38.58s/it]Training MLP on cuda:  10%|▉         | 98/1000 [1:03:01<9:39:59, 38.58s/it]Training MLP on cuda:  10%|▉         | 99/1000 [1:03:40<9:39:41, 38.60s/it]Training MLP on cuda:  10%|█         | 100/1000 [1:04:19<9:39:27, 38.63s/it]Training MLP on cuda:  10%|█         | 101/1000 [1:04:57<9:38:10, 38.59s/it]Training MLP on cuda:  10%|█         | 102/1000 [1:05:36<9:37:44, 38.60s/it]Training MLP on cuda:  10%|█         | 103/1000 [1:06:14<9:36:37, 38.57s/it]Training MLP on cuda:  10%|█         | 104/1000 [1:06:53<9:36:30, 38.61s/it]Training MLP on cuda:  10%|█         | 105/1000 [1:07:31<9:34:50, 38.54s/it]Training MLP on cuda:  11%|█         | 106/1000 [1:08:10<9:35:12, 38.60s/it]Training MLP on cuda:  11%|█         | 107/1000 [1:08:49<9:34:53, 38.63s/it]Training MLP on cuda:  11%|█         | 108/1000 [1:09:27<9:32:38, 38.52s/it]Training MLP on cuda:  11%|█         | 109/1000 [1:10:06<9:32:37, 38.56s/it]Training MLP on cuda:  11%|█         | 110/1000 [1:10:44<9:32:08, 38.57s/it]Training MLP on cuda:  11%|█         | 111/1000 [1:11:23<9:31:53, 38.60s/it]Training MLP on cuda:  11%|█         | 112/1000 [1:12:01<9:30:15, 38.53s/it]Training MLP on cuda:  11%|█▏        | 113/1000 [1:12:40<9:30:36, 38.60s/it]Training MLP on cuda:  11%|█▏        | 114/1000 [1:13:19<9:29:58, 38.60s/it]Training MLP on cuda:  12%|█▏        | 115/1000 [1:13:57<9:29:32, 38.61s/it]Training MLP on cuda:  12%|█▏        | 116/1000 [1:14:36<9:28:08, 38.56s/it]Training MLP on cuda:  12%|█▏        | 117/1000 [1:15:14<9:28:03, 38.60s/it]Training MLP on cuda:  12%|█▏        | 118/1000 [1:15:53<9:27:07, 38.58s/it]Training MLP on cuda:  12%|█▏        | 119/1000 [1:16:32<9:26:39, 38.59s/it]Training MLP on cuda:  12%|█▏        | 120/1000 [1:17:10<9:25:42, 38.57s/it]Training MLP on cuda:  12%|█▏        | 121/1000 [1:17:49<9:25:17, 38.59s/it]Training MLP on cuda:  12%|█▏        | 122/1000 [1:18:27<9:24:24, 38.57s/it]Training MLP on cuda:  12%|█▏        | 123/1000 [1:19:06<9:24:11, 38.60s/it]Training MLP on cuda:  12%|█▏        | 124/1000 [1:19:44<9:23:16, 38.58s/it]Training MLP on cuda:  12%|█▎        | 125/1000 [1:20:23<9:22:47, 38.59s/it]Training MLP on cuda:  13%|█▎        | 126/1000 [1:21:01<9:21:34, 38.55s/it]Training MLP on cuda:  13%|█▎        | 127/1000 [1:21:40<9:21:44, 38.61s/it]Training MLP on cuda:  13%|█▎        | 128/1000 [1:22:19<9:20:33, 38.57s/it]Training MLP on cuda:  13%|█▎        | 129/1000 [1:22:57<9:20:23, 38.60s/it]Training MLP on cuda:  13%|█▎        | 130/1000 [1:23:36<9:19:01, 38.55s/it]Training MLP on cuda:  13%|█▎        | 131/1000 [1:24:15<9:19:00, 38.60s/it]Training MLP on cuda:  13%|█▎        | 132/1000 [1:24:53<9:18:00, 38.57s/it]Training MLP on cuda:  13%|█▎        | 133/1000 [1:25:32<9:17:43, 38.60s/it]Training MLP on cuda:  13%|█▎        | 134/1000 [1:26:10<9:16:48, 38.58s/it]Training MLP on cuda:  14%|█▎        | 135/1000 [1:26:49<9:16:46, 38.62s/it]Training MLP on cuda:  14%|█▎        | 136/1000 [1:27:27<9:15:44, 38.59s/it]Training MLP on cuda:  14%|█▎        | 137/1000 [1:28:06<9:14:57, 38.58s/it]Training MLP on cuda:  14%|█▍        | 138/1000 [1:28:45<9:15:03, 38.64s/it]Training MLP on cuda:  14%|█▍        | 139/1000 [1:29:23<9:13:20, 38.56s/it]Training MLP on cuda:  14%|█▍        | 140/1000 [1:30:02<9:13:09, 38.59s/it]Training MLP on cuda:  14%|█▍        | 141/1000 [1:30:40<9:11:38, 38.53s/it]Training MLP on cuda:  14%|█▍        | 142/1000 [1:31:19<9:11:46, 38.59s/it]Training MLP on cuda:  14%|█▍        | 143/1000 [1:31:57<9:10:49, 38.56s/it]Training MLP on cuda:  14%|█▍        | 144/1000 [1:32:36<9:10:24, 38.58s/it]Training MLP on cuda:  14%|█▍        | 145/1000 [1:33:15<9:09:37, 38.57s/it]Training MLP on cuda:  15%|█▍        | 146/1000 [1:33:53<9:09:13, 38.59s/it]Training MLP on cuda:  15%|█▍        | 147/1000 [1:34:32<9:07:50, 38.53s/it]Training MLP on cuda:  15%|█▍        | 148/1000 [1:35:10<9:07:59, 38.59s/it]Training MLP on cuda:  15%|█▍        | 149/1000 [1:35:49<9:07:15, 38.59s/it]Training MLP on cuda:  15%|█▌        | 150/1000 [1:36:28<9:07:13, 38.63s/it]Training MLP on cuda:  15%|█▌        | 151/1000 [1:37:06<9:05:41, 38.56s/it]Training MLP on cuda:  15%|█▌        | 151/1000 [1:37:45<9:09:37, 38.84s/it]
Training MLP on cuda:   0%|          | 0/1000 [00:00<?, ?it/s]Training MLP on cuda:   0%|          | 1/1000 [00:38<10:40:05, 38.44s/it]Training MLP on cuda:   0%|          | 2/1000 [01:17<10:47:52, 38.95s/it]Training MLP on cuda:   0%|          | 3/1000 [01:56<10:42:19, 38.66s/it]Training MLP on cuda:   0%|          | 4/1000 [02:34<10:40:35, 38.59s/it]Training MLP on cuda:   0%|          | 5/1000 [03:14<10:47:45, 39.06s/it]Training MLP on cuda:   1%|          | 6/1000 [03:52<10:42:24, 38.78s/it]Training MLP on cuda:   1%|          | 7/1000 [04:30<10:39:19, 38.63s/it]Training MLP on cuda:   1%|          | 8/1000 [05:10<10:45:05, 39.02s/it]Training MLP on cuda:   1%|          | 9/1000 [05:49<10:41:07, 38.82s/it]Training MLP on cuda:   1%|          | 10/1000 [06:27<10:38:31, 38.70s/it]Training MLP on cuda:   1%|          | 11/1000 [07:07<10:44:10, 39.08s/it]Training MLP on cuda:   1%|          | 12/1000 [07:45<10:39:24, 38.83s/it]Training MLP on cuda:   1%|▏         | 13/1000 [08:24<10:37:00, 38.72s/it]Training MLP on cuda:   1%|▏         | 14/1000 [09:04<10:42:18, 39.09s/it]Training MLP on cuda:   2%|▏         | 15/1000 [09:42<10:37:50, 38.85s/it]Training MLP on cuda:   2%|▏         | 16/1000 [10:20<10:34:54, 38.71s/it]Training MLP on cuda:   2%|▏         | 17/1000 [11:00<10:40:08, 39.07s/it]Training MLP on cuda:   2%|▏         | 18/1000 [11:39<10:36:06, 38.87s/it]Training MLP on cuda:   2%|▏         | 19/1000 [12:17<10:32:50, 38.71s/it]Training MLP on cuda:   2%|▏         | 20/1000 [12:57<10:38:00, 39.06s/it]Training MLP on cuda:   2%|▏         | 21/1000 [13:35<10:34:17, 38.87s/it]Training MLP on cuda:   2%|▏         | 22/1000 [14:14<10:31:45, 38.76s/it]Training MLP on cuda:   2%|▏         | 23/1000 [14:54<10:37:24, 39.15s/it]Training MLP on cuda:   2%|▏         | 24/1000 [15:32<10:33:28, 38.94s/it]Training MLP on cuda:   2%|▎         | 25/1000 [16:11<10:31:15, 38.85s/it]Training MLP on cuda:   3%|▎         | 26/1000 [16:51<10:36:04, 39.18s/it]Training MLP on cuda:   3%|▎         | 27/1000 [17:29<10:31:26, 38.94s/it]Training MLP on cuda:   3%|▎         | 28/1000 [18:08<10:29:29, 38.86s/it]Training MLP on cuda:   3%|▎         | 29/1000 [18:48<10:34:37, 39.21s/it]Training MLP on cuda:   3%|▎         | 30/1000 [19:26<10:29:49, 38.96s/it]Training MLP on cuda:   3%|▎         | 31/1000 [20:05<10:27:27, 38.85s/it]Training MLP on cuda:   3%|▎         | 32/1000 [20:45<10:31:52, 39.17s/it]Training MLP on cuda:   3%|▎         | 33/1000 [21:23<10:27:44, 38.95s/it]Training MLP on cuda:   3%|▎         | 34/1000 [22:02<10:25:22, 38.84s/it]Training MLP on cuda:   4%|▎         | 35/1000 [22:42<10:29:56, 39.17s/it]Training MLP on cuda:   4%|▎         | 36/1000 [23:20<10:25:26, 38.93s/it]Training MLP on cuda:   4%|▎         | 37/1000 [23:59<10:22:55, 38.81s/it]Training MLP on cuda:   4%|▍         | 38/1000 [24:39<10:28:21, 39.19s/it]Training MLP on cuda:   4%|▍         | 39/1000 [25:17<10:24:02, 38.96s/it]Training MLP on cuda:   4%|▍         | 40/1000 [25:56<10:21:20, 38.83s/it]Training MLP on cuda:   4%|▍         | 41/1000 [26:36<10:26:09, 39.18s/it]Training MLP on cuda:   4%|▍         | 42/1000 [27:14<10:21:43, 38.94s/it]Training MLP on cuda:   4%|▍         | 43/1000 [27:53<10:19:15, 38.83s/it]Training MLP on cuda:   4%|▍         | 44/1000 [28:33<10:24:02, 39.17s/it]Training MLP on cuda:   4%|▍         | 45/1000 [29:11<10:19:16, 38.91s/it]Training MLP on cuda:   5%|▍         | 46/1000 [29:50<10:17:25, 38.83s/it]Training MLP on cuda:   5%|▍         | 47/1000 [30:30<10:22:14, 39.18s/it]Training MLP on cuda:   5%|▍         | 48/1000 [31:08<10:18:14, 38.96s/it]Training MLP on cuda:   5%|▍         | 49/1000 [31:47<10:15:14, 38.82s/it]Training MLP on cuda:   5%|▌         | 50/1000 [32:27<10:19:53, 39.15s/it]Training MLP on cuda:   5%|▌         | 51/1000 [33:05<10:15:21, 38.91s/it]Training MLP on cuda:   5%|▌         | 52/1000 [33:44<10:13:18, 38.82s/it]Training MLP on cuda:   5%|▌         | 53/1000 [34:23<10:18:07, 39.16s/it]Training MLP on cuda:   5%|▌         | 54/1000 [35:02<10:14:05, 38.95s/it]Training MLP on cuda:   6%|▌         | 55/1000 [35:40<10:11:34, 38.83s/it]Training MLP on cuda:   6%|▌         | 56/1000 [36:21<10:17:29, 39.25s/it]Training MLP on cuda:   6%|▌         | 57/1000 [36:59<10:13:37, 39.04s/it]Training MLP on cuda:   6%|▌         | 58/1000 [37:38<10:10:43, 38.90s/it]Training MLP on cuda:   6%|▌         | 59/1000 [38:18<10:15:28, 39.24s/it]Training MLP on cuda:   6%|▌         | 60/1000 [38:56<10:10:44, 38.98s/it]Training MLP on cuda:   6%|▌         | 61/1000 [39:35<10:08:06, 38.86s/it]Training MLP on cuda:   6%|▌         | 62/1000 [40:15<10:12:42, 39.19s/it]Training MLP on cuda:   6%|▋         | 63/1000 [40:53<10:08:35, 38.97s/it]Training MLP on cuda:   6%|▋         | 64/1000 [41:32<10:05:58, 38.84s/it]Training MLP on cuda:   6%|▋         | 65/1000 [42:12<10:10:34, 39.18s/it]Training MLP on cuda:   7%|▋         | 66/1000 [42:50<10:06:42, 38.97s/it]Training MLP on cuda:   7%|▋         | 67/1000 [43:29<10:04:14, 38.86s/it]Training MLP on cuda:   7%|▋         | 68/1000 [44:09<10:09:12, 39.22s/it]Training MLP on cuda:   7%|▋         | 69/1000 [44:47<10:04:47, 38.98s/it]Training MLP on cuda:   7%|▋         | 70/1000 [45:26<10:02:15, 38.86s/it]Training MLP on cuda:   7%|▋         | 71/1000 [46:06<10:06:52, 39.20s/it]Training MLP on cuda:   7%|▋         | 72/1000 [46:44<10:02:26, 38.95s/it]Training MLP on cuda:   7%|▋         | 73/1000 [47:23<10:00:17, 38.85s/it]Training MLP on cuda:   7%|▋         | 74/1000 [48:03<10:04:34, 39.17s/it]Training MLP on cuda:   8%|▊         | 75/1000 [48:41<10:00:04, 38.92s/it]Training MLP on cuda:   8%|▊         | 76/1000 [49:20<9:57:38, 38.81s/it] Training MLP on cuda:   8%|▊         | 77/1000 [50:00<10:02:31, 39.17s/it]Training MLP on cuda:   8%|▊         | 78/1000 [50:38<9:58:28, 38.95s/it] Training MLP on cuda:   8%|▊         | 79/1000 [51:17<9:56:09, 38.84s/it]Training MLP on cuda:   8%|▊         | 80/1000 [51:57<10:00:26, 39.16s/it]Training MLP on cuda:   8%|▊         | 81/1000 [52:35<9:56:21, 38.94s/it] Training MLP on cuda:   8%|▊         | 82/1000 [53:14<9:54:05, 38.83s/it]Training MLP on cuda:   8%|▊         | 83/1000 [53:54<9:58:34, 39.16s/it]Training MLP on cuda:   8%|▊         | 84/1000 [54:32<9:54:04, 38.91s/it]Training MLP on cuda:   8%|▊         | 85/1000 [55:11<9:52:07, 38.83s/it]Training MLP on cuda:   9%|▊         | 86/1000 [55:50<9:56:29, 39.16s/it]Training MLP on cuda:   9%|▊         | 87/1000 [56:29<9:52:46, 38.96s/it]Training MLP on cuda:   9%|▉         | 88/1000 [57:07<9:50:17, 38.83s/it]Training MLP on cuda:   9%|▉         | 89/1000 [57:47<9:54:40, 39.17s/it]Training MLP on cuda:   9%|▉         | 90/1000 [58:26<9:50:28, 38.93s/it]Training MLP on cuda:   9%|▉         | 91/1000 [59:04<9:48:33, 38.85s/it]Training MLP on cuda:   9%|▉         | 92/1000 [59:44<9:53:01, 39.19s/it]Training MLP on cuda:   9%|▉         | 93/1000 [1:00:23<9:48:48, 38.95s/it]Training MLP on cuda:   9%|▉         | 94/1000 [1:01:01<9:46:46, 38.86s/it]Training MLP on cuda:  10%|▉         | 95/1000 [1:01:42<9:51:35, 39.22s/it]Training MLP on cuda:  10%|▉         | 96/1000 [1:02:20<9:47:36, 39.00s/it]Training MLP on cuda:  10%|▉         | 97/1000 [1:02:59<9:45:23, 38.90s/it]Training MLP on cuda:  10%|▉         | 98/1000 [1:03:39<9:50:27, 39.28s/it]Training MLP on cuda:  10%|▉         | 99/1000 [1:04:17<9:45:48, 39.01s/it]Training MLP on cuda:  10%|█         | 100/1000 [1:04:56<9:43:11, 38.88s/it]Training MLP on cuda:  10%|█         | 101/1000 [1:05:36<9:47:22, 39.20s/it]Training MLP on cuda:  10%|█         | 102/1000 [1:06:14<9:42:51, 38.94s/it]Training MLP on cuda:  10%|█         | 103/1000 [1:06:53<9:39:59, 38.80s/it]Training MLP on cuda:  10%|█         | 104/1000 [1:07:32<9:44:24, 39.13s/it]Training MLP on cuda:  10%|█         | 105/1000 [1:08:11<9:40:37, 38.92s/it]Training MLP on cuda:  11%|█         | 106/1000 [1:08:49<9:38:11, 38.81s/it]Training MLP on cuda:  11%|█         | 107/1000 [1:09:29<9:42:41, 39.15s/it]Training MLP on cuda:  11%|█         | 108/1000 [1:10:08<9:38:16, 38.90s/it]Training MLP on cuda:  11%|█         | 109/1000 [1:10:46<9:35:39, 38.76s/it]Training MLP on cuda:  11%|█         | 110/1000 [1:11:26<9:40:23, 39.13s/it]Training MLP on cuda:  11%|█         | 111/1000 [1:12:04<9:36:15, 38.89s/it]Training MLP on cuda:  11%|█         | 112/1000 [1:12:43<9:33:48, 38.77s/it]Training MLP on cuda:  11%|█▏        | 113/1000 [1:13:23<9:37:48, 39.09s/it]Training MLP on cuda:  11%|█▏        | 114/1000 [1:14:01<9:34:07, 38.88s/it]Training MLP on cuda:  12%|█▏        | 115/1000 [1:14:40<9:31:48, 38.77s/it]Training MLP on cuda:  12%|█▏        | 116/1000 [1:15:20<9:36:07, 39.10s/it]Training MLP on cuda:  12%|█▏        | 117/1000 [1:15:58<9:32:04, 38.87s/it]Training MLP on cuda:  12%|█▏        | 118/1000 [1:16:36<9:30:10, 38.79s/it]Training MLP on cuda:  12%|█▏        | 119/1000 [1:17:16<9:34:28, 39.12s/it]Training MLP on cuda:  12%|█▏        | 120/1000 [1:17:55<9:30:28, 38.90s/it]Training MLP on cuda:  12%|█▏        | 121/1000 [1:18:33<9:28:36, 38.81s/it]Training MLP on cuda:  12%|█▏        | 122/1000 [1:19:13<9:32:45, 39.14s/it]Training MLP on cuda:  12%|█▏        | 123/1000 [1:19:52<9:28:42, 38.91s/it]Training MLP on cuda:  12%|█▏        | 124/1000 [1:20:30<9:26:56, 38.83s/it]Training MLP on cuda:  12%|█▎        | 125/1000 [1:21:10<9:31:58, 39.22s/it]Training MLP on cuda:  13%|█▎        | 126/1000 [1:21:49<9:27:42, 38.97s/it]Training MLP on cuda:  13%|█▎        | 127/1000 [1:22:27<9:25:39, 38.88s/it]Training MLP on cuda:  13%|█▎        | 128/1000 [1:23:08<9:30:10, 39.23s/it]Training MLP on cuda:  13%|█▎        | 129/1000 [1:23:46<9:26:07, 39.00s/it]Training MLP on cuda:  13%|█▎        | 130/1000 [1:24:25<9:23:47, 38.88s/it]Training MLP on cuda:  13%|█▎        | 131/1000 [1:25:05<9:28:02, 39.22s/it]Training MLP on cuda:  13%|█▎        | 132/1000 [1:25:43<9:23:53, 38.98s/it]Training MLP on cuda:  13%|█▎        | 133/1000 [1:26:22<9:21:12, 38.84s/it]Training MLP on cuda:  13%|█▎        | 134/1000 [1:27:02<9:25:37, 39.19s/it]Training MLP on cuda:  14%|█▎        | 135/1000 [1:27:40<9:21:48, 38.97s/it]Training MLP on cuda:  14%|█▎        | 136/1000 [1:28:19<9:19:28, 38.85s/it]Training MLP on cuda:  14%|█▎        | 137/1000 [1:28:59<9:23:29, 39.18s/it]Training MLP on cuda:  14%|█▍        | 138/1000 [1:29:37<9:19:58, 38.98s/it]Training MLP on cuda:  14%|█▍        | 139/1000 [1:30:16<9:17:33, 38.85s/it]Training MLP on cuda:  14%|█▍        | 140/1000 [1:30:56<9:21:56, 39.21s/it]Training MLP on cuda:  14%|█▍        | 141/1000 [1:31:34<9:17:57, 38.97s/it]Training MLP on cuda:  14%|█▍        | 142/1000 [1:32:13<9:15:31, 38.85s/it]Training MLP on cuda:  14%|█▍        | 143/1000 [1:32:53<9:19:39, 39.18s/it]Training MLP on cuda:  14%|█▍        | 144/1000 [1:33:31<9:16:26, 39.00s/it]Training MLP on cuda:  14%|█▍        | 145/1000 [1:34:10<9:13:53, 38.87s/it]Training MLP on cuda:  15%|█▍        | 146/1000 [1:34:50<9:17:59, 39.20s/it]Training MLP on cuda:  15%|█▍        | 147/1000 [1:35:28<9:13:29, 38.93s/it]Training MLP on cuda:  15%|█▍        | 148/1000 [1:36:07<9:11:21, 38.83s/it]Training MLP on cuda:  15%|█▍        | 149/1000 [1:36:47<9:15:50, 39.19s/it]Training MLP on cuda:  15%|█▌        | 150/1000 [1:37:25<9:12:12, 38.98s/it]Training MLP on cuda:  15%|█▌        | 151/1000 [1:38:04<9:09:46, 38.85s/it]Training MLP on cuda:  15%|█▌        | 152/1000 [1:38:44<9:13:58, 39.20s/it]Training MLP on cuda:  15%|█▌        | 153/1000 [1:39:22<9:09:54, 38.95s/it]Training MLP on cuda:  15%|█▌        | 154/1000 [1:40:01<9:07:52, 38.86s/it]Training MLP on cuda:  16%|█▌        | 155/1000 [1:40:41<9:11:54, 39.19s/it]Training MLP on cuda:  16%|█▌        | 156/1000 [1:41:19<9:07:28, 38.92s/it]Training MLP on cuda:  16%|█▌        | 157/1000 [1:41:57<9:05:03, 38.79s/it]Training MLP on cuda:  16%|█▌        | 158/1000 [1:42:37<9:09:44, 39.17s/it]Training MLP on cuda:  16%|█▌        | 159/1000 [1:43:16<9:06:09, 38.96s/it]Training MLP on cuda:  16%|█▌        | 160/1000 [1:43:55<9:03:47, 38.84s/it]Training MLP on cuda:  16%|█▌        | 161/1000 [1:44:35<9:08:08, 39.20s/it]Training MLP on cuda:  16%|█▌        | 162/1000 [1:45:13<9:04:32, 38.99s/it]Training MLP on cuda:  16%|█▋        | 163/1000 [1:45:52<9:02:34, 38.89s/it]Training MLP on cuda:  16%|█▋        | 164/1000 [1:46:32<9:06:56, 39.25s/it]Training MLP on cuda:  16%|█▋        | 165/1000 [1:47:10<9:03:29, 39.05s/it]Training MLP on cuda:  17%|█▋        | 166/1000 [1:47:49<9:00:51, 38.91s/it]Training MLP on cuda:  17%|█▋        | 167/1000 [1:48:29<9:04:57, 39.25s/it]Training MLP on cuda:  17%|█▋        | 168/1000 [1:49:08<9:01:17, 39.04s/it]Training MLP on cuda:  17%|█▋        | 169/1000 [1:49:46<8:59:00, 38.92s/it]Training MLP on cuda:  17%|█▋        | 170/1000 [1:50:26<9:03:02, 39.26s/it]Training MLP on cuda:  17%|█▋        | 171/1000 [1:51:05<8:59:00, 39.01s/it]Training MLP on cuda:  17%|█▋        | 172/1000 [1:51:43<8:56:41, 38.89s/it]Training MLP on cuda:  17%|█▋        | 173/1000 [1:52:23<9:00:48, 39.24s/it]Training MLP on cuda:  17%|█▋        | 174/1000 [1:53:02<8:56:41, 38.99s/it]Training MLP on cuda:  18%|█▊        | 175/1000 [1:53:40<8:54:34, 38.88s/it]Training MLP on cuda:  18%|█▊        | 176/1000 [1:54:20<8:58:36, 39.22s/it]Training MLP on cuda:  18%|█▊        | 177/1000 [1:54:59<8:54:28, 38.97s/it]Training MLP on cuda:  18%|█▊        | 178/1000 [1:55:37<8:52:07, 38.84s/it]Training MLP on cuda:  18%|█▊        | 179/1000 [1:56:17<8:56:46, 39.23s/it]Training MLP on cuda:  18%|█▊        | 180/1000 [1:56:56<8:53:10, 39.01s/it]Training MLP on cuda:  18%|█▊        | 181/1000 [1:57:35<8:50:40, 38.88s/it]Training MLP on cuda:  18%|█▊        | 182/1000 [1:58:14<8:54:30, 39.21s/it]Training MLP on cuda:  18%|█▊        | 183/1000 [1:58:53<8:50:49, 38.98s/it]Training MLP on cuda:  18%|█▊        | 184/1000 [1:59:32<8:48:32, 38.86s/it]Training MLP on cuda:  18%|█▊        | 185/1000 [2:00:12<8:52:25, 39.20s/it]Training MLP on cuda:  19%|█▊        | 186/1000 [2:00:50<8:48:41, 38.97s/it]Training MLP on cuda:  19%|█▊        | 187/1000 [2:01:28<8:46:15, 38.84s/it]Training MLP on cuda:  19%|█▉        | 188/1000 [2:02:09<8:50:37, 39.21s/it]Training MLP on cuda:  19%|█▉        | 189/1000 [2:02:47<8:46:48, 38.98s/it]Training MLP on cuda:  19%|█▉        | 190/1000 [2:03:26<8:44:41, 38.87s/it]Training MLP on cuda:  19%|█▉        | 191/1000 [2:04:06<8:48:28, 39.20s/it]Training MLP on cuda:  19%|█▉        | 192/1000 [2:04:44<8:44:55, 38.98s/it]Training MLP on cuda:  19%|█▉        | 193/1000 [2:05:23<8:42:35, 38.85s/it]Training MLP on cuda:  19%|█▉        | 194/1000 [2:06:03<8:46:31, 39.20s/it]Training MLP on cuda:  20%|█▉        | 195/1000 [2:06:41<8:42:45, 38.96s/it]Training MLP on cuda:  20%|█▉        | 196/1000 [2:07:20<8:40:33, 38.85s/it]Training MLP on cuda:  20%|█▉        | 197/1000 [2:08:00<8:44:14, 39.17s/it]Training MLP on cuda:  20%|█▉        | 198/1000 [2:08:38<8:40:39, 38.95s/it]Training MLP on cuda:  20%|█▉        | 199/1000 [2:09:17<8:39:00, 38.88s/it]Training MLP on cuda:  20%|██        | 200/1000 [2:09:57<8:42:55, 39.22s/it]Training MLP on cuda:  20%|██        | 201/1000 [2:10:35<8:38:49, 38.96s/it]Training MLP on cuda:  20%|██        | 202/1000 [2:11:14<8:36:41, 38.85s/it]Training MLP on cuda:  20%|██        | 203/1000 [2:11:54<8:40:38, 39.20s/it]Training MLP on cuda:  20%|██        | 204/1000 [2:12:32<8:36:51, 38.96s/it]Training MLP on cuda:  20%|██        | 205/1000 [2:13:11<8:34:39, 38.84s/it]Training MLP on cuda:  21%|██        | 206/1000 [2:13:51<8:38:15, 39.16s/it]Training MLP on cuda:  21%|██        | 207/1000 [2:14:29<8:34:59, 38.97s/it]Training MLP on cuda:  21%|██        | 208/1000 [2:15:08<8:33:01, 38.86s/it]Training MLP on cuda:  21%|██        | 209/1000 [2:15:48<8:37:00, 39.22s/it]Training MLP on cuda:  21%|██        | 210/1000 [2:16:26<8:33:28, 39.00s/it]Training MLP on cuda:  21%|██        | 211/1000 [2:17:05<8:31:09, 38.87s/it]Training MLP on cuda:  21%|██        | 212/1000 [2:17:45<8:35:09, 39.23s/it]Training MLP on cuda:  21%|██▏       | 213/1000 [2:18:23<8:31:29, 38.99s/it]Training MLP on cuda:  21%|██▏       | 214/1000 [2:19:02<8:29:11, 38.87s/it]Training MLP on cuda:  22%|██▏       | 215/1000 [2:19:42<8:32:48, 39.20s/it]Training MLP on cuda:  22%|██▏       | 216/1000 [2:20:20<8:29:02, 38.96s/it]Training MLP on cuda:  22%|██▏       | 217/1000 [2:20:59<8:26:45, 38.83s/it]Training MLP on cuda:  22%|██▏       | 218/1000 [2:21:39<8:30:42, 39.18s/it]Training MLP on cuda:  22%|██▏       | 219/1000 [2:22:17<8:26:48, 38.93s/it]Training MLP on cuda:  22%|██▏       | 220/1000 [2:22:56<8:24:40, 38.82s/it]Training MLP on cuda:  22%|██▏       | 221/1000 [2:23:36<8:28:30, 39.17s/it]Training MLP on cuda:  22%|██▏       | 222/1000 [2:24:14<8:24:36, 38.92s/it]Training MLP on cuda:  22%|██▏       | 223/1000 [2:24:53<8:22:30, 38.80s/it]Training MLP on cuda:  22%|██▏       | 224/1000 [2:25:32<8:26:12, 39.14s/it]Training MLP on cuda:  22%|██▎       | 225/1000 [2:26:11<8:22:15, 38.88s/it]Training MLP on cuda:  23%|██▎       | 226/1000 [2:26:49<8:20:34, 38.80s/it]Training MLP on cuda:  23%|██▎       | 227/1000 [2:27:29<8:24:36, 39.17s/it]Training MLP on cuda:  23%|██▎       | 228/1000 [2:28:08<8:20:58, 38.94s/it]Training MLP on cuda:  23%|██▎       | 229/1000 [2:28:46<8:18:46, 38.81s/it]Training MLP on cuda:  23%|██▎       | 230/1000 [2:29:26<8:22:15, 39.14s/it]Training MLP on cuda:  23%|██▎       | 231/1000 [2:30:05<8:18:34, 38.90s/it]Training MLP on cuda:  23%|██▎       | 232/1000 [2:30:43<8:16:13, 38.77s/it]Training MLP on cuda:  23%|██▎       | 233/1000 [2:31:23<8:20:21, 39.14s/it]Training MLP on cuda:  23%|██▎       | 234/1000 [2:32:01<8:16:48, 38.91s/it]Training MLP on cuda:  24%|██▎       | 235/1000 [2:32:40<8:14:30, 38.78s/it]Training MLP on cuda:  24%|██▎       | 236/1000 [2:33:20<8:18:44, 39.17s/it]Training MLP on cuda:  24%|██▎       | 237/1000 [2:33:58<8:15:23, 38.96s/it]Training MLP on cuda:  24%|██▍       | 238/1000 [2:34:37<8:12:55, 38.81s/it]Training MLP on cuda:  24%|██▍       | 239/1000 [2:35:17<8:17:10, 39.20s/it]Training MLP on cuda:  24%|██▍       | 240/1000 [2:35:55<8:13:19, 38.95s/it]Training MLP on cuda:  24%|██▍       | 241/1000 [2:36:34<8:11:10, 38.83s/it]Training MLP on cuda:  24%|██▍       | 242/1000 [2:37:14<8:14:40, 39.16s/it]Training MLP on cuda:  24%|██▍       | 243/1000 [2:37:52<8:11:23, 38.95s/it]Training MLP on cuda:  24%|██▍       | 244/1000 [2:38:31<8:09:10, 38.82s/it]Training MLP on cuda:  24%|██▍       | 245/1000 [2:39:11<8:12:53, 39.17s/it]Training MLP on cuda:  25%|██▍       | 246/1000 [2:39:49<8:09:32, 38.96s/it]Training MLP on cuda:  25%|██▍       | 247/1000 [2:40:28<8:07:37, 38.85s/it]Training MLP on cuda:  25%|██▍       | 248/1000 [2:41:08<8:11:15, 39.20s/it]Training MLP on cuda:  25%|██▍       | 249/1000 [2:41:46<8:07:29, 38.95s/it]Training MLP on cuda:  25%|██▌       | 250/1000 [2:42:25<8:05:23, 38.83s/it]Training MLP on cuda:  25%|██▌       | 251/1000 [2:43:05<8:09:13, 39.19s/it]Training MLP on cuda:  25%|██▌       | 252/1000 [2:43:43<8:05:23, 38.94s/it]Training MLP on cuda:  25%|██▌       | 253/1000 [2:44:22<8:03:16, 38.82s/it]Training MLP on cuda:  25%|██▌       | 254/1000 [2:45:02<8:06:44, 39.15s/it]Training MLP on cuda:  26%|██▌       | 255/1000 [2:45:40<8:03:17, 38.92s/it]Training MLP on cuda:  26%|██▌       | 256/1000 [2:46:19<8:01:16, 38.81s/it]Training MLP on cuda:  26%|██▌       | 257/1000 [2:46:59<8:05:32, 39.21s/it]Training MLP on cuda:  26%|██▌       | 258/1000 [2:47:37<8:02:14, 38.99s/it]Training MLP on cuda:  26%|██▌       | 259/1000 [2:48:16<8:00:02, 38.87s/it]Training MLP on cuda:  26%|██▌       | 260/1000 [2:48:56<8:03:46, 39.22s/it]Training MLP on cuda:  26%|██▌       | 261/1000 [2:49:34<8:00:35, 39.02s/it]Training MLP on cuda:  26%|██▌       | 262/1000 [2:50:13<7:58:19, 38.89s/it]Training MLP on cuda:  26%|██▋       | 263/1000 [2:50:53<8:01:34, 39.21s/it]Training MLP on cuda:  26%|██▋       | 264/1000 [2:51:31<7:57:56, 38.96s/it]Training MLP on cuda:  26%|██▋       | 265/1000 [2:52:10<7:55:55, 38.85s/it]Training MLP on cuda:  27%|██▋       | 266/1000 [2:52:50<7:59:18, 39.18s/it]Training MLP on cuda:  27%|██▋       | 267/1000 [2:53:28<7:55:59, 38.96s/it]Training MLP on cuda:  27%|██▋       | 268/1000 [2:54:07<7:54:12, 38.87s/it]Training MLP on cuda:  27%|██▋       | 269/1000 [2:54:47<7:57:27, 39.19s/it]Training MLP on cuda:  27%|██▋       | 270/1000 [2:55:25<7:54:03, 38.96s/it]Training MLP on cuda:  27%|██▋       | 271/1000 [2:56:04<7:51:57, 38.84s/it]Training MLP on cuda:  27%|██▋       | 272/1000 [2:56:44<7:55:32, 39.19s/it]Training MLP on cuda:  27%|██▋       | 273/1000 [2:57:22<7:51:45, 38.93s/it]Training MLP on cuda:  27%|██▋       | 274/1000 [2:58:01<7:49:44, 38.82s/it]Training MLP on cuda:  28%|██▊       | 275/1000 [2:58:41<7:53:13, 39.16s/it]Training MLP on cuda:  28%|██▊       | 276/1000 [2:59:19<7:49:38, 38.92s/it]Training MLP on cuda:  28%|██▊       | 277/1000 [2:59:58<7:47:49, 38.82s/it]Training MLP on cuda:  28%|██▊       | 278/1000 [3:00:38<7:51:26, 39.18s/it]Training MLP on cuda:  28%|██▊       | 279/1000 [3:01:16<7:48:04, 38.95s/it]Training MLP on cuda:  28%|██▊       | 280/1000 [3:01:55<7:45:54, 38.83s/it]Training MLP on cuda:  28%|██▊       | 281/1000 [3:02:35<7:49:43, 39.20s/it]Training MLP on cuda:  28%|██▊       | 282/1000 [3:03:13<7:46:27, 38.98s/it]Training MLP on cuda:  28%|██▊       | 283/1000 [3:03:52<7:43:54, 38.82s/it]Training MLP on cuda:  28%|██▊       | 284/1000 [3:04:32<7:47:42, 39.19s/it]Training MLP on cuda:  28%|██▊       | 285/1000 [3:05:10<7:44:18, 38.96s/it]Training MLP on cuda:  29%|██▊       | 286/1000 [3:05:49<7:41:56, 38.82s/it]Training MLP on cuda:  29%|██▊       | 287/1000 [3:06:29<7:45:36, 39.18s/it]Training MLP on cuda:  29%|██▉       | 288/1000 [3:07:07<7:41:49, 38.92s/it]Training MLP on cuda:  29%|██▉       | 289/1000 [3:07:45<7:39:47, 38.80s/it]Training MLP on cuda:  29%|██▉       | 290/1000 [3:08:26<7:43:41, 39.18s/it]Training MLP on cuda:  29%|██▉       | 291/1000 [3:09:04<7:40:44, 38.99s/it]Training MLP on cuda:  29%|██▉       | 292/1000 [3:09:43<7:38:19, 38.84s/it]Training MLP on cuda:  29%|██▉       | 293/1000 [3:10:22<7:41:19, 39.15s/it]Training MLP on cuda:  29%|██▉       | 294/1000 [3:11:01<7:38:21, 38.95s/it]Training MLP on cuda:  30%|██▉       | 295/1000 [3:11:39<7:36:16, 38.83s/it]Training MLP on cuda:  30%|██▉       | 296/1000 [3:12:19<7:39:16, 39.14s/it]Training MLP on cuda:  30%|██▉       | 297/1000 [3:12:58<7:35:51, 38.91s/it]Training MLP on cuda:  30%|██▉       | 298/1000 [3:13:36<7:33:48, 38.79s/it]Training MLP on cuda:  30%|██▉       | 299/1000 [3:14:16<7:37:17, 39.14s/it]Training MLP on cuda:  30%|███       | 300/1000 [3:14:55<7:34:08, 38.93s/it]Training MLP on cuda:  30%|███       | 301/1000 [3:15:33<7:32:32, 38.84s/it]Training MLP on cuda:  30%|███       | 302/1000 [3:16:13<7:35:54, 39.19s/it]Training MLP on cuda:  30%|███       | 303/1000 [3:16:52<7:32:30, 38.95s/it]Training MLP on cuda:  30%|███       | 304/1000 [3:17:30<7:30:35, 38.84s/it]Training MLP on cuda:  30%|███       | 305/1000 [3:18:10<7:33:48, 39.18s/it]Training MLP on cuda:  31%|███       | 306/1000 [3:18:49<7:30:12, 38.92s/it]Training MLP on cuda:  31%|███       | 307/1000 [3:19:27<7:28:06, 38.80s/it]Training MLP on cuda:  31%|███       | 308/1000 [3:20:07<7:31:34, 39.15s/it]Training MLP on cuda:  31%|███       | 309/1000 [3:20:45<7:28:13, 38.92s/it]Training MLP on cuda:  31%|███       | 310/1000 [3:21:24<7:26:30, 38.83s/it]Training MLP on cuda:  31%|███       | 311/1000 [3:22:04<7:29:49, 39.17s/it]Training MLP on cuda:  31%|███       | 312/1000 [3:22:42<7:26:21, 38.93s/it]Training MLP on cuda:  31%|███▏      | 313/1000 [3:23:21<7:24:29, 38.82s/it]Training MLP on cuda:  31%|███▏      | 314/1000 [3:24:01<7:27:50, 39.17s/it]Training MLP on cuda:  32%|███▏      | 315/1000 [3:24:39<7:24:55, 38.97s/it]Training MLP on cuda:  32%|███▏      | 316/1000 [3:25:18<7:22:44, 38.84s/it]Training MLP on cuda:  32%|███▏      | 317/1000 [3:25:58<7:25:18, 39.12s/it]Training MLP on cuda:  32%|███▏      | 318/1000 [3:26:36<7:22:00, 38.89s/it]Training MLP on cuda:  32%|███▏      | 319/1000 [3:27:15<7:20:19, 38.80s/it]Training MLP on cuda:  32%|███▏      | 320/1000 [3:27:55<7:23:33, 39.14s/it]Training MLP on cuda:  32%|███▏      | 321/1000 [3:28:33<7:20:07, 38.89s/it]Training MLP on cuda:  32%|███▏      | 322/1000 [3:29:11<7:18:18, 38.79s/it]Training MLP on cuda:  32%|███▏      | 323/1000 [3:29:51<7:21:38, 39.14s/it]Training MLP on cuda:  32%|███▏      | 324/1000 [3:30:30<7:18:40, 38.94s/it]Training MLP on cuda:  32%|███▎      | 325/1000 [3:31:08<7:16:26, 38.79s/it]Training MLP on cuda:  33%|███▎      | 326/1000 [3:31:48<7:19:28, 39.12s/it]Training MLP on cuda:  33%|███▎      | 327/1000 [3:32:27<7:16:30, 38.92s/it]Training MLP on cuda:  33%|███▎      | 328/1000 [3:33:05<7:14:53, 38.83s/it]Training MLP on cuda:  33%|███▎      | 329/1000 [3:33:45<7:18:02, 39.17s/it]Training MLP on cuda:  33%|███▎      | 330/1000 [3:34:24<7:14:54, 38.95s/it]Training MLP on cuda:  33%|███▎      | 331/1000 [3:35:02<7:12:49, 38.82s/it]Training MLP on cuda:  33%|███▎      | 332/1000 [3:35:42<7:15:51, 39.15s/it]Training MLP on cuda:  33%|███▎      | 333/1000 [3:36:20<7:12:38, 38.92s/it]Training MLP on cuda:  33%|███▎      | 334/1000 [3:36:59<7:10:55, 38.82s/it]Training MLP on cuda:  34%|███▎      | 335/1000 [3:37:39<7:13:57, 39.15s/it]Training MLP on cuda:  34%|███▎      | 336/1000 [3:38:17<7:10:26, 38.90s/it]Training MLP on cuda:  34%|███▎      | 337/1000 [3:38:56<7:08:42, 38.80s/it]Training MLP on cuda:  34%|███▍      | 338/1000 [3:39:36<7:11:44, 39.13s/it]Training MLP on cuda:  34%|███▍      | 339/1000 [3:40:14<7:08:17, 38.88s/it]Training MLP on cuda:  34%|███▍      | 340/1000 [3:40:52<7:06:12, 38.75s/it]Training MLP on cuda:  34%|███▍      | 341/1000 [3:41:32<7:09:10, 39.08s/it]Training MLP on cuda:  34%|███▍      | 342/1000 [3:42:11<7:06:08, 38.86s/it]Training MLP on cuda:  34%|███▍      | 343/1000 [3:42:49<7:04:06, 38.73s/it]Training MLP on cuda:  34%|███▍      | 344/1000 [3:43:29<7:07:04, 39.06s/it]Training MLP on cuda:  34%|███▍      | 345/1000 [3:44:07<7:03:54, 38.83s/it]Training MLP on cuda:  35%|███▍      | 346/1000 [3:44:46<7:02:00, 38.72s/it]Training MLP on cuda:  35%|███▍      | 347/1000 [3:45:26<7:05:25, 39.09s/it]Training MLP on cuda:  35%|███▍      | 348/1000 [3:46:04<7:02:23, 38.87s/it]Training MLP on cuda:  35%|███▍      | 349/1000 [3:46:43<7:00:37, 38.77s/it]Training MLP on cuda:  35%|███▌      | 350/1000 [3:47:22<7:03:30, 39.09s/it]Training MLP on cuda:  35%|███▌      | 351/1000 [3:48:01<7:00:14, 38.85s/it]Training MLP on cuda:  35%|███▌      | 352/1000 [3:48:39<6:58:30, 38.75s/it]Training MLP on cuda:  35%|███▌      | 353/1000 [3:49:19<7:01:39, 39.10s/it]Training MLP on cuda:  35%|███▌      | 354/1000 [3:49:57<6:58:39, 38.88s/it]Training MLP on cuda:  36%|███▌      | 355/1000 [3:50:36<6:56:37, 38.76s/it]Training MLP on cuda:  36%|███▌      | 356/1000 [3:51:16<6:59:51, 39.12s/it]Training MLP on cuda:  36%|███▌      | 357/1000 [3:51:54<6:56:57, 38.91s/it]Training MLP on cuda:  36%|███▌      | 358/1000 [3:52:33<6:55:14, 38.81s/it]Training MLP on cuda:  36%|███▌      | 359/1000 [3:53:13<6:57:58, 39.12s/it]Training MLP on cuda:  36%|███▌      | 360/1000 [3:53:51<6:54:29, 38.86s/it]Training MLP on cuda:  36%|███▌      | 361/1000 [3:54:30<6:53:07, 38.79s/it]Training MLP on cuda:  36%|███▌      | 362/1000 [3:55:10<6:56:28, 39.17s/it]Training MLP on cuda:  36%|███▋      | 363/1000 [3:55:48<6:53:20, 38.93s/it]Training MLP on cuda:  36%|███▋      | 364/1000 [3:56:27<6:51:09, 38.79s/it]Training MLP on cuda:  36%|███▋      | 365/1000 [3:57:06<6:53:42, 39.09s/it]Training MLP on cuda:  37%|███▋      | 366/1000 [3:57:45<6:50:54, 38.89s/it]Training MLP on cuda:  37%|███▋      | 367/1000 [3:58:23<6:49:11, 38.79s/it]Training MLP on cuda:  37%|███▋      | 368/1000 [3:59:03<6:52:09, 39.13s/it]Training MLP on cuda:  37%|███▋      | 369/1000 [3:59:42<6:49:00, 38.89s/it]Training MLP on cuda:  37%|███▋      | 370/1000 [4:00:20<6:47:06, 38.77s/it]Training MLP on cuda:  37%|███▋      | 371/1000 [4:01:00<6:49:57, 39.11s/it]Training MLP on cuda:  37%|███▋      | 372/1000 [4:01:38<6:47:05, 38.89s/it]Training MLP on cuda:  37%|███▋      | 373/1000 [4:02:17<6:45:16, 38.78s/it]Training MLP on cuda:  37%|███▋      | 374/1000 [4:02:57<6:48:03, 39.11s/it]Training MLP on cuda:  38%|███▊      | 375/1000 [4:03:35<6:45:05, 38.89s/it]Training MLP on cuda:  38%|███▊      | 376/1000 [4:04:14<6:43:50, 38.83s/it]Training MLP on cuda:  38%|███▊      | 377/1000 [4:04:54<6:46:55, 39.19s/it]Training MLP on cuda:  38%|███▊      | 378/1000 [4:05:32<6:43:53, 38.96s/it]Training MLP on cuda:  38%|███▊      | 379/1000 [4:06:11<6:41:53, 38.83s/it]Training MLP on cuda:  38%|███▊      | 380/1000 [4:06:51<6:44:39, 39.16s/it]Training MLP on cuda:  38%|███▊      | 381/1000 [4:07:29<6:41:34, 38.92s/it]Training MLP on cuda:  38%|███▊      | 382/1000 [4:08:08<6:39:34, 38.79s/it]Training MLP on cuda:  38%|███▊      | 383/1000 [4:08:47<6:42:21, 39.13s/it]Training MLP on cuda:  38%|███▊      | 384/1000 [4:09:26<6:39:23, 38.90s/it]Training MLP on cuda:  38%|███▊      | 385/1000 [4:10:04<6:37:43, 38.80s/it]Training MLP on cuda:  39%|███▊      | 386/1000 [4:10:44<6:40:32, 39.14s/it]Training MLP on cuda:  39%|███▊      | 387/1000 [4:11:23<6:37:27, 38.90s/it]Training MLP on cuda:  39%|███▉      | 388/1000 [4:12:01<6:35:23, 38.76s/it]Training MLP on cuda:  39%|███▉      | 389/1000 [4:12:41<6:37:53, 39.07s/it]Training MLP on cuda:  39%|███▉      | 390/1000 [4:13:19<6:34:33, 38.81s/it]Training MLP on cuda:  39%|███▉      | 391/1000 [4:13:58<6:32:50, 38.70s/it]Training MLP on cuda:  39%|███▉      | 392/1000 [4:14:37<6:35:42, 39.05s/it]Training MLP on cuda:  39%|███▉      | 393/1000 [4:15:16<6:32:26, 38.79s/it]Training MLP on cuda:  39%|███▉      | 394/1000 [4:15:54<6:30:42, 38.68s/it]Training MLP on cuda:  40%|███▉      | 395/1000 [4:16:34<6:33:31, 39.03s/it]Training MLP on cuda:  40%|███▉      | 396/1000 [4:17:12<6:30:27, 38.79s/it]Training MLP on cuda:  40%|███▉      | 397/1000 [4:17:50<6:28:23, 38.65s/it]Training MLP on cuda:  40%|███▉      | 398/1000 [4:18:30<6:31:15, 39.00s/it]Training MLP on cuda:  40%|███▉      | 399/1000 [4:19:08<6:28:20, 38.77s/it]Training MLP on cuda:  40%|████      | 400/1000 [4:19:47<6:26:31, 38.65s/it]Training MLP on cuda:  40%|████      | 401/1000 [4:20:27<6:29:10, 38.98s/it]Training MLP on cuda:  40%|████      | 402/1000 [4:21:05<6:26:31, 38.78s/it]Training MLP on cuda:  40%|████      | 403/1000 [4:21:43<6:24:24, 38.63s/it]Training MLP on cuda:  40%|████      | 404/1000 [4:22:23<6:27:16, 38.99s/it]Training MLP on cuda:  40%|████      | 405/1000 [4:23:01<6:24:24, 38.76s/it]Training MLP on cuda:  41%|████      | 406/1000 [4:23:40<6:22:37, 38.65s/it]Training MLP on cuda:  41%|████      | 407/1000 [4:24:19<6:25:13, 38.98s/it]Training MLP on cuda:  41%|████      | 408/1000 [4:24:58<6:22:18, 38.75s/it]Training MLP on cuda:  41%|████      | 409/1000 [4:25:36<6:20:54, 38.67s/it]Training MLP on cuda:  41%|████      | 410/1000 [4:26:16<6:23:27, 39.00s/it]Training MLP on cuda:  41%|████      | 411/1000 [4:26:54<6:20:28, 38.76s/it]Training MLP on cuda:  41%|████      | 412/1000 [4:27:32<6:18:29, 38.62s/it]Training MLP on cuda:  41%|████▏     | 413/1000 [4:28:12<6:21:21, 38.98s/it]Training MLP on cuda:  41%|████▏     | 414/1000 [4:28:50<6:18:49, 38.79s/it]Training MLP on cuda:  42%|████▏     | 415/1000 [4:29:29<6:16:57, 38.66s/it]Training MLP on cuda:  42%|████▏     | 416/1000 [4:30:09<6:19:22, 38.98s/it]Training MLP on cuda:  42%|████▏     | 417/1000 [4:30:47<6:17:00, 38.80s/it]Training MLP on cuda:  42%|████▏     | 418/1000 [4:31:25<6:15:21, 38.70s/it]Training MLP on cuda:  42%|████▏     | 419/1000 [4:32:05<6:17:47, 39.02s/it]Training MLP on cuda:  42%|████▏     | 420/1000 [4:32:43<6:15:05, 38.80s/it]Training MLP on cuda:  42%|████▏     | 421/1000 [4:33:22<6:13:12, 38.67s/it]Training MLP on cuda:  42%|████▏     | 422/1000 [4:34:02<6:15:47, 39.01s/it]Training MLP on cuda:  42%|████▏     | 423/1000 [4:34:40<6:12:50, 38.77s/it]Training MLP on cuda:  42%|████▏     | 424/1000 [4:35:18<6:11:06, 38.66s/it]Training MLP on cuda:  42%|████▎     | 425/1000 [4:35:58<6:13:39, 38.99s/it]Training MLP on cuda:  43%|████▎     | 426/1000 [4:36:36<6:10:56, 38.77s/it]Training MLP on cuda:  43%|████▎     | 427/1000 [4:37:15<6:09:09, 38.66s/it]Training MLP on cuda:  43%|████▎     | 428/1000 [4:37:54<6:11:41, 38.99s/it]Training MLP on cuda:  43%|████▎     | 429/1000 [4:38:33<6:08:49, 38.76s/it]Training MLP on cuda:  43%|████▎     | 430/1000 [4:39:11<6:07:02, 38.64s/it]Training MLP on cuda:  43%|████▎     | 431/1000 [4:39:51<6:09:57, 39.01s/it]Training MLP on cuda:  43%|████▎     | 432/1000 [4:40:29<6:07:21, 38.81s/it]Training MLP on cuda:  43%|████▎     | 433/1000 [4:41:08<6:05:32, 38.68s/it]Training MLP on cuda:  43%|████▎     | 434/1000 [4:41:47<6:07:57, 39.01s/it]Training MLP on cuda:  44%|████▎     | 435/1000 [4:42:26<6:05:15, 38.79s/it]Training MLP on cuda:  44%|████▎     | 436/1000 [4:43:04<6:03:44, 38.70s/it]Training MLP on cuda:  44%|████▎     | 437/1000 [4:43:44<6:05:58, 39.00s/it]Training MLP on cuda:  44%|████▍     | 438/1000 [4:44:22<6:03:12, 38.78s/it]Training MLP on cuda:  44%|████▍     | 439/1000 [4:45:01<6:01:35, 38.67s/it]Training MLP on cuda:  44%|████▍     | 440/1000 [4:45:40<6:04:01, 39.00s/it]Training MLP on cuda:  44%|████▍     | 441/1000 [4:46:19<6:01:24, 38.79s/it]Training MLP on cuda:  44%|████▍     | 442/1000 [4:46:57<5:59:55, 38.70s/it]Training MLP on cuda:  44%|████▍     | 443/1000 [4:47:37<6:02:13, 39.02s/it]Training MLP on cuda:  44%|████▍     | 444/1000 [4:48:15<5:59:20, 38.78s/it]Training MLP on cuda:  44%|████▍     | 445/1000 [4:48:53<5:57:35, 38.66s/it]Training MLP on cuda:  45%|████▍     | 446/1000 [4:49:33<6:00:06, 39.00s/it]Training MLP on cuda:  45%|████▍     | 447/1000 [4:50:11<5:57:07, 38.75s/it]Training MLP on cuda:  45%|████▍     | 448/1000 [4:50:50<5:55:26, 38.63s/it]Training MLP on cuda:  45%|████▍     | 449/1000 [4:51:30<5:57:56, 38.98s/it]Training MLP on cuda:  45%|████▌     | 450/1000 [4:52:08<5:55:11, 38.75s/it]Training MLP on cuda:  45%|████▌     | 451/1000 [4:52:46<5:53:39, 38.65s/it]Training MLP on cuda:  45%|████▌     | 452/1000 [4:53:26<5:55:44, 38.95s/it]Training MLP on cuda:  45%|████▌     | 453/1000 [4:54:04<5:53:20, 38.76s/it]Training MLP on cuda:  45%|████▌     | 454/1000 [4:54:43<5:51:42, 38.65s/it]Training MLP on cuda:  46%|████▌     | 455/1000 [4:55:22<5:54:14, 39.00s/it]Training MLP on cuda:  46%|████▌     | 456/1000 [4:56:00<5:51:12, 38.74s/it]Training MLP on cuda:  46%|████▌     | 457/1000 [4:56:39<5:49:37, 38.63s/it]Training MLP on cuda:  46%|████▌     | 458/1000 [4:57:19<5:52:05, 38.98s/it]Training MLP on cuda:  46%|████▌     | 459/1000 [4:57:57<5:49:12, 38.73s/it]Training MLP on cuda:  46%|████▌     | 460/1000 [4:58:35<5:47:43, 38.64s/it]Training MLP on cuda:  46%|████▌     | 461/1000 [4:59:15<5:50:19, 39.00s/it]Training MLP on cuda:  46%|████▌     | 462/1000 [4:59:53<5:47:27, 38.75s/it]Training MLP on cuda:  46%|████▋     | 463/1000 [5:00:32<5:45:51, 38.64s/it]Training MLP on cuda:  46%|████▋     | 464/1000 [5:01:11<5:48:11, 38.98s/it]Training MLP on cuda:  46%|████▋     | 465/1000 [5:01:50<5:45:41, 38.77s/it]Training MLP on cuda:  47%|████▋     | 466/1000 [5:02:28<5:43:53, 38.64s/it]Training MLP on cuda:  47%|████▋     | 467/1000 [5:03:08<5:46:04, 38.96s/it]Training MLP on cuda:  47%|████▋     | 468/1000 [5:03:46<5:43:26, 38.73s/it]Training MLP on cuda:  47%|████▋     | 469/1000 [5:04:24<5:42:06, 38.66s/it]Training MLP on cuda:  47%|████▋     | 470/1000 [5:05:04<5:44:37, 39.01s/it]Training MLP on cuda:  47%|████▋     | 471/1000 [5:05:42<5:41:44, 38.76s/it]Training MLP on cuda:  47%|████▋     | 472/1000 [5:06:21<5:40:23, 38.68s/it]Training MLP on cuda:  47%|████▋     | 473/1000 [5:07:01<5:42:49, 39.03s/it]Training MLP on cuda:  47%|████▋     | 474/1000 [5:07:39<5:40:20, 38.82s/it]Training MLP on cuda:  48%|████▊     | 475/1000 [5:08:17<5:38:26, 38.68s/it]Training MLP on cuda:  48%|████▊     | 476/1000 [5:08:57<5:40:50, 39.03s/it]Training MLP on cuda:  48%|████▊     | 477/1000 [5:09:36<5:38:06, 38.79s/it]Training MLP on cuda:  48%|████▊     | 478/1000 [5:10:14<5:36:26, 38.67s/it]Training MLP on cuda:  48%|████▊     | 479/1000 [5:10:54<5:38:34, 38.99s/it]Training MLP on cuda:  48%|████▊     | 480/1000 [5:11:32<5:36:04, 38.78s/it]Training MLP on cuda:  48%|████▊     | 481/1000 [5:12:10<5:34:33, 38.68s/it]Training MLP on cuda:  48%|████▊     | 482/1000 [5:12:50<5:37:03, 39.04s/it]Training MLP on cuda:  48%|████▊     | 483/1000 [5:13:29<5:34:22, 38.81s/it]Training MLP on cuda:  48%|████▊     | 484/1000 [5:14:07<5:32:32, 38.67s/it]Training MLP on cuda:  48%|████▊     | 485/1000 [5:14:47<5:34:51, 39.01s/it]Training MLP on cuda:  49%|████▊     | 486/1000 [5:15:25<5:32:09, 38.77s/it]Training MLP on cuda:  49%|████▊     | 487/1000 [5:16:03<5:30:23, 38.64s/it]Training MLP on cuda:  49%|████▉     | 488/1000 [5:16:43<5:32:40, 38.98s/it]Training MLP on cuda:  49%|████▉     | 489/1000 [5:17:21<5:29:59, 38.75s/it]Training MLP on cuda:  49%|████▉     | 490/1000 [5:18:00<5:28:24, 38.64s/it]Training MLP on cuda:  49%|████▉     | 491/1000 [5:18:39<5:30:52, 39.00s/it]Training MLP on cuda:  49%|████▉     | 492/1000 [5:19:18<5:28:23, 38.79s/it]Training MLP on cuda:  49%|████▉     | 493/1000 [5:19:56<5:26:37, 38.65s/it]Training MLP on cuda:  49%|████▉     | 494/1000 [5:20:36<5:28:56, 39.00s/it]Training MLP on cuda:  50%|████▉     | 495/1000 [5:21:14<5:26:32, 38.80s/it]Training MLP on cuda:  50%|████▉     | 496/1000 [5:21:53<5:24:56, 38.68s/it]Training MLP on cuda:  50%|████▉     | 497/1000 [5:22:32<5:27:02, 39.01s/it]Training MLP on cuda:  50%|████▉     | 498/1000 [5:23:11<5:24:18, 38.76s/it]Training MLP on cuda:  50%|████▉     | 499/1000 [5:23:49<5:22:37, 38.64s/it]Training MLP on cuda:  50%|█████     | 500/1000 [5:24:29<5:24:49, 38.98s/it]Training MLP on cuda:  50%|█████     | 501/1000 [5:25:07<5:22:13, 38.74s/it]Training MLP on cuda:  50%|█████     | 502/1000 [5:25:45<5:20:40, 38.64s/it]Training MLP on cuda:  50%|█████     | 503/1000 [5:26:25<5:22:52, 38.98s/it]Training MLP on cuda:  50%|█████     | 504/1000 [5:27:03<5:20:13, 38.74s/it]Training MLP on cuda:  50%|█████     | 505/1000 [5:27:42<5:18:39, 38.63s/it]Training MLP on cuda:  51%|█████     | 506/1000 [5:28:21<5:20:53, 38.97s/it]Training MLP on cuda:  51%|█████     | 507/1000 [5:29:00<5:18:13, 38.73s/it]Training MLP on cuda:  51%|█████     | 508/1000 [5:29:38<5:16:49, 38.64s/it]Training MLP on cuda:  51%|█████     | 509/1000 [5:30:18<5:19:06, 39.00s/it]Training MLP on cuda:  51%|█████     | 510/1000 [5:30:56<5:16:51, 38.80s/it]Training MLP on cuda:  51%|█████     | 511/1000 [5:31:35<5:15:19, 38.69s/it]Training MLP on cuda:  51%|█████     | 512/1000 [5:32:14<5:17:16, 39.01s/it]Training MLP on cuda:  51%|█████▏    | 513/1000 [5:32:53<5:14:39, 38.77s/it]Training MLP on cuda:  51%|█████▏    | 514/1000 [5:33:31<5:13:28, 38.70s/it]Training MLP on cuda:  52%|█████▏    | 515/1000 [5:34:11<5:15:34, 39.04s/it]Training MLP on cuda:  52%|█████▏    | 516/1000 [5:34:49<5:13:03, 38.81s/it]Training MLP on cuda:  52%|█████▏    | 517/1000 [5:35:28<5:11:36, 38.71s/it]Training MLP on cuda:  52%|█████▏    | 518/1000 [5:36:08<5:13:52, 39.07s/it]Training MLP on cuda:  52%|█████▏    | 519/1000 [5:36:46<5:11:35, 38.87s/it]Training MLP on cuda:  52%|█████▏    | 520/1000 [5:37:24<5:10:01, 38.75s/it]Training MLP on cuda:  52%|█████▏    | 521/1000 [5:38:04<5:11:45, 39.05s/it]Training MLP on cuda:  52%|█████▏    | 522/1000 [5:38:42<5:09:18, 38.82s/it]Training MLP on cuda:  52%|█████▏    | 523/1000 [5:39:21<5:07:59, 38.74s/it]Training MLP on cuda:  52%|█████▏    | 524/1000 [5:40:01<5:09:56, 39.07s/it]Training MLP on cuda:  52%|█████▎    | 525/1000 [5:40:39<5:07:13, 38.81s/it]Training MLP on cuda:  53%|█████▎    | 526/1000 [5:41:17<5:05:35, 38.68s/it]Training MLP on cuda:  53%|█████▎    | 527/1000 [5:41:57<5:07:43, 39.03s/it]Training MLP on cuda:  53%|█████▎    | 528/1000 [5:42:36<5:05:15, 38.80s/it]Training MLP on cuda:  53%|█████▎    | 529/1000 [5:43:14<5:03:49, 38.70s/it]Training MLP on cuda:  53%|█████▎    | 530/1000 [5:43:54<5:05:39, 39.02s/it]Training MLP on cuda:  53%|█████▎    | 531/1000 [5:44:32<5:03:17, 38.80s/it]Training MLP on cuda:  53%|█████▎    | 532/1000 [5:45:11<5:01:59, 38.72s/it]Training MLP on cuda:  53%|█████▎    | 533/1000 [5:45:50<5:03:51, 39.04s/it]Training MLP on cuda:  53%|█████▎    | 534/1000 [5:46:29<5:01:19, 38.80s/it]Training MLP on cuda:  54%|█████▎    | 535/1000 [5:47:07<4:59:34, 38.65s/it]Training MLP on cuda:  54%|█████▎    | 536/1000 [5:47:47<5:01:38, 39.01s/it]Training MLP on cuda:  54%|█████▎    | 537/1000 [5:48:25<4:59:48, 38.85s/it]Training MLP on cuda:  54%|█████▍    | 538/1000 [5:49:04<4:58:06, 38.71s/it]Training MLP on cuda:  54%|█████▍    | 539/1000 [5:49:43<4:59:47, 39.02s/it]Training MLP on cuda:  54%|█████▍    | 540/1000 [5:50:22<4:57:28, 38.80s/it]Training MLP on cuda:  54%|█████▍    | 541/1000 [5:51:00<4:55:54, 38.68s/it]Training MLP on cuda:  54%|█████▍    | 542/1000 [5:51:40<4:57:50, 39.02s/it]Training MLP on cuda:  54%|█████▍    | 543/1000 [5:52:18<4:55:32, 38.80s/it]Training MLP on cuda:  54%|█████▍    | 544/1000 [5:52:57<4:54:06, 38.70s/it]Training MLP on cuda:  55%|█████▍    | 545/1000 [5:53:37<4:56:17, 39.07s/it]Training MLP on cuda:  55%|█████▍    | 546/1000 [5:54:15<4:53:45, 38.82s/it]Training MLP on cuda:  55%|█████▍    | 547/1000 [5:54:53<4:52:05, 38.69s/it]Training MLP on cuda:  55%|█████▍    | 548/1000 [5:55:33<4:53:59, 39.03s/it]Training MLP on cuda:  55%|█████▍    | 549/1000 [5:56:11<4:51:26, 38.77s/it]Training MLP on cuda:  55%|█████▌    | 550/1000 [5:56:50<4:49:55, 38.66s/it]Training MLP on cuda:  55%|█████▌    | 551/1000 [5:57:29<4:51:53, 39.01s/it]Training MLP on cuda:  55%|█████▌    | 552/1000 [5:58:08<4:49:31, 38.78s/it]Training MLP on cuda:  55%|█████▌    | 553/1000 [5:58:46<4:47:54, 38.65s/it]Training MLP on cuda:  55%|█████▌    | 554/1000 [5:59:26<4:49:48, 38.99s/it]Training MLP on cuda:  56%|█████▌    | 555/1000 [6:00:04<4:47:41, 38.79s/it]Training MLP on cuda:  56%|█████▌    | 556/1000 [6:00:42<4:46:07, 38.67s/it]Training MLP on cuda:  56%|█████▌    | 557/1000 [6:01:22<4:48:01, 39.01s/it]Training MLP on cuda:  56%|█████▌    | 558/1000 [6:02:01<4:46:03, 38.83s/it]Training MLP on cuda:  56%|█████▌    | 559/1000 [6:02:39<4:44:38, 38.73s/it]Training MLP on cuda:  56%|█████▌    | 560/1000 [6:03:19<4:46:15, 39.04s/it]Training MLP on cuda:  56%|█████▌    | 561/1000 [6:03:57<4:43:54, 38.80s/it]Training MLP on cuda:  56%|█████▌    | 562/1000 [6:04:36<4:42:20, 38.68s/it]Training MLP on cuda:  56%|█████▋    | 563/1000 [6:05:15<4:44:13, 39.02s/it]Training MLP on cuda:  56%|█████▋    | 564/1000 [6:05:54<4:41:59, 38.81s/it]Training MLP on cuda:  56%|█████▋    | 565/1000 [6:06:32<4:40:26, 38.68s/it]Training MLP on cuda:  57%|█████▋    | 566/1000 [6:07:12<4:42:20, 39.03s/it]Training MLP on cuda:  57%|█████▋    | 567/1000 [6:07:50<4:40:04, 38.81s/it]Training MLP on cuda:  57%|█████▋    | 568/1000 [6:08:29<4:38:25, 38.67s/it]Training MLP on cuda:  57%|█████▋    | 569/1000 [6:09:08<4:40:18, 39.02s/it]Training MLP on cuda:  57%|█████▋    | 570/1000 [6:09:47<4:37:57, 38.78s/it]Training MLP on cuda:  57%|█████▋    | 571/1000 [6:10:25<4:36:25, 38.66s/it]Training MLP on cuda:  57%|█████▋    | 572/1000 [6:11:05<4:38:17, 39.01s/it]Training MLP on cuda:  57%|█████▋    | 573/1000 [6:11:43<4:36:03, 38.79s/it]Training MLP on cuda:  57%|█████▋    | 574/1000 [6:12:22<4:34:32, 38.67s/it]Training MLP on cuda:  57%|█████▊    | 575/1000 [6:13:01<4:36:19, 39.01s/it]Training MLP on cuda:  58%|█████▊    | 576/1000 [6:13:40<4:34:03, 38.78s/it]Training MLP on cuda:  58%|█████▊    | 577/1000 [6:14:18<4:32:37, 38.67s/it]Training MLP on cuda:  58%|█████▊    | 578/1000 [6:14:58<4:34:18, 39.00s/it]Training MLP on cuda:  58%|█████▊    | 579/1000 [6:15:36<4:32:07, 38.78s/it]Training MLP on cuda:  58%|█████▊    | 580/1000 [6:16:15<4:30:50, 38.69s/it]Training MLP on cuda:  58%|█████▊    | 581/1000 [6:16:54<4:32:36, 39.04s/it]Training MLP on cuda:  58%|█████▊    | 582/1000 [6:17:33<4:30:29, 38.83s/it]Training MLP on cuda:  58%|█████▊    | 583/1000 [6:18:11<4:28:43, 38.67s/it]Training MLP on cuda:  58%|█████▊    | 584/1000 [6:18:51<4:30:34, 39.02s/it]Training MLP on cuda:  58%|█████▊    | 585/1000 [6:19:29<4:28:27, 38.81s/it]Training MLP on cuda:  59%|█████▊    | 586/1000 [6:20:08<4:26:58, 38.69s/it]Training MLP on cuda:  59%|█████▊    | 587/1000 [6:20:47<4:28:39, 39.03s/it]Training MLP on cuda:  59%|█████▉    | 588/1000 [6:21:26<4:26:31, 38.81s/it]Training MLP on cuda:  59%|█████▉    | 589/1000 [6:22:04<4:25:05, 38.70s/it]Training MLP on cuda:  59%|█████▉    | 590/1000 [6:22:44<4:26:39, 39.02s/it]Training MLP on cuda:  59%|█████▉    | 591/1000 [6:23:22<4:24:31, 38.81s/it]Training MLP on cuda:  59%|█████▉    | 592/1000 [6:24:01<4:23:02, 38.68s/it]Training MLP on cuda:  59%|█████▉    | 593/1000 [6:24:40<4:24:43, 39.03s/it]Training MLP on cuda:  59%|█████▉    | 594/1000 [6:25:19<4:22:33, 38.80s/it]Training MLP on cuda:  60%|█████▉    | 595/1000 [6:25:57<4:21:21, 38.72s/it]Training MLP on cuda:  60%|█████▉    | 596/1000 [6:26:37<4:22:39, 39.01s/it]Training MLP on cuda:  60%|█████▉    | 597/1000 [6:27:15<4:20:30, 38.79s/it]Training MLP on cuda:  60%|█████▉    | 598/1000 [6:27:54<4:19:11, 38.69s/it]Training MLP on cuda:  60%|█████▉    | 599/1000 [6:28:33<4:20:52, 39.03s/it]Training MLP on cuda:  60%|██████    | 600/1000 [6:29:12<4:18:37, 38.79s/it]Training MLP on cuda:  60%|██████    | 601/1000 [6:29:50<4:17:03, 38.65s/it]Training MLP on cuda:  60%|██████    | 602/1000 [6:30:30<4:18:36, 38.99s/it]Training MLP on cuda:  60%|██████    | 603/1000 [6:31:08<4:16:45, 38.80s/it]Training MLP on cuda:  60%|██████    | 604/1000 [6:31:47<4:15:20, 38.69s/it]Training MLP on cuda:  60%|██████    | 605/1000 [6:32:26<4:16:48, 39.01s/it]Training MLP on cuda:  61%|██████    | 606/1000 [6:33:05<4:14:50, 38.81s/it]Training MLP on cuda:  61%|██████    | 607/1000 [6:33:43<4:13:32, 38.71s/it]Training MLP on cuda:  61%|██████    | 608/1000 [6:34:23<4:15:19, 39.08s/it]Training MLP on cuda:  61%|██████    | 609/1000 [6:35:01<4:13:08, 38.85s/it]Training MLP on cuda:  61%|██████    | 610/1000 [6:35:40<4:11:52, 38.75s/it]Training MLP on cuda:  61%|██████    | 611/1000 [6:36:20<4:13:25, 39.09s/it]Training MLP on cuda:  61%|██████    | 612/1000 [6:36:58<4:11:17, 38.86s/it]Training MLP on cuda:  61%|██████▏   | 613/1000 [6:37:37<4:09:41, 38.71s/it]Training MLP on cuda:  61%|██████▏   | 614/1000 [6:38:16<4:11:15, 39.06s/it]Training MLP on cuda:  62%|██████▏   | 615/1000 [6:38:55<4:09:11, 38.84s/it]Training MLP on cuda:  62%|██████▏   | 616/1000 [6:39:33<4:07:46, 38.72s/it]Training MLP on cuda:  62%|██████▏   | 617/1000 [6:40:13<4:09:05, 39.02s/it]Training MLP on cuda:  62%|██████▏   | 618/1000 [6:40:51<4:06:57, 38.79s/it]Training MLP on cuda:  62%|██████▏   | 619/1000 [6:41:30<4:05:41, 38.69s/it]Training MLP on cuda:  62%|██████▏   | 620/1000 [6:42:09<4:07:05, 39.01s/it]Training MLP on cuda:  62%|██████▏   | 621/1000 [6:42:48<4:05:17, 38.83s/it]Training MLP on cuda:  62%|██████▏   | 622/1000 [6:43:26<4:04:00, 38.73s/it]Training MLP on cuda:  62%|██████▏   | 623/1000 [6:44:06<4:05:20, 39.05s/it]Training MLP on cuda:  62%|██████▏   | 624/1000 [6:44:44<4:03:15, 38.82s/it]Training MLP on cuda:  62%|██████▎   | 625/1000 [6:45:23<4:02:01, 38.73s/it]Training MLP on cuda:  63%|██████▎   | 626/1000 [6:46:03<4:03:24, 39.05s/it]Training MLP on cuda:  63%|██████▎   | 627/1000 [6:46:41<4:01:19, 38.82s/it]Training MLP on cuda:  63%|██████▎   | 628/1000 [6:47:19<4:00:00, 38.71s/it]Training MLP on cuda:  63%|██████▎   | 629/1000 [6:47:59<4:01:41, 39.09s/it]Training MLP on cuda:  63%|██████▎   | 630/1000 [6:48:38<3:59:54, 38.91s/it]Training MLP on cuda:  63%|██████▎   | 631/1000 [6:49:16<3:58:36, 38.80s/it]Training MLP on cuda:  63%|██████▎   | 632/1000 [6:49:56<4:00:16, 39.18s/it]Training MLP on cuda:  63%|██████▎   | 633/1000 [6:50:35<3:58:26, 38.98s/it]Training MLP on cuda:  63%|██████▎   | 634/1000 [6:51:14<3:57:04, 38.86s/it]Training MLP on cuda:  64%|██████▎   | 635/1000 [6:51:53<3:58:08, 39.15s/it]Training MLP on cuda:  64%|██████▎   | 636/1000 [6:52:32<3:55:56, 38.89s/it]Training MLP on cuda:  64%|██████▎   | 637/1000 [6:53:10<3:54:33, 38.77s/it]Training MLP on cuda:  64%|██████▍   | 638/1000 [6:53:50<3:56:03, 39.13s/it]Training MLP on cuda:  64%|██████▍   | 639/1000 [6:54:28<3:53:58, 38.89s/it]Training MLP on cuda:  64%|██████▍   | 640/1000 [6:55:07<3:52:29, 38.75s/it]Training MLP on cuda:  64%|██████▍   | 641/1000 [6:55:47<3:53:47, 39.07s/it]Training MLP on cuda:  64%|██████▍   | 642/1000 [6:56:25<3:51:56, 38.87s/it]Training MLP on cuda:  64%|██████▍   | 643/1000 [6:57:04<3:50:36, 38.76s/it]Training MLP on cuda:  64%|██████▍   | 644/1000 [6:57:43<3:51:59, 39.10s/it]Training MLP on cuda:  64%|██████▍   | 645/1000 [6:58:22<3:49:48, 38.84s/it]Training MLP on cuda:  65%|██████▍   | 646/1000 [6:59:00<3:48:19, 38.70s/it]Training MLP on cuda:  65%|██████▍   | 647/1000 [6:59:40<3:49:51, 39.07s/it]Training MLP on cuda:  65%|██████▍   | 648/1000 [7:00:18<3:47:46, 38.82s/it]Training MLP on cuda:  65%|██████▍   | 649/1000 [7:00:57<3:46:26, 38.71s/it]Training MLP on cuda:  65%|██████▌   | 650/1000 [7:01:37<3:47:44, 39.04s/it]Training MLP on cuda:  65%|██████▌   | 651/1000 [7:02:15<3:45:52, 38.83s/it]Training MLP on cuda:  65%|██████▌   | 652/1000 [7:02:53<3:44:38, 38.73s/it]Training MLP on cuda:  65%|██████▌   | 653/1000 [7:03:33<3:45:50, 39.05s/it]Training MLP on cuda:  65%|██████▌   | 654/1000 [7:04:11<3:43:48, 38.81s/it]Training MLP on cuda:  66%|██████▌   | 655/1000 [7:04:50<3:42:30, 38.70s/it]Training MLP on cuda:  66%|██████▌   | 656/1000 [7:05:30<3:43:51, 39.05s/it]Training MLP on cuda:  66%|██████▌   | 657/1000 [7:06:08<3:41:41, 38.78s/it]Training MLP on cuda:  66%|██████▌   | 658/1000 [7:06:46<3:40:30, 38.68s/it]Training MLP on cuda:  66%|██████▌   | 659/1000 [7:07:26<3:41:37, 39.00s/it]Training MLP on cuda:  66%|██████▌   | 660/1000 [7:08:04<3:39:47, 38.79s/it]Training MLP on cuda:  66%|██████▌   | 661/1000 [7:08:43<3:38:20, 38.64s/it]Training MLP on cuda:  66%|██████▌   | 662/1000 [7:09:22<3:39:40, 38.99s/it]Training MLP on cuda:  66%|██████▋   | 663/1000 [7:10:01<3:37:48, 38.78s/it]Training MLP on cuda:  66%|██████▋   | 664/1000 [7:10:39<3:36:16, 38.62s/it]Training MLP on cuda:  66%|██████▋   | 665/1000 [7:11:19<3:37:31, 38.96s/it]Training MLP on cuda:  67%|██████▋   | 666/1000 [7:11:57<3:35:21, 38.69s/it]Training MLP on cuda:  67%|██████▋   | 667/1000 [7:12:35<3:33:47, 38.52s/it]Training MLP on cuda:  67%|██████▋   | 668/1000 [7:13:14<3:34:42, 38.80s/it]Training MLP on cuda:  67%|██████▋   | 669/1000 [7:13:52<3:32:36, 38.54s/it]Training MLP on cuda:  67%|██████▋   | 670/1000 [7:14:30<3:30:44, 38.32s/it]Training MLP on cuda:  67%|██████▋   | 671/1000 [7:15:09<3:31:09, 38.51s/it]Training MLP on cuda:  67%|██████▋   | 672/1000 [7:15:46<3:28:11, 38.08s/it]Training MLP on cuda:  67%|██████▋   | 673/1000 [7:16:23<3:26:02, 37.81s/it]Training MLP on cuda:  67%|██████▋   | 674/1000 [7:17:02<3:26:23, 37.99s/it]Training MLP on cuda:  68%|██████▊   | 675/1000 [7:17:39<3:24:19, 37.72s/it]Training MLP on cuda:  68%|██████▊   | 676/1000 [7:18:16<3:22:51, 37.57s/it]Training MLP on cuda:  68%|██████▊   | 677/1000 [7:18:54<3:23:37, 37.83s/it]Training MLP on cuda:  68%|██████▊   | 678/1000 [7:19:32<3:21:44, 37.59s/it]Training MLP on cuda:  68%|██████▊   | 679/1000 [7:20:09<3:20:32, 37.48s/it]Training MLP on cuda:  68%|██████▊   | 680/1000 [7:20:47<3:21:35, 37.80s/it]Training MLP on cuda:  68%|██████▊   | 681/1000 [7:21:24<3:19:48, 37.58s/it]Training MLP on cuda:  68%|██████▊   | 682/1000 [7:22:02<3:18:43, 37.50s/it]Training MLP on cuda:  68%|██████▊   | 683/1000 [7:22:40<3:19:31, 37.77s/it]Training MLP on cuda:  68%|██████▊   | 684/1000 [7:23:17<3:17:44, 37.55s/it]Training MLP on cuda:  68%|██████▊   | 685/1000 [7:23:54<3:16:32, 37.44s/it]Training MLP on cuda:  69%|██████▊   | 686/1000 [7:24:33<3:17:40, 37.77s/it]Training MLP on cuda:  69%|██████▊   | 687/1000 [7:25:10<3:15:47, 37.53s/it]Training MLP on cuda:  69%|██████▉   | 688/1000 [7:25:47<3:14:43, 37.45s/it]Training MLP on cuda:  69%|██████▉   | 689/1000 [7:26:25<3:15:40, 37.75s/it]Training MLP on cuda:  69%|██████▉   | 690/1000 [7:27:02<3:13:47, 37.51s/it]Training MLP on cuda:  69%|██████▉   | 691/1000 [7:27:40<3:12:43, 37.42s/it]Training MLP on cuda:  69%|██████▉   | 692/1000 [7:28:18<3:13:58, 37.79s/it]Training MLP on cuda:  69%|██████▉   | 693/1000 [7:28:55<3:12:04, 37.54s/it]Training MLP on cuda:  69%|██████▉   | 694/1000 [7:29:33<3:11:19, 37.52s/it]Training MLP on cuda:  70%|██████▉   | 695/1000 [7:30:12<3:12:40, 37.90s/it]Training MLP on cuda:  70%|██████▉   | 696/1000 [7:30:49<3:12:02, 37.90s/it]Training MLP on cuda:  70%|██████▉   | 697/1000 [7:31:27<3:11:27, 37.91s/it]Training MLP on cuda:  70%|██████▉   | 698/1000 [7:32:07<3:12:58, 38.34s/it]Training MLP on cuda:  70%|██████▉   | 699/1000 [7:32:45<3:11:33, 38.18s/it]Training MLP on cuda:  70%|███████   | 700/1000 [7:33:22<3:10:23, 38.08s/it]Training MLP on cuda:  70%|███████   | 701/1000 [7:34:02<3:11:37, 38.45s/it]Training MLP on cuda:  70%|███████   | 702/1000 [7:34:40<3:10:09, 38.29s/it]Training MLP on cuda:  70%|███████   | 703/1000 [7:35:18<3:08:59, 38.18s/it]Training MLP on cuda:  70%|███████   | 704/1000 [7:35:57<3:10:03, 38.53s/it]Training MLP on cuda:  70%|███████   | 705/1000 [7:36:35<3:08:21, 38.31s/it]Training MLP on cuda:  71%|███████   | 706/1000 [7:37:13<3:07:17, 38.22s/it]Training MLP on cuda:  71%|███████   | 707/1000 [7:37:52<3:08:19, 38.57s/it]Training MLP on cuda:  71%|███████   | 708/1000 [7:38:30<3:06:25, 38.31s/it]Training MLP on cuda:  71%|███████   | 709/1000 [7:39:08<3:05:14, 38.19s/it]Training MLP on cuda:  71%|███████   | 710/1000 [7:39:47<3:06:11, 38.52s/it]Training MLP on cuda:  71%|███████   | 711/1000 [7:40:25<3:04:23, 38.28s/it]Training MLP on cuda:  71%|███████   | 712/1000 [7:41:03<3:03:13, 38.17s/it]Training MLP on cuda:  71%|███████▏  | 713/1000 [7:41:42<3:04:22, 38.54s/it]Training MLP on cuda:  71%|███████▏  | 714/1000 [7:42:20<3:02:34, 38.30s/it]Training MLP on cuda:  72%|███████▏  | 715/1000 [7:42:58<3:01:33, 38.22s/it]Training MLP on cuda:  72%|███████▏  | 716/1000 [7:43:37<3:02:28, 38.55s/it]Training MLP on cuda:  72%|███████▏  | 717/1000 [7:44:15<3:00:46, 38.33s/it]Training MLP on cuda:  72%|███████▏  | 718/1000 [7:44:53<2:59:29, 38.19s/it]Training MLP on cuda:  72%|███████▏  | 719/1000 [7:45:32<3:00:29, 38.54s/it]Training MLP on cuda:  72%|███████▏  | 720/1000 [7:46:10<2:58:51, 38.33s/it]Training MLP on cuda:  72%|███████▏  | 721/1000 [7:46:48<2:57:51, 38.25s/it]Training MLP on cuda:  72%|███████▏  | 722/1000 [7:47:28<2:59:02, 38.64s/it]Training MLP on cuda:  72%|███████▏  | 723/1000 [7:48:06<2:57:33, 38.46s/it]Training MLP on cuda:  72%|███████▏  | 724/1000 [7:48:44<2:56:36, 38.39s/it]Training MLP on cuda:  72%|███████▎  | 725/1000 [7:49:23<2:57:21, 38.69s/it]Training MLP on cuda:  73%|███████▎  | 726/1000 [7:50:01<2:55:36, 38.45s/it]Training MLP on cuda:  73%|███████▎  | 727/1000 [7:50:39<2:54:30, 38.35s/it]Training MLP on cuda:  73%|███████▎  | 728/1000 [7:51:19<2:55:26, 38.70s/it]Training MLP on cuda:  73%|███████▎  | 729/1000 [7:51:57<2:53:49, 38.48s/it]Training MLP on cuda:  73%|███████▎  | 730/1000 [7:52:35<2:52:34, 38.35s/it]Training MLP on cuda:  73%|███████▎  | 731/1000 [7:53:14<2:53:30, 38.70s/it]Training MLP on cuda:  73%|███████▎  | 732/1000 [7:53:52<2:51:48, 38.46s/it]Training MLP on cuda:  73%|███████▎  | 733/1000 [7:54:30<2:50:33, 38.33s/it]Training MLP on cuda:  73%|███████▎  | 734/1000 [7:55:10<2:51:36, 38.71s/it]Training MLP on cuda:  74%|███████▎  | 735/1000 [7:55:48<2:50:06, 38.52s/it]Training MLP on cuda:  74%|███████▎  | 736/1000 [7:56:26<2:49:03, 38.42s/it]Training MLP on cuda:  74%|███████▎  | 737/1000 [7:57:05<2:49:39, 38.71s/it]Training MLP on cuda:  74%|███████▍  | 738/1000 [7:57:43<2:47:57, 38.46s/it]Training MLP on cuda:  74%|███████▍  | 739/1000 [7:58:21<2:46:48, 38.35s/it]Training MLP on cuda:  74%|███████▍  | 740/1000 [7:59:01<2:47:43, 38.71s/it]Training MLP on cuda:  74%|███████▍  | 741/1000 [7:59:39<2:46:06, 38.48s/it]Training MLP on cuda:  74%|███████▍  | 742/1000 [8:00:17<2:45:02, 38.38s/it]Training MLP on cuda:  74%|███████▍  | 743/1000 [8:00:57<2:45:47, 38.71s/it]Training MLP on cuda:  74%|███████▍  | 744/1000 [8:01:35<2:44:20, 38.52s/it]Training MLP on cuda:  74%|███████▍  | 745/1000 [8:02:13<2:43:14, 38.41s/it]Training MLP on cuda:  75%|███████▍  | 746/1000 [8:02:52<2:43:57, 38.73s/it]Training MLP on cuda:  75%|███████▍  | 747/1000 [8:03:30<2:42:16, 38.48s/it]Training MLP on cuda:  75%|███████▍  | 748/1000 [8:04:08<2:41:14, 38.39s/it]Training MLP on cuda:  75%|███████▍  | 749/1000 [8:04:48<2:42:11, 38.77s/it]Training MLP on cuda:  75%|███████▌  | 750/1000 [8:05:26<2:40:36, 38.54s/it]Training MLP on cuda:  75%|███████▌  | 751/1000 [8:06:04<2:39:27, 38.42s/it]Training MLP on cuda:  75%|███████▌  | 752/1000 [8:06:44<2:40:11, 38.76s/it]Training MLP on cuda:  75%|███████▌  | 753/1000 [8:07:22<2:38:34, 38.52s/it]Training MLP on cuda:  75%|███████▌  | 754/1000 [8:08:00<2:37:24, 38.39s/it]Training MLP on cuda:  76%|███████▌  | 755/1000 [8:08:39<2:38:10, 38.74s/it]Training MLP on cuda:  76%|███████▌  | 756/1000 [8:09:17<2:36:49, 38.56s/it]Training MLP on cuda:  76%|███████▌  | 757/1000 [8:09:56<2:35:47, 38.47s/it]Training MLP on cuda:  76%|███████▌  | 758/1000 [8:10:35<2:36:23, 38.78s/it]Training MLP on cuda:  76%|███████▌  | 759/1000 [8:11:13<2:34:40, 38.51s/it]Training MLP on cuda:  76%|███████▌  | 760/1000 [8:11:51<2:33:41, 38.42s/it]Training MLP on cuda:  76%|███████▌  | 761/1000 [8:12:31<2:34:24, 38.76s/it]Training MLP on cuda:  76%|███████▌  | 762/1000 [8:13:09<2:32:56, 38.56s/it]Training MLP on cuda:  76%|███████▋  | 763/1000 [8:13:47<2:31:55, 38.46s/it]Training MLP on cuda:  76%|███████▋  | 764/1000 [8:14:27<2:32:28, 38.76s/it]Training MLP on cuda:  76%|███████▋  | 765/1000 [8:15:05<2:30:55, 38.53s/it]Training MLP on cuda:  77%|███████▋  | 766/1000 [8:15:43<2:29:48, 38.41s/it]Training MLP on cuda:  77%|███████▋  | 767/1000 [8:16:22<2:30:26, 38.74s/it]Training MLP on cuda:  77%|███████▋  | 768/1000 [8:17:00<2:28:43, 38.46s/it]Training MLP on cuda:  77%|███████▋  | 769/1000 [8:17:38<2:27:47, 38.39s/it]Training MLP on cuda:  77%|███████▋  | 770/1000 [8:18:18<2:28:30, 38.74s/it]Training MLP on cuda:  77%|███████▋  | 771/1000 [8:18:56<2:26:50, 38.48s/it]Training MLP on cuda:  77%|███████▋  | 772/1000 [8:19:34<2:25:50, 38.38s/it]Training MLP on cuda:  77%|███████▋  | 773/1000 [8:20:13<2:26:24, 38.70s/it]Training MLP on cuda:  77%|███████▋  | 774/1000 [8:20:51<2:24:53, 38.47s/it]Training MLP on cuda:  78%|███████▊  | 775/1000 [8:21:29<2:23:49, 38.35s/it]Training MLP on cuda:  78%|███████▊  | 776/1000 [8:22:09<2:24:16, 38.64s/it]Training MLP on cuda:  78%|███████▊  | 777/1000 [8:22:47<2:22:59, 38.47s/it]Training MLP on cuda:  78%|███████▊  | 778/1000 [8:23:25<2:21:43, 38.30s/it]Training MLP on cuda:  78%|███████▊  | 779/1000 [8:24:04<2:22:15, 38.62s/it]Training MLP on cuda:  78%|███████▊  | 780/1000 [8:24:42<2:20:44, 38.38s/it]Training MLP on cuda:  78%|███████▊  | 781/1000 [8:25:20<2:19:43, 38.28s/it]Training MLP on cuda:  78%|███████▊  | 782/1000 [8:25:59<2:20:22, 38.64s/it]Training MLP on cuda:  78%|███████▊  | 783/1000 [8:26:37<2:18:59, 38.43s/it]Training MLP on cuda:  78%|███████▊  | 784/1000 [8:27:15<2:17:59, 38.33s/it]Training MLP on cuda:  78%|███████▊  | 785/1000 [8:27:55<2:18:37, 38.69s/it]Training MLP on cuda:  79%|███████▊  | 786/1000 [8:28:33<2:17:16, 38.49s/it]Training MLP on cuda:  79%|███████▊  | 787/1000 [8:29:11<2:16:15, 38.38s/it]Training MLP on cuda:  79%|███████▉  | 788/1000 [8:29:51<2:16:49, 38.72s/it]Training MLP on cuda:  79%|███████▉  | 789/1000 [8:30:28<2:15:17, 38.47s/it]Training MLP on cuda:  79%|███████▉  | 790/1000 [8:31:07<2:14:18, 38.37s/it]Training MLP on cuda:  79%|███████▉  | 791/1000 [8:31:46<2:14:49, 38.70s/it]Training MLP on cuda:  79%|███████▉  | 792/1000 [8:32:24<2:13:21, 38.47s/it]Training MLP on cuda:  79%|███████▉  | 793/1000 [8:33:02<2:12:11, 38.32s/it]Training MLP on cuda:  79%|███████▉  | 794/1000 [8:33:42<2:12:50, 38.69s/it]Training MLP on cuda:  80%|███████▉  | 795/1000 [8:34:19<2:11:26, 38.47s/it]Training MLP on cuda:  80%|███████▉  | 796/1000 [8:34:58<2:10:24, 38.36s/it]Training MLP on cuda:  80%|███████▉  | 797/1000 [8:35:37<2:10:50, 38.67s/it]Training MLP on cuda:  80%|███████▉  | 798/1000 [8:36:15<2:09:23, 38.43s/it]Training MLP on cuda:  80%|███████▉  | 799/1000 [8:36:53<2:08:24, 38.33s/it]Training MLP on cuda:  80%|████████  | 800/1000 [8:37:32<2:08:58, 38.69s/it]Training MLP on cuda:  80%|████████  | 801/1000 [8:38:11<2:07:40, 38.49s/it]Training MLP on cuda:  80%|████████  | 802/1000 [8:38:49<2:06:42, 38.40s/it]Training MLP on cuda:  80%|████████  | 803/1000 [8:39:28<2:07:12, 38.74s/it]Training MLP on cuda:  80%|████████  | 804/1000 [8:40:06<2:05:39, 38.47s/it]Training MLP on cuda:  80%|████████  | 805/1000 [8:40:44<2:04:37, 38.34s/it]Training MLP on cuda:  81%|████████  | 806/1000 [8:41:24<2:05:11, 38.72s/it]Training MLP on cuda:  81%|████████  | 807/1000 [8:42:02<2:03:54, 38.52s/it]Training MLP on cuda:  81%|████████  | 808/1000 [8:42:40<2:02:54, 38.41s/it]Training MLP on cuda:  81%|████████  | 809/1000 [8:43:19<2:03:20, 38.75s/it]Training MLP on cuda:  81%|████████  | 810/1000 [8:43:58<2:02:08, 38.57s/it]Training MLP on cuda:  81%|████████  | 811/1000 [8:44:35<2:00:28, 38.25s/it]Training MLP on cuda:  81%|████████  | 812/1000 [8:45:14<2:00:26, 38.44s/it]Training MLP on cuda:  81%|████████▏ | 813/1000 [8:45:51<1:58:40, 38.08s/it]Training MLP on cuda:  81%|████████▏ | 814/1000 [8:46:29<1:57:29, 37.90s/it]Training MLP on cuda:  82%|████████▏ | 815/1000 [8:47:07<1:57:39, 38.16s/it]Training MLP on cuda:  82%|████████▏ | 816/1000 [8:47:45<1:56:13, 37.90s/it]Training MLP on cuda:  82%|████████▏ | 817/1000 [8:48:22<1:55:06, 37.74s/it]Training MLP on cuda:  82%|████████▏ | 818/1000 [8:49:01<1:55:19, 38.02s/it]Training MLP on cuda:  82%|████████▏ | 819/1000 [8:49:38<1:53:57, 37.77s/it]Training MLP on cuda:  82%|████████▏ | 820/1000 [8:50:15<1:52:59, 37.66s/it]Training MLP on cuda:  82%|████████▏ | 821/1000 [8:50:54<1:53:22, 38.00s/it]Training MLP on cuda:  82%|████████▏ | 822/1000 [8:51:31<1:51:56, 37.73s/it]Training MLP on cuda:  82%|████████▏ | 823/1000 [8:52:09<1:50:57, 37.61s/it]Training MLP on cuda:  82%|████████▏ | 824/1000 [8:52:47<1:51:22, 37.97s/it]Training MLP on cuda:  82%|████████▎ | 825/1000 [8:53:25<1:50:02, 37.73s/it]Training MLP on cuda:  83%|████████▎ | 826/1000 [8:54:02<1:49:01, 37.59s/it]Training MLP on cuda:  83%|████████▎ | 827/1000 [8:54:41<1:49:22, 37.94s/it]Training MLP on cuda:  83%|████████▎ | 828/1000 [8:55:18<1:48:05, 37.71s/it]Training MLP on cuda:  83%|████████▎ | 829/1000 [8:55:55<1:47:15, 37.63s/it]Training MLP on cuda:  83%|████████▎ | 830/1000 [8:56:34<1:47:34, 37.97s/it]Training MLP on cuda:  83%|████████▎ | 831/1000 [8:57:11<1:46:23, 37.77s/it]Training MLP on cuda:  83%|████████▎ | 832/1000 [8:57:49<1:45:36, 37.72s/it]Training MLP on cuda:  83%|████████▎ | 833/1000 [8:58:28<1:46:09, 38.14s/it]Training MLP on cuda:  83%|████████▎ | 834/1000 [8:59:06<1:45:08, 38.00s/it]Training MLP on cuda:  84%|████████▎ | 835/1000 [8:59:43<1:44:15, 37.91s/it]Training MLP on cuda:  84%|████████▎ | 836/1000 [9:00:23<1:44:43, 38.31s/it]Training MLP on cuda:  84%|████████▎ | 837/1000 [9:01:00<1:43:34, 38.12s/it]Training MLP on cuda:  84%|████████▍ | 838/1000 [9:01:38<1:42:40, 38.03s/it]Training MLP on cuda:  84%|████████▍ | 839/1000 [9:02:17<1:42:43, 38.28s/it]Training MLP on cuda:  84%|████████▍ | 840/1000 [9:02:54<1:41:12, 37.95s/it]Training MLP on cuda:  84%|████████▍ | 841/1000 [9:03:32<1:40:06, 37.78s/it]Training MLP on cuda:  84%|████████▍ | 842/1000 [9:04:10<1:40:07, 38.02s/it]Training MLP on cuda:  84%|████████▍ | 843/1000 [9:04:47<1:38:54, 37.80s/it]Training MLP on cuda:  84%|████████▍ | 844/1000 [9:05:25<1:38:02, 37.71s/it]Training MLP on cuda:  84%|████████▍ | 845/1000 [9:06:04<1:38:13, 38.03s/it]Training MLP on cuda:  85%|████████▍ | 846/1000 [9:06:41<1:36:57, 37.78s/it]Training MLP on cuda:  85%|████████▍ | 847/1000 [9:07:18<1:36:04, 37.68s/it]Training MLP on cuda:  85%|████████▍ | 848/1000 [9:07:57<1:36:16, 38.00s/it]Training MLP on cuda:  85%|████████▍ | 849/1000 [9:08:34<1:35:07, 37.80s/it]Training MLP on cuda:  85%|████████▌ | 850/1000 [9:09:12<1:34:14, 37.69s/it]Training MLP on cuda:  85%|████████▌ | 851/1000 [9:09:51<1:34:18, 37.98s/it]Training MLP on cuda:  85%|████████▌ | 852/1000 [9:10:28<1:33:06, 37.75s/it]Training MLP on cuda:  85%|████████▌ | 853/1000 [9:11:05<1:32:14, 37.65s/it]Training MLP on cuda:  85%|████████▌ | 854/1000 [9:11:44<1:32:29, 38.01s/it]Training MLP on cuda:  86%|████████▌ | 855/1000 [9:12:21<1:31:20, 37.80s/it]Training MLP on cuda:  86%|████████▌ | 856/1000 [9:12:59<1:30:31, 37.72s/it]Training MLP on cuda:  86%|████████▌ | 857/1000 [9:13:38<1:30:36, 38.02s/it]Training MLP on cuda:  86%|████████▌ | 858/1000 [9:14:15<1:29:26, 37.79s/it]Training MLP on cuda:  86%|████████▌ | 859/1000 [9:14:52<1:28:35, 37.70s/it]Training MLP on cuda:  86%|████████▌ | 860/1000 [9:15:31<1:28:45, 38.04s/it]Training MLP on cuda:  86%|████████▌ | 861/1000 [9:16:08<1:27:38, 37.83s/it]Training MLP on cuda:  86%|████████▌ | 862/1000 [9:16:46<1:26:45, 37.72s/it]Training MLP on cuda:  86%|████████▋ | 863/1000 [9:17:25<1:26:54, 38.06s/it]Training MLP on cuda:  86%|████████▋ | 864/1000 [9:18:02<1:25:45, 37.83s/it]Training MLP on cuda:  86%|████████▋ | 865/1000 [9:18:39<1:24:48, 37.69s/it]Training MLP on cuda:  87%|████████▋ | 866/1000 [9:19:18<1:24:56, 38.03s/it]Training MLP on cuda:  87%|████████▋ | 867/1000 [9:19:56<1:23:45, 37.78s/it]Training MLP on cuda:  87%|████████▋ | 868/1000 [9:20:33<1:22:47, 37.64s/it]Training MLP on cuda:  87%|████████▋ | 869/1000 [9:21:12<1:22:53, 37.97s/it]Training MLP on cuda:  87%|████████▋ | 870/1000 [9:21:49<1:21:46, 37.75s/it]Training MLP on cuda:  87%|████████▋ | 871/1000 [9:22:26<1:20:55, 37.64s/it]Training MLP on cuda:  87%|████████▋ | 872/1000 [9:23:05<1:21:03, 37.99s/it]Training MLP on cuda:  87%|████████▋ | 873/1000 [9:23:42<1:19:58, 37.78s/it]Training MLP on cuda:  87%|████████▋ | 874/1000 [9:24:20<1:19:04, 37.66s/it]Training MLP on cuda:  88%|████████▊ | 875/1000 [9:24:58<1:19:02, 37.94s/it]Training MLP on cuda:  88%|████████▊ | 876/1000 [9:25:35<1:17:58, 37.73s/it]Training MLP on cuda:  88%|████████▊ | 877/1000 [9:26:13<1:17:06, 37.62s/it]Training MLP on cuda:  88%|████████▊ | 878/1000 [9:26:51<1:17:06, 37.92s/it]Training MLP on cuda:  88%|████████▊ | 879/1000 [9:27:29<1:16:03, 37.71s/it]Training MLP on cuda:  88%|████████▊ | 880/1000 [9:28:06<1:15:12, 37.60s/it]Training MLP on cuda:  88%|████████▊ | 881/1000 [9:28:45<1:15:10, 37.91s/it]Training MLP on cuda:  88%|████████▊ | 882/1000 [9:29:22<1:14:11, 37.72s/it]Training MLP on cuda:  88%|████████▊ | 883/1000 [9:29:59<1:13:25, 37.66s/it]Training MLP on cuda:  88%|████████▊ | 884/1000 [9:30:38<1:13:27, 37.99s/it]Training MLP on cuda:  88%|████████▊ | 885/1000 [9:31:16<1:12:28, 37.82s/it]Training MLP on cuda:  89%|████████▊ | 886/1000 [9:31:53<1:11:29, 37.63s/it]Training MLP on cuda:  89%|████████▊ | 887/1000 [9:32:31<1:11:23, 37.90s/it]Training MLP on cuda:  89%|████████▉ | 888/1000 [9:33:08<1:10:17, 37.65s/it]Training MLP on cuda:  89%|████████▉ | 889/1000 [9:33:46<1:09:25, 37.52s/it]Training MLP on cuda:  89%|████████▉ | 890/1000 [9:34:24<1:09:21, 37.83s/it]Training MLP on cuda:  89%|████████▉ | 891/1000 [9:35:01<1:08:20, 37.62s/it]Training MLP on cuda:  89%|████████▉ | 892/1000 [9:35:38<1:07:28, 37.49s/it]Training MLP on cuda:  89%|████████▉ | 893/1000 [9:36:17<1:07:26, 37.82s/it]Training MLP on cuda:  89%|████████▉ | 894/1000 [9:36:54<1:06:24, 37.59s/it]Training MLP on cuda:  90%|████████▉ | 895/1000 [9:37:31<1:05:38, 37.51s/it]Training MLP on cuda:  90%|████████▉ | 896/1000 [9:38:10<1:05:35, 37.84s/it]Training MLP on cuda:  90%|████████▉ | 897/1000 [9:38:47<1:04:35, 37.63s/it]Training MLP on cuda:  90%|████████▉ | 898/1000 [9:39:24<1:03:46, 37.52s/it]Training MLP on cuda:  90%|████████▉ | 899/1000 [9:40:03<1:03:41, 37.84s/it]Training MLP on cuda:  90%|█████████ | 900/1000 [9:40:40<1:02:42, 37.62s/it]Training MLP on cuda:  90%|█████████ | 901/1000 [9:41:18<1:01:56, 37.54s/it]Training MLP on cuda:  90%|█████████ | 902/1000 [9:41:56<1:01:47, 37.83s/it]Training MLP on cuda:  90%|█████████ | 902/1000 [9:42:33<1:03:17, 38.75s/it]
Computing expactation over sampled graphs:   0%|          | 0/16 [00:00<?, ?it/s]Computing expactation over sampled graphs:   6%|▋         | 1/16 [42:07<10:31:53, 2527.54s/it]Computing expactation over sampled graphs:  12%|█▎        | 2/16 [1:32:46<11:00:00, 2828.57s/it]Computing expactation over sampled graphs:  19%|█▉        | 3/16 [2:22:14<10:26:38, 2892.17s/it]Computing expactation over sampled graphs:  25%|██▌       | 4/16 [3:06:35<9:20:10, 2800.91s/it] Computing expactation over sampled graphs:  31%|███▏      | 5/16 [3:54:52<8:39:51, 2835.59s/it]Computing expactation over sampled graphs:  38%|███▊      | 6/16 [4:38:48<7:41:15, 2767.56s/it]Computing expactation over sampled graphs:  44%|████▍     | 7/16 [5:41:50<7:44:54, 3099.35s/it]Computing expactation over sampled graphs:  50%|█████     | 8/16 [6:26:36<6:35:42, 2967.82s/it]Computing expactation over sampled graphs:  56%|█████▋    | 9/16 [7:12:17<5:37:57, 2896.81s/it]Computing expactation over sampled graphs:  62%|██████▎   | 10/16 [8:13:22<5:13:23, 3133.95s/it]Computing expactation over sampled graphs:  69%|██████▉   | 11/16 [9:13:30<4:33:15, 3279.06s/it]Computing expactation over sampled graphs:  75%|███████▌  | 12/16 [10:13:07<3:44:38, 3369.69s/it]Computing expactation over sampled graphs:  81%|████████▏ | 13/16 [11:11:25<2:50:25, 3408.57s/it]Computing expactation over sampled graphs:  88%|████████▊ | 14/16 [12:06:52<1:52:47, 3383.94s/it]Computing expactation over sampled graphs:  94%|█████████▍| 15/16 [13:10:05<58:27, 3507.13s/it]  Computing expactation over sampled graphs: 100%|██████████| 16/16 [14:03:22<00:00, 3413.85s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [14:03:22<00:00, 3162.66s/it]
Computing expactation over sampled graphs:   0%|          | 0/16 [00:00<?, ?it/s]Computing expactation over sampled graphs:   6%|▋         | 1/16 [32:10<8:02:40, 1930.68s/it]Computing expactation over sampled graphs:  12%|█▎        | 2/16 [1:01:47<7:09:23, 1840.25s/it]Computing expactation over sampled graphs:  19%|█▉        | 3/16 [1:33:43<6:46:13, 1874.87s/it]Computing expactation over sampled graphs:  25%|██▌       | 4/16 [2:04:07<6:10:57, 1854.83s/it]Computing expactation over sampled graphs:  31%|███▏      | 5/16 [2:35:27<5:41:42, 1863.88s/it]Computing expactation over sampled graphs:  38%|███▊      | 6/16 [3:00:44<4:50:58, 1745.86s/it]Computing expactation over sampled graphs:  44%|████▍     | 7/16 [3:37:56<4:45:41, 1904.65s/it]Computing expactation over sampled graphs:  50%|█████     | 8/16 [4:06:56<4:06:59, 1852.41s/it]Computing expactation over sampled graphs:  56%|█████▋    | 9/16 [4:31:56<3:23:15, 1742.16s/it]Computing expactation over sampled graphs:  62%|██████▎   | 10/16 [5:02:15<2:56:35, 1765.89s/it]Computing expactation over sampled graphs:  69%|██████▉   | 11/16 [5:26:23<2:19:02, 1668.54s/it]Computing expactation over sampled graphs:  75%|███████▌  | 12/16 [5:51:18<1:47:42, 1615.70s/it]Computing expactation over sampled graphs:  81%|████████▏ | 13/16 [6:14:23<1:17:18, 1546.09s/it]Computing expactation over sampled graphs:  88%|████████▊ | 14/16 [6:44:54<54:24, 1632.02s/it]  Computing expactation over sampled graphs:  94%|█████████▍| 15/16 [7:12:59<27:28, 1648.05s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [7:50:32<00:00, 1830.00s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [7:50:32<00:00, 1764.52s/it]
                                               train_acc         test_acc  \
github-GraphSAGE_MLP-attack-0hop         0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_MLP-attack-comb         0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_lira                    0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_rmia                    0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_lset                    0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_graph-lset-MIA          0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_lira-offline            0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_rmia-offline            0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_lset-offline            0.9619 (0.0000)  0.8420 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline  0.9619 (0.0000)  0.8420 (0.0000)   

                                                     AUC      TPR@0.01FPR  \
github-GraphSAGE_MLP-attack-0hop         0.4970 (0.0000)  0.0058 (0.0000)   
github-GraphSAGE_MLP-attack-comb         0.4965 (0.0000)  0.0090 (0.0000)   
github-GraphSAGE_lira                    0.5426 (0.0000)  0.0172 (0.0000)   
github-GraphSAGE_rmia                    0.5466 (0.0000)  0.0268 (0.0000)   
github-GraphSAGE_lset                    0.5466 (0.0000)  0.0268 (0.0000)   
github-GraphSAGE_graph-lset-MIA          0.5867 (0.0000)  0.0340 (0.0000)   
github-GraphSAGE_lira-offline            0.5387 (0.0000)  0.0151 (0.0000)   
github-GraphSAGE_rmia-offline            0.5506 (0.0000)  0.0284 (0.0000)   
github-GraphSAGE_lset-offline            0.5505 (0.0000)  0.0281 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline  0.5924 (0.0000)  0.0363 (0.0000)   

                                        threshold@0.01FPR     TPR@0.001FPR  \
github-GraphSAGE_MLP-attack-0hop          0.0584 (0.0000)  0.0008 (0.0000)   
github-GraphSAGE_MLP-attack-comb          0.1302 (0.0000)  0.0029 (0.0000)   
github-GraphSAGE_lira                     1.7542 (0.0000)  0.0034 (0.0000)   
github-GraphSAGE_rmia                     0.9341 (0.0000)  0.0034 (0.0000)   
github-GraphSAGE_lset                     0.6236 (0.0000)  0.0034 (0.0000)   
github-GraphSAGE_graph-lset-MIA           0.6005 (0.0000)  0.0072 (0.0000)   
github-GraphSAGE_lira-offline            -0.0003 (0.0000)  0.0008 (0.0000)   
github-GraphSAGE_rmia-offline             0.9487 (0.0000)  0.0040 (0.0000)   
github-GraphSAGE_lset-offline             0.6463 (0.0000)  0.0040 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline   0.6221 (0.0000)  0.0064 (0.0000)   

                                        threshold@0.001FPR  
github-GraphSAGE_MLP-attack-0hop           0.0958 (0.0000)  
github-GraphSAGE_MLP-attack-comb           0.1898 (0.0000)  
github-GraphSAGE_lira                      3.3782 (0.0000)  
github-GraphSAGE_rmia                      0.9808 (0.0000)  
github-GraphSAGE_lset                      0.7313 (0.0000)  
github-GraphSAGE_graph-lset-MIA            0.6775 (0.0000)  
github-GraphSAGE_lira-offline             -0.0000 (0.0000)  
github-GraphSAGE_rmia-offline              0.9875 (0.0000)  
github-GraphSAGE_lset-offline              0.7702 (0.0000)  
github-GraphSAGE_graph-lset-MIA-offline    0.7417 (0.0000)  
Done.
