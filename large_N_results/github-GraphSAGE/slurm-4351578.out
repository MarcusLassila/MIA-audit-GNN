This job can be monitored from: https://job.c3se.chalmers.se/alvis/4351578
/usr/share/lmod/lmod/init/bash: /usr/share/lmod/lmod/libexec/addto: /usr/bin/lua: bad interpreter: No such file or directory
no change     /opt/conda/condabin/conda
no change     /opt/conda/bin/conda
no change     /opt/conda/bin/conda-env
no change     /opt/conda/bin/activate
no change     /opt/conda/bin/deactivate
no change     /opt/conda/etc/profile.d/conda.sh
no change     /opt/conda/etc/fish/conf.d/conda.fish
no change     /opt/conda/shell/condabin/Conda.psm1
no change     /opt/conda/shell/condabin/conda-hook.ps1
no change     /opt/conda/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /opt/conda/etc/profile.d/conda.csh
no change     /cephyr/users/lassila/Alvis/.bashrc
No action taken.
Overwriting config seed with seed=3453
Running MIA...

attacks:
  MLP-attack-0hop:
    attack: mlp-attack
    edge_dropout: 0.0
    mlp_attack_queries:
    - 0
    mlp_hidden_dim:
    - 128
    - 64
  MLP-attack-comb:
    attack: mlp-attack
    edge_dropout: 0.5
    mlp_attack_queries:
    - 0
    - 2
    mlp_hidden_dim:
    - 128
    - 64
  graph-lset-MIA:
    attack: graph-lset
    num_sampled_graphs: 16
    prior: 0.5
    sampling_strategy: MIA
  graph-lset-MIA-offline:
    attack: graph-lset
    num_sampled_graphs: 16
    offline: true
    prior: 0.5
    sampling_strategy: MIA
    threshold_scale_factor: 0.9
  lira:
    attack: lira
  lira-offline:
    attack: lira
    offline: true
  lset:
    attack: lset
  lset-offline:
    attack: lset
    offline: true
  rmia:
    Z_frac: 0.5
    attack: rmia
    rmia_gamma: 1
  rmia-offline:
    Z_frac: 0.5
    attack: rmia
    offline: true
    rmia_gamma: 1
batch_size: 524288
datadir: ./data
dataset: github
device: cuda
dropout: 0.0
early_stopping: 0
epochs: 300
epochs_mlp: 1000
frac_target_nodes: 0.2
hidden_dim:
- 64
hidden_dim_mlp:
- 128
hyperparam_search: false
inductive_inference: true
inductive_split: true
lr: 0.001
max_num_nodes: null
model: GraphSAGE
name: github-GraphSAGE
num_audits: 1
num_processes: 1
num_shadow_models: 128
offline: false
optimizer: Adam
pretrain_shadow_models: true
savedir: large_N_results
seed: 3453
target_fpr:
- 0.01
- 0.001
train_frac: 0.5
val_frac: 0.0
weight_decay: 1.0e-05

Dataset properties
#Nodes: 37700
#Edges: 578006
#Features: 128
#Classes: 2
#Class distribution: [0.7417, 0.2583]
Average degree: 15.3317
Fraction isolated nodes: 0.0

Training 128 shadow models:   0%|          | 0/128 [00:00<?, ?it/s]Training 128 shadow models:   1%|          | 1/128 [00:02<05:27,  2.58s/it]Training 128 shadow models:   2%|▏         | 2/128 [00:04<04:33,  2.17s/it]Training 128 shadow models:   2%|▏         | 3/128 [00:06<04:14,  2.04s/it]Training 128 shadow models:   3%|▎         | 4/128 [00:08<04:05,  1.98s/it]Training 128 shadow models:   4%|▍         | 5/128 [00:10<03:58,  1.94s/it]Training 128 shadow models:   5%|▍         | 6/128 [00:11<03:54,  1.92s/it]Training 128 shadow models:   5%|▌         | 7/128 [00:13<03:51,  1.91s/it]Training 128 shadow models:   6%|▋         | 8/128 [00:15<03:48,  1.90s/it]Training 128 shadow models:   7%|▋         | 9/128 [00:17<03:45,  1.89s/it]Training 128 shadow models:   8%|▊         | 10/128 [00:19<03:42,  1.89s/it]Training 128 shadow models:   9%|▊         | 11/128 [00:21<03:40,  1.89s/it]Training 128 shadow models:   9%|▉         | 12/128 [00:23<03:38,  1.88s/it]Training 128 shadow models:  10%|█         | 13/128 [00:25<03:36,  1.88s/it]Training 128 shadow models:  11%|█         | 14/128 [00:27<03:34,  1.88s/it]Training 128 shadow models:  12%|█▏        | 15/128 [00:28<03:32,  1.88s/it]Training 128 shadow models:  12%|█▎        | 16/128 [00:30<03:30,  1.88s/it]Training 128 shadow models:  13%|█▎        | 17/128 [00:32<03:28,  1.88s/it]Training 128 shadow models:  14%|█▍        | 18/128 [00:34<03:26,  1.88s/it]Training 128 shadow models:  15%|█▍        | 19/128 [00:36<03:24,  1.88s/it]Training 128 shadow models:  16%|█▌        | 20/128 [00:38<03:22,  1.88s/it]Training 128 shadow models:  16%|█▋        | 21/128 [00:40<03:20,  1.88s/it]Training 128 shadow models:  17%|█▋        | 22/128 [00:42<03:18,  1.88s/it]Training 128 shadow models:  18%|█▊        | 23/128 [00:43<03:17,  1.88s/it]Training 128 shadow models:  19%|█▉        | 24/128 [00:45<03:15,  1.88s/it]Training 128 shadow models:  20%|█▉        | 25/128 [00:47<03:16,  1.91s/it]Training 128 shadow models:  20%|██        | 26/128 [00:49<03:13,  1.90s/it]Training 128 shadow models:  21%|██        | 27/128 [00:51<03:11,  1.89s/it]Training 128 shadow models:  22%|██▏       | 28/128 [00:53<03:08,  1.89s/it]Training 128 shadow models:  23%|██▎       | 29/128 [00:55<03:06,  1.89s/it]Training 128 shadow models:  23%|██▎       | 30/128 [00:57<03:04,  1.88s/it]Training 128 shadow models:  24%|██▍       | 31/128 [00:59<03:02,  1.88s/it]Training 128 shadow models:  25%|██▌       | 32/128 [01:00<03:00,  1.88s/it]Training 128 shadow models:  26%|██▌       | 33/128 [01:02<02:58,  1.88s/it]Training 128 shadow models:  27%|██▋       | 34/128 [01:04<02:56,  1.88s/it]Training 128 shadow models:  27%|██▋       | 35/128 [01:06<02:55,  1.88s/it]Training 128 shadow models:  28%|██▊       | 36/128 [01:08<02:53,  1.88s/it]Training 128 shadow models:  29%|██▉       | 37/128 [01:10<02:51,  1.88s/it]Training 128 shadow models:  30%|██▉       | 38/128 [01:12<02:49,  1.88s/it]Training 128 shadow models:  30%|███       | 39/128 [01:14<02:47,  1.88s/it]Training 128 shadow models:  31%|███▏      | 40/128 [01:15<02:45,  1.88s/it]Training 128 shadow models:  32%|███▏      | 41/128 [01:17<02:43,  1.88s/it]Training 128 shadow models:  33%|███▎      | 42/128 [01:19<02:41,  1.88s/it]Training 128 shadow models:  34%|███▎      | 43/128 [01:21<02:39,  1.88s/it]Training 128 shadow models:  34%|███▍      | 44/128 [01:23<02:37,  1.88s/it]Training 128 shadow models:  35%|███▌      | 45/128 [01:25<02:36,  1.88s/it]Training 128 shadow models:  36%|███▌      | 46/128 [01:27<02:34,  1.88s/it]Training 128 shadow models:  37%|███▋      | 47/128 [01:29<02:32,  1.88s/it]Training 128 shadow models:  38%|███▊      | 48/128 [01:31<02:30,  1.88s/it]Training 128 shadow models:  38%|███▊      | 49/128 [01:32<02:28,  1.88s/it]Training 128 shadow models:  39%|███▉      | 50/128 [01:34<02:26,  1.88s/it]Training 128 shadow models:  40%|███▉      | 51/128 [01:36<02:25,  1.88s/it]Training 128 shadow models:  41%|████      | 52/128 [01:38<02:23,  1.88s/it]Training 128 shadow models:  41%|████▏     | 53/128 [01:40<02:21,  1.88s/it]Training 128 shadow models:  42%|████▏     | 54/128 [01:42<02:19,  1.88s/it]Training 128 shadow models:  43%|████▎     | 55/128 [01:44<02:17,  1.89s/it]Training 128 shadow models:  44%|████▍     | 56/128 [01:46<02:15,  1.88s/it]Training 128 shadow models:  45%|████▍     | 57/128 [01:48<02:13,  1.88s/it]Training 128 shadow models:  45%|████▌     | 58/128 [01:49<02:11,  1.88s/it]Training 128 shadow models:  46%|████▌     | 59/128 [01:51<02:09,  1.88s/it]Training 128 shadow models:  47%|████▋     | 60/128 [01:53<02:07,  1.88s/it]Training 128 shadow models:  48%|████▊     | 61/128 [01:55<02:06,  1.88s/it]Training 128 shadow models:  48%|████▊     | 62/128 [01:57<02:04,  1.88s/it]Training 128 shadow models:  49%|████▉     | 63/128 [01:59<02:02,  1.88s/it]Training 128 shadow models:  50%|█████     | 64/128 [02:01<02:00,  1.88s/it]Training 128 shadow models:  51%|█████     | 65/128 [02:03<01:58,  1.89s/it]Training 128 shadow models:  52%|█████▏    | 66/128 [02:04<01:56,  1.89s/it]Training 128 shadow models:  52%|█████▏    | 67/128 [02:06<01:55,  1.89s/it]Training 128 shadow models:  53%|█████▎    | 68/128 [02:08<01:53,  1.89s/it]Training 128 shadow models:  54%|█████▍    | 69/128 [02:10<01:51,  1.89s/it]Training 128 shadow models:  55%|█████▍    | 70/128 [02:12<01:49,  1.89s/it]Training 128 shadow models:  55%|█████▌    | 71/128 [02:14<01:47,  1.89s/it]Training 128 shadow models:  56%|█████▋    | 72/128 [02:16<01:45,  1.89s/it]Training 128 shadow models:  57%|█████▋    | 73/128 [02:18<01:43,  1.89s/it]Training 128 shadow models:  58%|█████▊    | 74/128 [02:20<01:41,  1.88s/it]Training 128 shadow models:  59%|█████▊    | 75/128 [02:21<01:39,  1.88s/it]Training 128 shadow models:  59%|█████▉    | 76/128 [02:23<01:37,  1.88s/it]Training 128 shadow models:  60%|██████    | 77/128 [02:25<01:35,  1.88s/it]Training 128 shadow models:  61%|██████    | 78/128 [02:27<01:34,  1.88s/it]Training 128 shadow models:  62%|██████▏   | 79/128 [02:29<01:32,  1.88s/it]Training 128 shadow models:  62%|██████▎   | 80/128 [02:31<01:30,  1.88s/it]Training 128 shadow models:  63%|██████▎   | 81/128 [02:33<01:28,  1.88s/it]Training 128 shadow models:  64%|██████▍   | 82/128 [02:35<01:26,  1.88s/it]Training 128 shadow models:  65%|██████▍   | 83/128 [02:36<01:24,  1.88s/it]Training 128 shadow models:  66%|██████▌   | 84/128 [02:38<01:22,  1.88s/it]Training 128 shadow models:  66%|██████▋   | 85/128 [02:40<01:20,  1.88s/it]Training 128 shadow models:  67%|██████▋   | 86/128 [02:42<01:19,  1.88s/it]Training 128 shadow models:  68%|██████▊   | 87/128 [02:44<01:17,  1.88s/it]Training 128 shadow models:  69%|██████▉   | 88/128 [02:46<01:15,  1.88s/it]Training 128 shadow models:  70%|██████▉   | 89/128 [02:48<01:13,  1.88s/it]Training 128 shadow models:  70%|███████   | 90/128 [02:50<01:11,  1.89s/it]Training 128 shadow models:  71%|███████   | 91/128 [02:52<01:09,  1.89s/it]Training 128 shadow models:  72%|███████▏  | 92/128 [02:53<01:08,  1.89s/it]Training 128 shadow models:  73%|███████▎  | 93/128 [02:55<01:06,  1.89s/it]Training 128 shadow models:  73%|███████▎  | 94/128 [02:57<01:04,  1.89s/it]Training 128 shadow models:  74%|███████▍  | 95/128 [02:59<01:02,  1.89s/it]Training 128 shadow models:  75%|███████▌  | 96/128 [03:01<01:00,  1.89s/it]Training 128 shadow models:  76%|███████▌  | 97/128 [03:03<00:58,  1.89s/it]Training 128 shadow models:  77%|███████▋  | 98/128 [03:05<00:56,  1.89s/it]Training 128 shadow models:  77%|███████▋  | 99/128 [03:07<00:54,  1.89s/it]Training 128 shadow models:  78%|███████▊  | 100/128 [03:09<00:52,  1.89s/it]Training 128 shadow models:  79%|███████▉  | 101/128 [03:10<00:51,  1.89s/it]Training 128 shadow models:  80%|███████▉  | 102/128 [03:12<00:49,  1.89s/it]Training 128 shadow models:  80%|████████  | 103/128 [03:14<00:47,  1.89s/it]Training 128 shadow models:  81%|████████▏ | 104/128 [03:16<00:45,  1.89s/it]Training 128 shadow models:  82%|████████▏ | 105/128 [03:18<00:43,  1.89s/it]Training 128 shadow models:  83%|████████▎ | 106/128 [03:20<00:41,  1.89s/it]Training 128 shadow models:  84%|████████▎ | 107/128 [03:22<00:39,  1.89s/it]Training 128 shadow models:  84%|████████▍ | 108/128 [03:24<00:37,  1.89s/it]Training 128 shadow models:  85%|████████▌ | 109/128 [03:26<00:35,  1.89s/it]Training 128 shadow models:  86%|████████▌ | 110/128 [03:28<00:34,  1.89s/it]Training 128 shadow models:  87%|████████▋ | 111/128 [03:29<00:32,  1.90s/it]Training 128 shadow models:  88%|████████▊ | 112/128 [03:31<00:30,  1.90s/it]Training 128 shadow models:  88%|████████▊ | 113/128 [03:33<00:28,  1.90s/it]Training 128 shadow models:  89%|████████▉ | 114/128 [03:35<00:26,  1.90s/it]Training 128 shadow models:  90%|████████▉ | 115/128 [03:37<00:24,  1.90s/it]Training 128 shadow models:  91%|█████████ | 116/128 [03:39<00:22,  1.89s/it]Training 128 shadow models:  91%|█████████▏| 117/128 [03:41<00:20,  1.89s/it]Training 128 shadow models:  92%|█████████▏| 118/128 [03:43<00:18,  1.89s/it]Training 128 shadow models:  93%|█████████▎| 119/128 [03:45<00:16,  1.89s/it]Training 128 shadow models:  94%|█████████▍| 120/128 [03:46<00:15,  1.89s/it]Training 128 shadow models:  95%|█████████▍| 121/128 [03:48<00:13,  1.89s/it]Training 128 shadow models:  95%|█████████▌| 122/128 [03:50<00:11,  1.88s/it]Training 128 shadow models:  96%|█████████▌| 123/128 [03:52<00:09,  1.88s/it]Training 128 shadow models:  97%|█████████▋| 124/128 [03:54<00:07,  1.88s/it]Training 128 shadow models:  98%|█████████▊| 125/128 [03:56<00:05,  1.88s/it]Training 128 shadow models:  98%|█████████▊| 126/128 [03:58<00:03,  1.88s/it]Training 128 shadow models:  99%|█████████▉| 127/128 [04:00<00:01,  1.88s/it]Training 128 shadow models: 100%|██████████| 128/128 [04:01<00:00,  1.88s/it]Training 128 shadow models: 100%|██████████| 128/128 [04:01<00:00,  1.89s/it]
[I 2025-05-15 03:11:35,343] A new study created in memory with name: no-name-88a7e7df-ee7b-43ed-a37b-d007e4c2d5cc
Tuning interpolation parameter for offline RMIA using optuna
  0%|          | 0/100 [00:00<?, ?it/s]                                         0%|          | 0/100 [00:07<?, ?it/s]Best trial: 0. Best value: 0.546026:   0%|          | 0/100 [00:07<?, ?it/s]Best trial: 0. Best value: 0.546026:   1%|          | 1/100 [00:07<12:28,  7.56s/it]                                                                                    Best trial: 0. Best value: 0.546026:   1%|          | 1/100 [00:15<12:28,  7.56s/it]Best trial: 0. Best value: 0.546026:   1%|          | 1/100 [00:15<12:28,  7.56s/it]Best trial: 0. Best value: 0.546026:   2%|▏         | 2/100 [00:15<12:17,  7.53s/it]                                                                                    Best trial: 0. Best value: 0.546026:   2%|▏         | 2/100 [00:22<12:17,  7.53s/it]Best trial: 0. Best value: 0.546026:   2%|▏         | 2/100 [00:22<12:17,  7.53s/it]Best trial: 0. Best value: 0.546026:   3%|▎         | 3/100 [00:22<12:08,  7.51s/it]                                                                                    Best trial: 0. Best value: 0.546026:   3%|▎         | 3/100 [00:30<12:08,  7.51s/it]Best trial: 0. Best value: 0.546026:   3%|▎         | 3/100 [00:30<12:08,  7.51s/it]Best trial: 0. Best value: 0.546026:   4%|▍         | 4/100 [00:30<12:01,  7.52s/it]                                                                                    Best trial: 0. Best value: 0.546026:   4%|▍         | 4/100 [00:37<12:01,  7.52s/it]Best trial: 0. Best value: 0.546026:   4%|▍         | 4/100 [00:37<12:01,  7.52s/it]Best trial: 0. Best value: 0.546026:   5%|▌         | 5/100 [00:37<12:00,  7.58s/it]                                                                                    Best trial: 0. Best value: 0.546026:   5%|▌         | 5/100 [00:45<12:00,  7.58s/it]Best trial: 0. Best value: 0.546026:   5%|▌         | 5/100 [00:45<12:00,  7.58s/it]Best trial: 0. Best value: 0.546026:   6%|▌         | 6/100 [00:45<11:50,  7.56s/it]                                                                                    Best trial: 0. Best value: 0.546026:   6%|▌         | 6/100 [00:52<11:50,  7.56s/it]Best trial: 0. Best value: 0.546026:   6%|▌         | 6/100 [00:52<11:50,  7.56s/it]Best trial: 0. Best value: 0.546026:   7%|▋         | 7/100 [00:52<11:41,  7.55s/it]                                                                                    Best trial: 0. Best value: 0.546026:   7%|▋         | 7/100 [01:00<11:41,  7.55s/it]Best trial: 0. Best value: 0.546026:   7%|▋         | 7/100 [01:00<11:41,  7.55s/it]Best trial: 0. Best value: 0.546026:   8%|▊         | 8/100 [01:00<11:33,  7.54s/it]                                                                                    Best trial: 0. Best value: 0.546026:   8%|▊         | 8/100 [01:07<11:33,  7.54s/it]Best trial: 0. Best value: 0.546026:   8%|▊         | 8/100 [01:07<11:33,  7.54s/it]Best trial: 0. Best value: 0.546026:   9%|▉         | 9/100 [01:07<11:25,  7.53s/it]                                                                                    Best trial: 0. Best value: 0.546026:   9%|▉         | 9/100 [01:15<11:25,  7.53s/it]Best trial: 0. Best value: 0.546026:   9%|▉         | 9/100 [01:15<11:25,  7.53s/it]Best trial: 0. Best value: 0.546026:  10%|█         | 10/100 [01:15<11:17,  7.52s/it]                                                                                     Best trial: 0. Best value: 0.546026:  10%|█         | 10/100 [01:22<11:17,  7.52s/it]Best trial: 10. Best value: 0.546238:  10%|█         | 10/100 [01:22<11:17,  7.52s/it]Best trial: 10. Best value: 0.546238:  11%|█         | 11/100 [01:22<11:09,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  11%|█         | 11/100 [01:30<11:09,  7.53s/it]Best trial: 10. Best value: 0.546238:  11%|█         | 11/100 [01:30<11:09,  7.53s/it]Best trial: 10. Best value: 0.546238:  12%|█▏        | 12/100 [01:30<11:02,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  12%|█▏        | 12/100 [01:37<11:02,  7.53s/it]Best trial: 10. Best value: 0.546238:  12%|█▏        | 12/100 [01:37<11:02,  7.53s/it]Best trial: 10. Best value: 0.546238:  13%|█▎        | 13/100 [01:37<10:55,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  13%|█▎        | 13/100 [01:45<10:55,  7.53s/it]Best trial: 10. Best value: 0.546238:  13%|█▎        | 13/100 [01:45<10:55,  7.53s/it]Best trial: 10. Best value: 0.546238:  14%|█▍        | 14/100 [01:45<10:47,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  14%|█▍        | 14/100 [01:53<10:47,  7.53s/it]Best trial: 10. Best value: 0.546238:  14%|█▍        | 14/100 [01:53<10:47,  7.53s/it]Best trial: 10. Best value: 0.546238:  15%|█▌        | 15/100 [01:53<10:39,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  15%|█▌        | 15/100 [02:00<10:39,  7.53s/it]Best trial: 10. Best value: 0.546238:  15%|█▌        | 15/100 [02:00<10:39,  7.53s/it]Best trial: 10. Best value: 0.546238:  16%|█▌        | 16/100 [02:00<10:32,  7.53s/it]                                                                                      Best trial: 10. Best value: 0.546238:  16%|█▌        | 16/100 [02:08<10:32,  7.53s/it]Best trial: 16. Best value: 0.546238:  16%|█▌        | 16/100 [02:08<10:32,  7.53s/it]Best trial: 16. Best value: 0.546238:  17%|█▋        | 17/100 [02:08<10:25,  7.53s/it]                                                                                      Best trial: 16. Best value: 0.546238:  17%|█▋        | 17/100 [02:15<10:25,  7.53s/it]Best trial: 16. Best value: 0.546238:  17%|█▋        | 17/100 [02:15<10:25,  7.53s/it]Best trial: 16. Best value: 0.546238:  18%|█▊        | 18/100 [02:15<10:17,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  18%|█▊        | 18/100 [02:23<10:17,  7.54s/it]Best trial: 16. Best value: 0.546238:  18%|█▊        | 18/100 [02:23<10:17,  7.54s/it]Best trial: 16. Best value: 0.546238:  19%|█▉        | 19/100 [02:23<10:14,  7.58s/it]                                                                                      Best trial: 16. Best value: 0.546238:  19%|█▉        | 19/100 [02:30<10:14,  7.58s/it]Best trial: 16. Best value: 0.546238:  19%|█▉        | 19/100 [02:30<10:14,  7.58s/it]Best trial: 16. Best value: 0.546238:  20%|██        | 20/100 [02:30<10:05,  7.56s/it]                                                                                      Best trial: 16. Best value: 0.546238:  20%|██        | 20/100 [02:38<10:05,  7.56s/it]Best trial: 16. Best value: 0.546238:  20%|██        | 20/100 [02:38<10:05,  7.56s/it]Best trial: 16. Best value: 0.546238:  21%|██        | 21/100 [02:38<09:57,  7.56s/it]                                                                                      Best trial: 16. Best value: 0.546238:  21%|██        | 21/100 [02:45<09:57,  7.56s/it]Best trial: 16. Best value: 0.546238:  21%|██        | 21/100 [02:45<09:57,  7.56s/it]Best trial: 16. Best value: 0.546238:  22%|██▏       | 22/100 [02:45<09:49,  7.56s/it]                                                                                      Best trial: 16. Best value: 0.546238:  22%|██▏       | 22/100 [02:53<09:49,  7.56s/it]Best trial: 16. Best value: 0.546238:  22%|██▏       | 22/100 [02:53<09:49,  7.56s/it]Best trial: 16. Best value: 0.546238:  23%|██▎       | 23/100 [02:53<09:41,  7.55s/it]                                                                                      Best trial: 16. Best value: 0.546238:  23%|██▎       | 23/100 [03:01<09:41,  7.55s/it]Best trial: 16. Best value: 0.546238:  23%|██▎       | 23/100 [03:01<09:41,  7.55s/it]Best trial: 16. Best value: 0.546238:  24%|██▍       | 24/100 [03:01<09:33,  7.55s/it]                                                                                      Best trial: 16. Best value: 0.546238:  24%|██▍       | 24/100 [03:08<09:33,  7.55s/it]Best trial: 16. Best value: 0.546238:  24%|██▍       | 24/100 [03:08<09:33,  7.55s/it]Best trial: 16. Best value: 0.546238:  25%|██▌       | 25/100 [03:08<09:25,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  25%|██▌       | 25/100 [03:16<09:25,  7.54s/it]Best trial: 16. Best value: 0.546238:  25%|██▌       | 25/100 [03:16<09:25,  7.54s/it]Best trial: 16. Best value: 0.546238:  26%|██▌       | 26/100 [03:16<09:17,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  26%|██▌       | 26/100 [03:23<09:17,  7.54s/it]Best trial: 16. Best value: 0.546238:  26%|██▌       | 26/100 [03:23<09:17,  7.54s/it]Best trial: 16. Best value: 0.546238:  27%|██▋       | 27/100 [03:23<09:10,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  27%|██▋       | 27/100 [03:31<09:10,  7.54s/it]Best trial: 16. Best value: 0.546238:  27%|██▋       | 27/100 [03:31<09:10,  7.54s/it]Best trial: 16. Best value: 0.546238:  28%|██▊       | 28/100 [03:31<09:02,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  28%|██▊       | 28/100 [03:38<09:02,  7.54s/it]Best trial: 16. Best value: 0.546238:  28%|██▊       | 28/100 [03:38<09:02,  7.54s/it]Best trial: 16. Best value: 0.546238:  29%|██▉       | 29/100 [03:38<08:55,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  29%|██▉       | 29/100 [03:46<08:55,  7.54s/it]Best trial: 16. Best value: 0.546238:  29%|██▉       | 29/100 [03:46<08:55,  7.54s/it]Best trial: 16. Best value: 0.546238:  30%|███       | 30/100 [03:46<08:48,  7.55s/it]                                                                                      Best trial: 16. Best value: 0.546238:  30%|███       | 30/100 [03:53<08:48,  7.55s/it]Best trial: 16. Best value: 0.546238:  30%|███       | 30/100 [03:53<08:48,  7.55s/it]Best trial: 16. Best value: 0.546238:  31%|███       | 31/100 [03:53<08:39,  7.53s/it]                                                                                      Best trial: 16. Best value: 0.546238:  31%|███       | 31/100 [04:01<08:39,  7.53s/it]Best trial: 16. Best value: 0.546238:  31%|███       | 31/100 [04:01<08:39,  7.53s/it]Best trial: 16. Best value: 0.546238:  32%|███▏      | 32/100 [04:01<08:31,  7.53s/it]                                                                                      Best trial: 16. Best value: 0.546238:  32%|███▏      | 32/100 [04:08<08:31,  7.53s/it]Best trial: 16. Best value: 0.546238:  32%|███▏      | 32/100 [04:08<08:31,  7.53s/it]Best trial: 16. Best value: 0.546238:  33%|███▎      | 33/100 [04:08<08:23,  7.52s/it]                                                                                      Best trial: 16. Best value: 0.546238:  33%|███▎      | 33/100 [04:16<08:23,  7.52s/it]Best trial: 16. Best value: 0.546238:  33%|███▎      | 33/100 [04:16<08:23,  7.52s/it]Best trial: 16. Best value: 0.546238:  34%|███▍      | 34/100 [04:16<08:18,  7.56s/it]                                                                                      Best trial: 16. Best value: 0.546238:  34%|███▍      | 34/100 [04:23<08:18,  7.56s/it]Best trial: 16. Best value: 0.546238:  34%|███▍      | 34/100 [04:23<08:18,  7.56s/it]Best trial: 16. Best value: 0.546238:  35%|███▌      | 35/100 [04:23<08:10,  7.54s/it]                                                                                      Best trial: 16. Best value: 0.546238:  35%|███▌      | 35/100 [04:31<08:10,  7.54s/it]Best trial: 16. Best value: 0.546238:  35%|███▌      | 35/100 [04:31<08:10,  7.54s/it]Best trial: 16. Best value: 0.546238:  36%|███▌      | 36/100 [04:31<08:01,  7.53s/it]                                                                                      Best trial: 16. Best value: 0.546238:  36%|███▌      | 36/100 [04:38<08:01,  7.53s/it]Best trial: 16. Best value: 0.546238:  36%|███▌      | 36/100 [04:38<08:01,  7.53s/it]Best trial: 16. Best value: 0.546238:  37%|███▋      | 37/100 [04:38<07:53,  7.52s/it]                                                                                      Best trial: 16. Best value: 0.546238:  37%|███▋      | 37/100 [04:46<07:53,  7.52s/it]Best trial: 16. Best value: 0.546238:  37%|███▋      | 37/100 [04:46<07:53,  7.52s/it]Best trial: 16. Best value: 0.546238:  38%|███▊      | 38/100 [04:46<07:46,  7.52s/it]                                                                                      Best trial: 16. Best value: 0.546238:  38%|███▊      | 38/100 [04:53<07:46,  7.52s/it]Best trial: 16. Best value: 0.546238:  38%|███▊      | 38/100 [04:53<07:46,  7.52s/it]Best trial: 16. Best value: 0.546238:  39%|███▉      | 39/100 [04:53<07:38,  7.51s/it]                                                                                      Best trial: 16. Best value: 0.546238:  39%|███▉      | 39/100 [05:01<07:38,  7.51s/it]Best trial: 16. Best value: 0.546238:  39%|███▉      | 39/100 [05:01<07:38,  7.51s/it]Best trial: 16. Best value: 0.546238:  40%|████      | 40/100 [05:01<07:30,  7.50s/it]                                                                                      Best trial: 16. Best value: 0.546238:  40%|████      | 40/100 [05:08<07:30,  7.50s/it]Best trial: 16. Best value: 0.546238:  40%|████      | 40/100 [05:08<07:30,  7.50s/it]Best trial: 16. Best value: 0.546238:  41%|████      | 41/100 [05:08<07:22,  7.51s/it]                                                                                      Best trial: 16. Best value: 0.546238:  41%|████      | 41/100 [05:16<07:22,  7.51s/it]Best trial: 41. Best value: 0.546251:  41%|████      | 41/100 [05:16<07:22,  7.51s/it]Best trial: 41. Best value: 0.546251:  42%|████▏     | 42/100 [05:16<07:15,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  42%|████▏     | 42/100 [05:23<07:15,  7.50s/it]Best trial: 41. Best value: 0.546251:  42%|████▏     | 42/100 [05:23<07:15,  7.50s/it]Best trial: 41. Best value: 0.546251:  43%|████▎     | 43/100 [05:23<07:07,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  43%|████▎     | 43/100 [05:31<07:07,  7.50s/it]Best trial: 41. Best value: 0.546251:  43%|████▎     | 43/100 [05:31<07:07,  7.50s/it]Best trial: 41. Best value: 0.546251:  44%|████▍     | 44/100 [05:31<06:59,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  44%|████▍     | 44/100 [05:38<06:59,  7.50s/it]Best trial: 41. Best value: 0.546251:  44%|████▍     | 44/100 [05:38<06:59,  7.50s/it]Best trial: 41. Best value: 0.546251:  45%|████▌     | 45/100 [05:38<06:52,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  45%|████▌     | 45/100 [05:46<06:52,  7.50s/it]Best trial: 41. Best value: 0.546251:  45%|████▌     | 45/100 [05:46<06:52,  7.50s/it]Best trial: 41. Best value: 0.546251:  46%|████▌     | 46/100 [05:46<06:45,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  46%|████▌     | 46/100 [05:53<06:45,  7.50s/it]Best trial: 41. Best value: 0.546251:  46%|████▌     | 46/100 [05:53<06:45,  7.50s/it]Best trial: 41. Best value: 0.546251:  47%|████▋     | 47/100 [05:53<06:37,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  47%|████▋     | 47/100 [06:01<06:37,  7.50s/it]Best trial: 41. Best value: 0.546251:  47%|████▋     | 47/100 [06:01<06:37,  7.50s/it]Best trial: 41. Best value: 0.546251:  48%|████▊     | 48/100 [06:01<06:29,  7.50s/it]                                                                                      Best trial: 41. Best value: 0.546251:  48%|████▊     | 48/100 [06:09<06:29,  7.50s/it]Best trial: 41. Best value: 0.546251:  48%|████▊     | 48/100 [06:09<06:29,  7.50s/it]Best trial: 41. Best value: 0.546251:  49%|████▉     | 49/100 [06:09<06:25,  7.55s/it]                                                                                      Best trial: 41. Best value: 0.546251:  49%|████▉     | 49/100 [06:16<06:25,  7.55s/it]Best trial: 49. Best value: 0.546276:  49%|████▉     | 49/100 [06:16<06:25,  7.55s/it]Best trial: 49. Best value: 0.546276:  50%|█████     | 50/100 [06:16<06:17,  7.54s/it]                                                                                      Best trial: 49. Best value: 0.546276:  50%|█████     | 50/100 [06:24<06:17,  7.54s/it]Best trial: 49. Best value: 0.546276:  50%|█████     | 50/100 [06:24<06:17,  7.54s/it]Best trial: 49. Best value: 0.546276:  51%|█████     | 51/100 [06:24<06:09,  7.54s/it]                                                                                      Best trial: 49. Best value: 0.546276:  51%|█████     | 51/100 [06:31<06:09,  7.54s/it]Best trial: 49. Best value: 0.546276:  51%|█████     | 51/100 [06:31<06:09,  7.54s/it]Best trial: 49. Best value: 0.546276:  52%|█████▏    | 52/100 [06:31<06:01,  7.53s/it]                                                                                      Best trial: 49. Best value: 0.546276:  52%|█████▏    | 52/100 [06:39<06:01,  7.53s/it]Best trial: 52. Best value: 0.546281:  52%|█████▏    | 52/100 [06:39<06:01,  7.53s/it]Best trial: 52. Best value: 0.546281:  53%|█████▎    | 53/100 [06:39<05:53,  7.53s/it]                                                                                      Best trial: 52. Best value: 0.546281:  53%|█████▎    | 53/100 [06:46<05:53,  7.53s/it]Best trial: 52. Best value: 0.546281:  53%|█████▎    | 53/100 [06:46<05:53,  7.53s/it]Best trial: 52. Best value: 0.546281:  54%|█████▍    | 54/100 [06:46<05:46,  7.53s/it]                                                                                      Best trial: 52. Best value: 0.546281:  54%|█████▍    | 54/100 [06:54<05:46,  7.53s/it]Best trial: 52. Best value: 0.546281:  54%|█████▍    | 54/100 [06:54<05:46,  7.53s/it]Best trial: 52. Best value: 0.546281:  55%|█████▌    | 55/100 [06:54<05:38,  7.52s/it]                                                                                      Best trial: 52. Best value: 0.546281:  55%|█████▌    | 55/100 [07:01<05:38,  7.52s/it]Best trial: 52. Best value: 0.546281:  55%|█████▌    | 55/100 [07:01<05:38,  7.52s/it]Best trial: 52. Best value: 0.546281:  56%|█████▌    | 56/100 [07:01<05:30,  7.51s/it]                                                                                      Best trial: 52. Best value: 0.546281:  56%|█████▌    | 56/100 [07:09<05:30,  7.51s/it]Best trial: 52. Best value: 0.546281:  56%|█████▌    | 56/100 [07:09<05:30,  7.51s/it]Best trial: 52. Best value: 0.546281:  57%|█████▋    | 57/100 [07:09<05:22,  7.51s/it]                                                                                      Best trial: 52. Best value: 0.546281:  57%|█████▋    | 57/100 [07:16<05:22,  7.51s/it]Best trial: 52. Best value: 0.546281:  57%|█████▋    | 57/100 [07:16<05:22,  7.51s/it]Best trial: 52. Best value: 0.546281:  58%|█████▊    | 58/100 [07:16<05:15,  7.51s/it]                                                                                      Best trial: 52. Best value: 0.546281:  58%|█████▊    | 58/100 [07:24<05:15,  7.51s/it]Best trial: 52. Best value: 0.546281:  58%|█████▊    | 58/100 [07:24<05:15,  7.51s/it]Best trial: 52. Best value: 0.546281:  59%|█████▉    | 59/100 [07:24<05:08,  7.52s/it]                                                                                      Best trial: 52. Best value: 0.546281:  59%|█████▉    | 59/100 [07:31<05:08,  7.52s/it]Best trial: 52. Best value: 0.546281:  59%|█████▉    | 59/100 [07:31<05:08,  7.52s/it]Best trial: 52. Best value: 0.546281:  60%|██████    | 60/100 [07:31<05:00,  7.51s/it]                                                                                      Best trial: 52. Best value: 0.546281:  60%|██████    | 60/100 [07:39<05:00,  7.51s/it]Best trial: 52. Best value: 0.546281:  60%|██████    | 60/100 [07:39<05:00,  7.51s/it]Best trial: 52. Best value: 0.546281:  61%|██████    | 61/100 [07:39<04:52,  7.51s/it]                                                                                      Best trial: 52. Best value: 0.546281:  61%|██████    | 61/100 [07:46<04:52,  7.51s/it]Best trial: 52. Best value: 0.546281:  61%|██████    | 61/100 [07:46<04:52,  7.51s/it]Best trial: 52. Best value: 0.546281:  62%|██████▏   | 62/100 [07:46<04:45,  7.52s/it]                                                                                      Best trial: 52. Best value: 0.546281:  62%|██████▏   | 62/100 [07:54<04:45,  7.52s/it]Best trial: 52. Best value: 0.546281:  62%|██████▏   | 62/100 [07:54<04:45,  7.52s/it]Best trial: 52. Best value: 0.546281:  63%|██████▎   | 63/100 [07:54<04:38,  7.52s/it]                                                                                      Best trial: 52. Best value: 0.546281:  63%|██████▎   | 63/100 [08:01<04:38,  7.52s/it]Best trial: 52. Best value: 0.546281:  63%|██████▎   | 63/100 [08:01<04:38,  7.52s/it]Best trial: 52. Best value: 0.546281:  64%|██████▍   | 64/100 [08:01<04:32,  7.57s/it]                                                                                      Best trial: 52. Best value: 0.546281:  64%|██████▍   | 64/100 [08:09<04:32,  7.57s/it]Best trial: 52. Best value: 0.546281:  64%|██████▍   | 64/100 [08:09<04:32,  7.57s/it]Best trial: 52. Best value: 0.546281:  65%|██████▌   | 65/100 [08:09<04:24,  7.55s/it]                                                                                      Best trial: 52. Best value: 0.546281:  65%|██████▌   | 65/100 [08:16<04:24,  7.55s/it]Best trial: 65. Best value: 0.546298:  65%|██████▌   | 65/100 [08:16<04:24,  7.55s/it]Best trial: 65. Best value: 0.546298:  66%|██████▌   | 66/100 [08:16<04:16,  7.54s/it]                                                                                      Best trial: 65. Best value: 0.546298:  66%|██████▌   | 66/100 [08:24<04:16,  7.54s/it]Best trial: 65. Best value: 0.546298:  66%|██████▌   | 66/100 [08:24<04:16,  7.54s/it]Best trial: 65. Best value: 0.546298:  67%|██████▋   | 67/100 [08:24<04:08,  7.53s/it]                                                                                      Best trial: 65. Best value: 0.546298:  67%|██████▋   | 67/100 [08:32<04:08,  7.53s/it]Best trial: 65. Best value: 0.546298:  67%|██████▋   | 67/100 [08:32<04:08,  7.53s/it]Best trial: 65. Best value: 0.546298:  68%|██████▊   | 68/100 [08:32<04:00,  7.53s/it]                                                                                      Best trial: 65. Best value: 0.546298:  68%|██████▊   | 68/100 [08:39<04:00,  7.53s/it]Best trial: 68. Best value: 0.546301:  68%|██████▊   | 68/100 [08:39<04:00,  7.53s/it]Best trial: 68. Best value: 0.546301:  69%|██████▉   | 69/100 [08:39<03:53,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  69%|██████▉   | 69/100 [08:47<03:53,  7.53s/it]Best trial: 68. Best value: 0.546301:  69%|██████▉   | 69/100 [08:47<03:53,  7.53s/it]Best trial: 68. Best value: 0.546301:  70%|███████   | 70/100 [08:47<03:45,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  70%|███████   | 70/100 [08:54<03:45,  7.51s/it]Best trial: 68. Best value: 0.546301:  70%|███████   | 70/100 [08:54<03:45,  7.51s/it]Best trial: 68. Best value: 0.546301:  71%|███████   | 71/100 [08:54<03:37,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  71%|███████   | 71/100 [09:02<03:37,  7.51s/it]Best trial: 68. Best value: 0.546301:  71%|███████   | 71/100 [09:02<03:37,  7.51s/it]Best trial: 68. Best value: 0.546301:  72%|███████▏  | 72/100 [09:02<03:30,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  72%|███████▏  | 72/100 [09:09<03:30,  7.52s/it]Best trial: 68. Best value: 0.546301:  72%|███████▏  | 72/100 [09:09<03:30,  7.52s/it]Best trial: 68. Best value: 0.546301:  73%|███████▎  | 73/100 [09:09<03:23,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  73%|███████▎  | 73/100 [09:17<03:23,  7.52s/it]Best trial: 68. Best value: 0.546301:  73%|███████▎  | 73/100 [09:17<03:23,  7.52s/it]Best trial: 68. Best value: 0.546301:  74%|███████▍  | 74/100 [09:17<03:15,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  74%|███████▍  | 74/100 [09:24<03:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  74%|███████▍  | 74/100 [09:24<03:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  75%|███████▌  | 75/100 [09:24<03:07,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  75%|███████▌  | 75/100 [09:32<03:07,  7.52s/it]Best trial: 68. Best value: 0.546301:  75%|███████▌  | 75/100 [09:32<03:07,  7.52s/it]Best trial: 68. Best value: 0.546301:  76%|███████▌  | 76/100 [09:32<03:00,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  76%|███████▌  | 76/100 [09:39<03:00,  7.51s/it]Best trial: 68. Best value: 0.546301:  76%|███████▌  | 76/100 [09:39<03:00,  7.51s/it]Best trial: 68. Best value: 0.546301:  77%|███████▋  | 77/100 [09:39<02:52,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  77%|███████▋  | 77/100 [09:47<02:52,  7.51s/it]Best trial: 68. Best value: 0.546301:  77%|███████▋  | 77/100 [09:47<02:52,  7.51s/it]Best trial: 68. Best value: 0.546301:  78%|███████▊  | 78/100 [09:47<02:46,  7.55s/it]                                                                                      Best trial: 68. Best value: 0.546301:  78%|███████▊  | 78/100 [09:54<02:46,  7.55s/it]Best trial: 68. Best value: 0.546301:  78%|███████▊  | 78/100 [09:54<02:46,  7.55s/it]Best trial: 68. Best value: 0.546301:  79%|███████▉  | 79/100 [09:54<02:38,  7.54s/it]                                                                                      Best trial: 68. Best value: 0.546301:  79%|███████▉  | 79/100 [10:02<02:38,  7.54s/it]Best trial: 68. Best value: 0.546301:  79%|███████▉  | 79/100 [10:02<02:38,  7.54s/it]Best trial: 68. Best value: 0.546301:  80%|████████  | 80/100 [10:02<02:30,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  80%|████████  | 80/100 [10:09<02:30,  7.53s/it]Best trial: 68. Best value: 0.546301:  80%|████████  | 80/100 [10:09<02:30,  7.53s/it]Best trial: 68. Best value: 0.546301:  81%|████████  | 81/100 [10:09<02:22,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  81%|████████  | 81/100 [10:17<02:22,  7.53s/it]Best trial: 68. Best value: 0.546301:  81%|████████  | 81/100 [10:17<02:22,  7.53s/it]Best trial: 68. Best value: 0.546301:  82%|████████▏ | 82/100 [10:17<02:15,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  82%|████████▏ | 82/100 [10:24<02:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  82%|████████▏ | 82/100 [10:24<02:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  83%|████████▎ | 83/100 [10:24<02:07,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  83%|████████▎ | 83/100 [10:32<02:07,  7.52s/it]Best trial: 68. Best value: 0.546301:  83%|████████▎ | 83/100 [10:32<02:07,  7.52s/it]Best trial: 68. Best value: 0.546301:  84%|████████▍ | 84/100 [10:32<02:00,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  84%|████████▍ | 84/100 [10:39<02:00,  7.53s/it]Best trial: 68. Best value: 0.546301:  84%|████████▍ | 84/100 [10:39<02:00,  7.53s/it]Best trial: 68. Best value: 0.546301:  85%|████████▌ | 85/100 [10:39<01:52,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  85%|████████▌ | 85/100 [10:47<01:52,  7.52s/it]Best trial: 68. Best value: 0.546301:  85%|████████▌ | 85/100 [10:47<01:52,  7.52s/it]Best trial: 68. Best value: 0.546301:  86%|████████▌ | 86/100 [10:47<01:45,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  86%|████████▌ | 86/100 [10:54<01:45,  7.51s/it]Best trial: 68. Best value: 0.546301:  86%|████████▌ | 86/100 [10:54<01:45,  7.51s/it]Best trial: 68. Best value: 0.546301:  87%|████████▋ | 87/100 [10:54<01:37,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  87%|████████▋ | 87/100 [11:02<01:37,  7.52s/it]Best trial: 68. Best value: 0.546301:  87%|████████▋ | 87/100 [11:02<01:37,  7.52s/it]Best trial: 68. Best value: 0.546301:  88%|████████▊ | 88/100 [11:02<01:30,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  88%|████████▊ | 88/100 [11:09<01:30,  7.51s/it]Best trial: 68. Best value: 0.546301:  88%|████████▊ | 88/100 [11:09<01:30,  7.51s/it]Best trial: 68. Best value: 0.546301:  89%|████████▉ | 89/100 [11:09<01:22,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  89%|████████▉ | 89/100 [11:17<01:22,  7.52s/it]Best trial: 68. Best value: 0.546301:  89%|████████▉ | 89/100 [11:17<01:22,  7.52s/it]Best trial: 68. Best value: 0.546301:  90%|█████████ | 90/100 [11:17<01:15,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  90%|█████████ | 90/100 [11:24<01:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  90%|█████████ | 90/100 [11:24<01:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  91%|█████████ | 91/100 [11:24<01:07,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  91%|█████████ | 91/100 [11:32<01:07,  7.51s/it]Best trial: 68. Best value: 0.546301:  91%|█████████ | 91/100 [11:32<01:07,  7.51s/it]Best trial: 68. Best value: 0.546301:  92%|█████████▏| 92/100 [11:32<01:00,  7.51s/it]                                                                                      Best trial: 68. Best value: 0.546301:  92%|█████████▏| 92/100 [11:40<01:00,  7.51s/it]Best trial: 68. Best value: 0.546301:  92%|█████████▏| 92/100 [11:40<01:00,  7.51s/it]Best trial: 68. Best value: 0.546301:  93%|█████████▎| 93/100 [11:40<00:52,  7.56s/it]                                                                                      Best trial: 68. Best value: 0.546301:  93%|█████████▎| 93/100 [11:47<00:52,  7.56s/it]Best trial: 68. Best value: 0.546301:  93%|█████████▎| 93/100 [11:47<00:52,  7.56s/it]Best trial: 68. Best value: 0.546301:  94%|█████████▍| 94/100 [11:47<00:45,  7.55s/it]                                                                                      Best trial: 68. Best value: 0.546301:  94%|█████████▍| 94/100 [11:55<00:45,  7.55s/it]Best trial: 68. Best value: 0.546301:  94%|█████████▍| 94/100 [11:55<00:45,  7.55s/it]Best trial: 68. Best value: 0.546301:  95%|█████████▌| 95/100 [11:55<00:37,  7.54s/it]                                                                                      Best trial: 68. Best value: 0.546301:  95%|█████████▌| 95/100 [12:02<00:37,  7.54s/it]Best trial: 68. Best value: 0.546301:  95%|█████████▌| 95/100 [12:02<00:37,  7.54s/it]Best trial: 68. Best value: 0.546301:  96%|█████████▌| 96/100 [12:02<00:30,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  96%|█████████▌| 96/100 [12:10<00:30,  7.53s/it]Best trial: 68. Best value: 0.546301:  96%|█████████▌| 96/100 [12:10<00:30,  7.53s/it]Best trial: 68. Best value: 0.546301:  97%|█████████▋| 97/100 [12:10<00:22,  7.53s/it]                                                                                      Best trial: 68. Best value: 0.546301:  97%|█████████▋| 97/100 [12:17<00:22,  7.53s/it]Best trial: 68. Best value: 0.546301:  97%|█████████▋| 97/100 [12:17<00:22,  7.53s/it]Best trial: 68. Best value: 0.546301:  98%|█████████▊| 98/100 [12:17<00:15,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  98%|█████████▊| 98/100 [12:25<00:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  98%|█████████▊| 98/100 [12:25<00:15,  7.52s/it]Best trial: 68. Best value: 0.546301:  99%|█████████▉| 99/100 [12:25<00:07,  7.52s/it]                                                                                      Best trial: 68. Best value: 0.546301:  99%|█████████▉| 99/100 [12:32<00:07,  7.52s/it]Best trial: 68. Best value: 0.546301:  99%|█████████▉| 99/100 [12:32<00:07,  7.52s/it]Best trial: 68. Best value: 0.546301: 100%|██████████| 100/100 [12:32<00:00,  7.52s/it]Best trial: 68. Best value: 0.546301: 100%|██████████| 100/100 [12:32<00:00,  7.53s/it]
[I 2025-05-15 03:24:08,112] A new study created in memory with name: no-name-a6f71d5b-133d-49ae-bc2d-b080446eb7be
[I 2025-05-15 03:11:42,904] Trial 0 finished with value: 0.5460260312814416 and parameters: {'interp_param': 0.936005712388086}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:11:50,407] Trial 1 finished with value: 0.5341231810538314 and parameters: {'interp_param': 0.2842190477120482}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:11:57,897] Trial 2 finished with value: 0.5419940040385847 and parameters: {'interp_param': 0.6734827142904267}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:05,429] Trial 3 finished with value: 0.5459342963082834 and parameters: {'interp_param': 0.9286178026224639}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:13,119] Trial 4 finished with value: 0.5421267946724455 and parameters: {'interp_param': 0.6811231459804091}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:20,642] Trial 5 finished with value: 0.5372927087364295 and parameters: {'interp_param': 0.4437134210160232}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:28,160] Trial 6 finished with value: 0.5423119208606265 and parameters: {'interp_param': 0.6929285530779542}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:35,675] Trial 7 finished with value: 0.5317584574576617 and parameters: {'interp_param': 0.1693349779229184}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:43,199] Trial 8 finished with value: 0.5368794208078577 and parameters: {'interp_param': 0.42328717848188}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:50,704] Trial 9 finished with value: 0.5301813338586777 and parameters: {'interp_param': 0.08293865210338369}. Best is trial 0 with value: 0.5460260312814416.
[I 2025-05-15 03:12:58,233] Trial 10 finished with value: 0.5462383623328103 and parameters: {'interp_param': 0.9707232650001977}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:05,760] Trial 11 finished with value: 0.5459036790521288 and parameters: {'interp_param': 0.9241808166764284}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:13,304] Trial 12 finished with value: 0.5462341183009801 and parameters: {'interp_param': 0.9751387005252485}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:20,829] Trial 13 finished with value: 0.5440075635514217 and parameters: {'interp_param': 0.786503824172577}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:28,348] Trial 14 finished with value: 0.5445788079842959 and parameters: {'interp_param': 0.8217058352007248}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:35,881] Trial 15 finished with value: 0.544338703572107 and parameters: {'interp_param': 0.8098584640444924}. Best is trial 10 with value: 0.5462383623328103.
[I 2025-05-15 03:13:43,423] Trial 16 finished with value: 0.546238455206186 and parameters: {'interp_param': 0.9944572927625533}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:13:50,968] Trial 17 finished with value: 0.5395564494227076 and parameters: {'interp_param': 0.5550858717389116}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:13:58,655] Trial 18 finished with value: 0.5395853949581014 and parameters: {'interp_param': 0.5561686094277847}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:06,174] Trial 19 finished with value: 0.5461759514244102 and parameters: {'interp_param': 0.989581010134307}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:13,722] Trial 20 finished with value: 0.5448424178035447 and parameters: {'interp_param': 0.8346564005114001}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:21,275] Trial 21 finished with value: 0.5461828620478579 and parameters: {'interp_param': 0.9903151359514223}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:28,826] Trial 22 finished with value: 0.5456160051783943 and parameters: {'interp_param': 0.8917549653649899}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:36,355] Trial 23 finished with value: 0.5431875493389808 and parameters: {'interp_param': 0.7421591050608303}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:43,889] Trial 24 finished with value: 0.5462377094048365 and parameters: {'interp_param': 0.99543775904869}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:51,416] Trial 25 finished with value: 0.545396583385516 and parameters: {'interp_param': 0.8715614829734346}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:14:58,955] Trial 26 finished with value: 0.5347848123887454 and parameters: {'interp_param': 0.3173690230086609}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:06,494] Trial 27 finished with value: 0.5408597682387127 and parameters: {'interp_param': 0.6149559352783647}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:14,034] Trial 28 finished with value: 0.545280685855807 and parameters: {'interp_param': 0.8643398658265945}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:21,597] Trial 29 finished with value: 0.543165885920537 and parameters: {'interp_param': 0.7409234721026929}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:29,103] Trial 30 finished with value: 0.5460256189799406 and parameters: {'interp_param': 0.9359653549477174}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:36,608] Trial 31 finished with value: 0.546234149258772 and parameters: {'interp_param': 0.9842275015648341}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:44,100] Trial 32 finished with value: 0.5461687101154584 and parameters: {'interp_param': 0.9888510123459113}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:51,763] Trial 33 finished with value: 0.5457579987194732 and parameters: {'interp_param': 0.9084866005714151}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:15:59,261] Trial 34 finished with value: 0.5462078872010638 and parameters: {'interp_param': 0.9971539563197089}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:06,756] Trial 35 finished with value: 0.5435387190510029 and parameters: {'interp_param': 0.7599594325953721}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:14,263] Trial 36 finished with value: 0.5454396104946915 and parameters: {'interp_param': 0.8745195806288505}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:21,771] Trial 37 finished with value: 0.5460484616088201 and parameters: {'interp_param': 0.9379326388501934}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:29,262] Trial 38 finished with value: 0.545944135257407 and parameters: {'interp_param': 0.9299347295482163}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:36,752] Trial 39 finished with value: 0.5288388984654786 and parameters: {'interp_param': 0.0006433779062469114}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:44,272] Trial 40 finished with value: 0.5349736844697422 and parameters: {'interp_param': 0.3261834798120828}. Best is trial 16 with value: 0.546238455206186.
[I 2025-05-15 03:16:51,760] Trial 41 finished with value: 0.5462506891626621 and parameters: {'interp_param': 0.9511051874047376}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:16:59,249] Trial 42 finished with value: 0.5462035742177881 and parameters: {'interp_param': 0.9466602379669251}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:06,752] Trial 43 finished with value: 0.5450848313855723 and parameters: {'interp_param': 0.8499372051862305}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:14,244] Trial 44 finished with value: 0.546247599012165 and parameters: {'interp_param': 0.9507343563879982}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:21,753] Trial 45 finished with value: 0.5422251335054773 and parameters: {'interp_param': 0.6872936373516526}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:29,251] Trial 46 finished with value: 0.5457228391109485 and parameters: {'interp_param': 0.9040099237047813}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:36,745] Trial 47 finished with value: 0.5439854836099599 and parameters: {'interp_param': 0.7850174682773183}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:44,426] Trial 48 finished with value: 0.532891647728472 and parameters: {'interp_param': 0.22859292459044167}. Best is trial 41 with value: 0.5462506891626621.
[I 2025-05-15 03:17:51,941] Trial 49 finished with value: 0.5462761885329525 and parameters: {'interp_param': 0.9569335339187072}. Best is trial 49 with value: 0.5462761885329525.
[I 2025-05-15 03:17:59,467] Trial 50 finished with value: 0.5444985470945408 and parameters: {'interp_param': 0.8181010612631764}. Best is trial 49 with value: 0.5462761885329525.
[I 2025-05-15 03:18:06,986] Trial 51 finished with value: 0.5459234723385094 and parameters: {'interp_param': 0.9266543893804313}. Best is trial 49 with value: 0.5462761885329525.
[I 2025-05-15 03:18:14,505] Trial 52 finished with value: 0.5462814330643289 and parameters: {'interp_param': 0.9589275761955312}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:22,031] Trial 53 finished with value: 0.5462600707807695 and parameters: {'interp_param': 0.9523655886810711}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:29,525] Trial 54 finished with value: 0.5462710748686053 and parameters: {'interp_param': 0.9542720680128377}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:37,021] Trial 55 finished with value: 0.537008462734558 and parameters: {'interp_param': 0.4299770910554144}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:44,531] Trial 56 finished with value: 0.5462714927987955 and parameters: {'interp_param': 0.9543456446278437}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:52,056] Trial 57 finished with value: 0.5456257723617277 and parameters: {'interp_param': 0.8926252345703724}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:18:59,575] Trial 58 finished with value: 0.5449640157884739 and parameters: {'interp_param': 0.8422380460686594}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:07,064] Trial 59 finished with value: 0.5440985879025393 and parameters: {'interp_param': 0.7933431402707333}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:14,573] Trial 60 finished with value: 0.5416512365527092 and parameters: {'interp_param': 0.6541775778783672}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:22,112] Trial 61 finished with value: 0.5462139633713036 and parameters: {'interp_param': 0.9476377392861007}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:29,646] Trial 62 finished with value: 0.5462771777751197 and parameters: {'interp_param': 0.9574299522250322}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:37,326] Trial 63 finished with value: 0.5456310267433107 and parameters: {'interp_param': 0.8932642946557594}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:44,844] Trial 64 finished with value: 0.5452169550197355 and parameters: {'interp_param': 0.860233068348855}. Best is trial 52 with value: 0.5462814330643289.
[I 2025-05-15 03:19:52,341] Trial 65 finished with value: 0.5462983247613085 and parameters: {'interp_param': 0.9609995932825457}. Best is trial 65 with value: 0.5462983247613085.
[I 2025-05-15 03:19:59,857] Trial 66 finished with value: 0.5462574604760464 and parameters: {'interp_param': 0.9681966073636673}. Best is trial 65 with value: 0.5462983247613085.
[I 2025-05-15 03:20:07,369] Trial 67 finished with value: 0.5457778567357823 and parameters: {'interp_param': 0.9101732212372011}. Best is trial 65 with value: 0.5462983247613085.
[I 2025-05-15 03:20:14,895] Trial 68 finished with value: 0.5463009646166511 and parameters: {'interp_param': 0.9621733858960182}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:22,374] Trial 69 finished with value: 0.5385617643127019 and parameters: {'interp_param': 0.5095797984434806}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:29,891] Trial 70 finished with value: 0.5455209450569554 and parameters: {'interp_param': 0.8808287690531159}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:37,415] Trial 71 finished with value: 0.5462701714639517 and parameters: {'interp_param': 0.9669048760910007}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:44,954] Trial 72 finished with value: 0.5462287161662998 and parameters: {'interp_param': 0.9725662662058612}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:52,454] Trial 73 finished with value: 0.5458225611944079 and parameters: {'interp_param': 0.914843824296466}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:20:59,972] Trial 74 finished with value: 0.5446906725580283 and parameters: {'interp_param': 0.8269389460792749}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:07,475] Trial 75 finished with value: 0.5462280055442591 and parameters: {'interp_param': 0.9728105200332401}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:14,975] Trial 76 finished with value: 0.5461545469256802 and parameters: {'interp_param': 0.9982182831247277}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:22,619] Trial 77 finished with value: 0.5458680044185212 and parameters: {'interp_param': 0.9196584919349436}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:30,123] Trial 78 finished with value: 0.5454040526563896 and parameters: {'interp_param': 0.8719966756945445}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:37,637] Trial 79 finished with value: 0.5462951290728845 and parameters: {'interp_param': 0.9638213991526009}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:45,153] Trial 80 finished with value: 0.5460999064230383 and parameters: {'interp_param': 0.9998594044092471}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:21:52,661] Trial 81 finished with value: 0.5462848313855723 and parameters: {'interp_param': 0.9653691548582146}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:00,169] Trial 82 finished with value: 0.5459785701721676 and parameters: {'interp_param': 0.9329931381398758}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:07,715] Trial 83 finished with value: 0.5462959072391982 and parameters: {'interp_param': 0.9637465836634604}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:15,234] Trial 84 finished with value: 0.545642143404935 and parameters: {'interp_param': 0.8943681501269266}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:22,726] Trial 85 finished with value: 0.5450709425944037 and parameters: {'interp_param': 0.8490370236626755}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:30,251] Trial 86 finished with value: 0.5462637814942763 and parameters: {'interp_param': 0.9675924863522055}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:37,755] Trial 87 finished with value: 0.5358361601080708 and parameters: {'interp_param': 0.3699897753702559}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:45,285] Trial 88 finished with value: 0.5458864552624728 and parameters: {'interp_param': 0.9219727439109339}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:22:52,805] Trial 89 finished with value: 0.5455152080152537 and parameters: {'interp_param': 0.88020313596327}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:00,310] Trial 90 finished with value: 0.546048130923316 and parameters: {'interp_param': 0.9378824090650842}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:07,823] Trial 91 finished with value: 0.5462744211244714 and parameters: {'interp_param': 0.9548164055578782}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:15,500] Trial 92 finished with value: 0.5462336271978273 and parameters: {'interp_param': 0.9748401887178342}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:23,021] Trial 93 finished with value: 0.5457701257308502 and parameters: {'interp_param': 0.9095488951651783}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:30,524] Trial 94 finished with value: 0.5462954302077689 and parameters: {'interp_param': 0.960231989700215}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:38,052] Trial 95 finished with value: 0.5461192409712303 and parameters: {'interp_param': 0.9994209308362203}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:45,575] Trial 96 finished with value: 0.5459497062527704 and parameters: {'interp_param': 0.9305053254537241}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:23:53,078] Trial 97 finished with value: 0.5427372555917511 and parameters: {'interp_param': 0.7172756817636388}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:24:00,581] Trial 98 finished with value: 0.5462745083691576 and parameters: {'interp_param': 0.9548381965300311}. Best is trial 68 with value: 0.5463009646166511.
[I 2025-05-15 03:24:08,110] Trial 99 finished with value: 0.5462499081820037 and parameters: {'interp_param': 0.9794999138383573}. Best is trial 68 with value: 0.5463009646166511.
Best hyperparameters: {'interp_param': 0.9621733858960182}
Best optimized value: 0.5463009646166511
Tuning threshold scale factor for offline LSET using optuna
  0%|          | 0/100 [00:00<?, ?it/s]                                         0%|          | 0/100 [00:06<?, ?it/s]Best trial: 0. Best value: 0.537486:   0%|          | 0/100 [00:06<?, ?it/s]Best trial: 0. Best value: 0.537486:   1%|          | 1/100 [00:06<10:07,  6.14s/it]                                                                                    Best trial: 0. Best value: 0.537486:   1%|          | 1/100 [00:12<10:07,  6.14s/it]Best trial: 0. Best value: 0.537486:   1%|          | 1/100 [00:12<10:07,  6.14s/it]Best trial: 0. Best value: 0.537486:   2%|▏         | 2/100 [00:12<09:58,  6.11s/it]                                                                                    Best trial: 0. Best value: 0.537486:   2%|▏         | 2/100 [00:18<09:58,  6.11s/it]Best trial: 2. Best value: 0.541779:   2%|▏         | 2/100 [00:18<09:58,  6.11s/it]Best trial: 2. Best value: 0.541779:   3%|▎         | 3/100 [00:18<09:51,  6.10s/it]                                                                                    Best trial: 2. Best value: 0.541779:   3%|▎         | 3/100 [00:24<09:51,  6.10s/it]Best trial: 2. Best value: 0.541779:   3%|▎         | 3/100 [00:24<09:51,  6.10s/it]Best trial: 2. Best value: 0.541779:   4%|▍         | 4/100 [00:24<09:44,  6.09s/it]                                                                                    Best trial: 2. Best value: 0.541779:   4%|▍         | 4/100 [00:30<09:44,  6.09s/it]Best trial: 4. Best value: 0.542543:   4%|▍         | 4/100 [00:30<09:44,  6.09s/it]Best trial: 4. Best value: 0.542543:   5%|▌         | 5/100 [00:30<09:37,  6.08s/it]                                                                                    Best trial: 4. Best value: 0.542543:   5%|▌         | 5/100 [00:36<09:37,  6.08s/it]Best trial: 4. Best value: 0.542543:   5%|▌         | 5/100 [00:36<09:37,  6.08s/it]Best trial: 4. Best value: 0.542543:   6%|▌         | 6/100 [00:36<09:31,  6.08s/it]                                                                                    Best trial: 4. Best value: 0.542543:   6%|▌         | 6/100 [00:42<09:31,  6.08s/it]Best trial: 6. Best value: 0.546389:   6%|▌         | 6/100 [00:42<09:31,  6.08s/it]Best trial: 6. Best value: 0.546389:   7%|▋         | 7/100 [00:42<09:25,  6.08s/it]                                                                                    Best trial: 6. Best value: 0.546389:   7%|▋         | 7/100 [00:48<09:25,  6.08s/it]Best trial: 6. Best value: 0.546389:   7%|▋         | 7/100 [00:48<09:25,  6.08s/it]Best trial: 6. Best value: 0.546389:   8%|▊         | 8/100 [00:48<09:19,  6.08s/it]                                                                                    Best trial: 6. Best value: 0.546389:   8%|▊         | 8/100 [00:54<09:19,  6.08s/it]Best trial: 6. Best value: 0.546389:   8%|▊         | 8/100 [00:54<09:19,  6.08s/it]Best trial: 6. Best value: 0.546389:   9%|▉         | 9/100 [00:54<09:17,  6.13s/it]                                                                                    Best trial: 6. Best value: 0.546389:   9%|▉         | 9/100 [01:01<09:17,  6.13s/it]Best trial: 6. Best value: 0.546389:   9%|▉         | 9/100 [01:01<09:17,  6.13s/it]Best trial: 6. Best value: 0.546389:  10%|█         | 10/100 [01:01<09:10,  6.12s/it]                                                                                     Best trial: 6. Best value: 0.546389:  10%|█         | 10/100 [01:07<09:10,  6.12s/it]Best trial: 10. Best value: 0.54644:  10%|█         | 10/100 [01:07<09:10,  6.12s/it]Best trial: 10. Best value: 0.54644:  11%|█         | 11/100 [01:07<09:04,  6.12s/it]                                                                                     Best trial: 10. Best value: 0.54644:  11%|█         | 11/100 [01:13<09:04,  6.12s/it]Best trial: 10. Best value: 0.54644:  11%|█         | 11/100 [01:13<09:04,  6.12s/it]Best trial: 10. Best value: 0.54644:  12%|█▏        | 12/100 [01:13<08:56,  6.09s/it]                                                                                     Best trial: 10. Best value: 0.54644:  12%|█▏        | 12/100 [01:19<08:56,  6.09s/it]Best trial: 10. Best value: 0.54644:  12%|█▏        | 12/100 [01:19<08:56,  6.09s/it]Best trial: 10. Best value: 0.54644:  13%|█▎        | 13/100 [01:19<08:50,  6.09s/it]                                                                                     Best trial: 10. Best value: 0.54644:  13%|█▎        | 13/100 [01:25<08:50,  6.09s/it]Best trial: 10. Best value: 0.54644:  13%|█▎        | 13/100 [01:25<08:50,  6.09s/it]Best trial: 10. Best value: 0.54644:  14%|█▍        | 14/100 [01:25<08:44,  6.09s/it]                                                                                     Best trial: 10. Best value: 0.54644:  14%|█▍        | 14/100 [01:31<08:44,  6.09s/it]Best trial: 10. Best value: 0.54644:  14%|█▍        | 14/100 [01:31<08:44,  6.09s/it]Best trial: 10. Best value: 0.54644:  15%|█▌        | 15/100 [01:31<08:38,  6.10s/it]                                                                                     Best trial: 10. Best value: 0.54644:  15%|█▌        | 15/100 [01:37<08:38,  6.10s/it]Best trial: 10. Best value: 0.54644:  15%|█▌        | 15/100 [01:37<08:38,  6.10s/it]Best trial: 10. Best value: 0.54644:  16%|█▌        | 16/100 [01:37<08:32,  6.10s/it]                                                                                     Best trial: 10. Best value: 0.54644:  16%|█▌        | 16/100 [01:43<08:32,  6.10s/it]Best trial: 16. Best value: 0.546442:  16%|█▌        | 16/100 [01:43<08:32,  6.10s/it]Best trial: 16. Best value: 0.546442:  17%|█▋        | 17/100 [01:43<08:26,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  17%|█▋        | 17/100 [01:49<08:26,  6.10s/it]Best trial: 16. Best value: 0.546442:  17%|█▋        | 17/100 [01:49<08:26,  6.10s/it]Best trial: 16. Best value: 0.546442:  18%|█▊        | 18/100 [01:49<08:20,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  18%|█▊        | 18/100 [01:55<08:20,  6.10s/it]Best trial: 16. Best value: 0.546442:  18%|█▊        | 18/100 [01:55<08:20,  6.10s/it]Best trial: 16. Best value: 0.546442:  19%|█▉        | 19/100 [01:55<08:14,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  19%|█▉        | 19/100 [02:01<08:14,  6.10s/it]Best trial: 16. Best value: 0.546442:  19%|█▉        | 19/100 [02:01<08:14,  6.10s/it]Best trial: 16. Best value: 0.546442:  20%|██        | 20/100 [02:01<08:08,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  20%|██        | 20/100 [02:08<08:08,  6.10s/it]Best trial: 16. Best value: 0.546442:  20%|██        | 20/100 [02:08<08:08,  6.10s/it]Best trial: 16. Best value: 0.546442:  21%|██        | 21/100 [02:08<08:02,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  21%|██        | 21/100 [02:14<08:02,  6.10s/it]Best trial: 16. Best value: 0.546442:  21%|██        | 21/100 [02:14<08:02,  6.10s/it]Best trial: 16. Best value: 0.546442:  22%|██▏       | 22/100 [02:14<07:56,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  22%|██▏       | 22/100 [02:20<07:56,  6.10s/it]Best trial: 16. Best value: 0.546442:  22%|██▏       | 22/100 [02:20<07:56,  6.10s/it]Best trial: 16. Best value: 0.546442:  23%|██▎       | 23/100 [02:20<07:49,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  23%|██▎       | 23/100 [02:26<07:49,  6.10s/it]Best trial: 16. Best value: 0.546442:  23%|██▎       | 23/100 [02:26<07:49,  6.10s/it]Best trial: 16. Best value: 0.546442:  24%|██▍       | 24/100 [02:26<07:43,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  24%|██▍       | 24/100 [02:32<07:43,  6.10s/it]Best trial: 16. Best value: 0.546442:  24%|██▍       | 24/100 [02:32<07:43,  6.10s/it]Best trial: 16. Best value: 0.546442:  25%|██▌       | 25/100 [02:32<07:40,  6.14s/it]                                                                                      Best trial: 16. Best value: 0.546442:  25%|██▌       | 25/100 [02:38<07:40,  6.14s/it]Best trial: 16. Best value: 0.546442:  25%|██▌       | 25/100 [02:38<07:40,  6.14s/it]Best trial: 16. Best value: 0.546442:  26%|██▌       | 26/100 [02:38<07:33,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  26%|██▌       | 26/100 [02:44<07:33,  6.12s/it]Best trial: 16. Best value: 0.546442:  26%|██▌       | 26/100 [02:44<07:33,  6.12s/it]Best trial: 16. Best value: 0.546442:  27%|██▋       | 27/100 [02:44<07:26,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  27%|██▋       | 27/100 [02:50<07:26,  6.12s/it]Best trial: 16. Best value: 0.546442:  27%|██▋       | 27/100 [02:50<07:26,  6.12s/it]Best trial: 16. Best value: 0.546442:  28%|██▊       | 28/100 [02:50<07:20,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  28%|██▊       | 28/100 [02:57<07:20,  6.11s/it]Best trial: 16. Best value: 0.546442:  28%|██▊       | 28/100 [02:57<07:20,  6.11s/it]Best trial: 16. Best value: 0.546442:  29%|██▉       | 29/100 [02:57<07:13,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  29%|██▉       | 29/100 [03:03<07:13,  6.11s/it]Best trial: 16. Best value: 0.546442:  29%|██▉       | 29/100 [03:03<07:13,  6.11s/it]Best trial: 16. Best value: 0.546442:  30%|███       | 30/100 [03:03<07:07,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  30%|███       | 30/100 [03:09<07:07,  6.11s/it]Best trial: 16. Best value: 0.546442:  30%|███       | 30/100 [03:09<07:07,  6.11s/it]Best trial: 16. Best value: 0.546442:  31%|███       | 31/100 [03:09<07:01,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  31%|███       | 31/100 [03:15<07:01,  6.11s/it]Best trial: 16. Best value: 0.546442:  31%|███       | 31/100 [03:15<07:01,  6.11s/it]Best trial: 16. Best value: 0.546442:  32%|███▏      | 32/100 [03:15<06:55,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  32%|███▏      | 32/100 [03:21<06:55,  6.11s/it]Best trial: 16. Best value: 0.546442:  32%|███▏      | 32/100 [03:21<06:55,  6.11s/it]Best trial: 16. Best value: 0.546442:  33%|███▎      | 33/100 [03:21<06:49,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  33%|███▎      | 33/100 [03:27<06:49,  6.11s/it]Best trial: 16. Best value: 0.546442:  33%|███▎      | 33/100 [03:27<06:49,  6.11s/it]Best trial: 16. Best value: 0.546442:  34%|███▍      | 34/100 [03:27<06:43,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  34%|███▍      | 34/100 [03:33<06:43,  6.11s/it]Best trial: 16. Best value: 0.546442:  34%|███▍      | 34/100 [03:33<06:43,  6.11s/it]Best trial: 16. Best value: 0.546442:  35%|███▌      | 35/100 [03:33<06:37,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  35%|███▌      | 35/100 [03:39<06:37,  6.11s/it]Best trial: 16. Best value: 0.546442:  35%|███▌      | 35/100 [03:39<06:37,  6.11s/it]Best trial: 16. Best value: 0.546442:  36%|███▌      | 36/100 [03:39<06:31,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  36%|███▌      | 36/100 [03:45<06:31,  6.11s/it]Best trial: 16. Best value: 0.546442:  36%|███▌      | 36/100 [03:45<06:31,  6.11s/it]Best trial: 16. Best value: 0.546442:  37%|███▋      | 37/100 [03:45<06:24,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  37%|███▋      | 37/100 [03:51<06:24,  6.11s/it]Best trial: 16. Best value: 0.546442:  37%|███▋      | 37/100 [03:51<06:24,  6.11s/it]Best trial: 16. Best value: 0.546442:  38%|███▊      | 38/100 [03:51<06:18,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  38%|███▊      | 38/100 [03:58<06:18,  6.11s/it]Best trial: 16. Best value: 0.546442:  38%|███▊      | 38/100 [03:58<06:18,  6.11s/it]Best trial: 16. Best value: 0.546442:  39%|███▉      | 39/100 [03:58<06:12,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  39%|███▉      | 39/100 [04:04<06:12,  6.11s/it]Best trial: 16. Best value: 0.546442:  39%|███▉      | 39/100 [04:04<06:12,  6.11s/it]Best trial: 16. Best value: 0.546442:  40%|████      | 40/100 [04:04<06:06,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  40%|████      | 40/100 [04:10<06:06,  6.11s/it]Best trial: 16. Best value: 0.546442:  40%|████      | 40/100 [04:10<06:06,  6.11s/it]Best trial: 16. Best value: 0.546442:  41%|████      | 41/100 [04:10<06:00,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  41%|████      | 41/100 [04:16<06:00,  6.11s/it]Best trial: 16. Best value: 0.546442:  41%|████      | 41/100 [04:16<06:00,  6.11s/it]Best trial: 16. Best value: 0.546442:  42%|████▏     | 42/100 [04:16<05:56,  6.15s/it]                                                                                      Best trial: 16. Best value: 0.546442:  42%|████▏     | 42/100 [04:22<05:56,  6.15s/it]Best trial: 16. Best value: 0.546442:  42%|████▏     | 42/100 [04:22<05:56,  6.15s/it]Best trial: 16. Best value: 0.546442:  43%|████▎     | 43/100 [04:22<05:50,  6.14s/it]                                                                                      Best trial: 16. Best value: 0.546442:  43%|████▎     | 43/100 [04:28<05:50,  6.14s/it]Best trial: 16. Best value: 0.546442:  43%|████▎     | 43/100 [04:28<05:50,  6.14s/it]Best trial: 16. Best value: 0.546442:  44%|████▍     | 44/100 [04:28<05:43,  6.14s/it]                                                                                      Best trial: 16. Best value: 0.546442:  44%|████▍     | 44/100 [04:34<05:43,  6.14s/it]Best trial: 16. Best value: 0.546442:  44%|████▍     | 44/100 [04:34<05:43,  6.14s/it]Best trial: 16. Best value: 0.546442:  45%|████▌     | 45/100 [04:34<05:36,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  45%|████▌     | 45/100 [04:41<05:36,  6.12s/it]Best trial: 16. Best value: 0.546442:  45%|████▌     | 45/100 [04:41<05:36,  6.12s/it]Best trial: 16. Best value: 0.546442:  46%|████▌     | 46/100 [04:41<05:30,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  46%|████▌     | 46/100 [04:47<05:30,  6.12s/it]Best trial: 16. Best value: 0.546442:  46%|████▌     | 46/100 [04:47<05:30,  6.12s/it]Best trial: 16. Best value: 0.546442:  47%|████▋     | 47/100 [04:47<05:23,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  47%|████▋     | 47/100 [04:53<05:23,  6.11s/it]Best trial: 16. Best value: 0.546442:  47%|████▋     | 47/100 [04:53<05:23,  6.11s/it]Best trial: 16. Best value: 0.546442:  48%|████▊     | 48/100 [04:53<05:17,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  48%|████▊     | 48/100 [04:59<05:17,  6.11s/it]Best trial: 16. Best value: 0.546442:  48%|████▊     | 48/100 [04:59<05:17,  6.11s/it]Best trial: 16. Best value: 0.546442:  49%|████▉     | 49/100 [04:59<05:11,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  49%|████▉     | 49/100 [05:05<05:11,  6.11s/it]Best trial: 16. Best value: 0.546442:  49%|████▉     | 49/100 [05:05<05:11,  6.11s/it]Best trial: 16. Best value: 0.546442:  50%|█████     | 50/100 [05:05<05:05,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  50%|█████     | 50/100 [05:11<05:05,  6.11s/it]Best trial: 16. Best value: 0.546442:  50%|█████     | 50/100 [05:11<05:05,  6.11s/it]Best trial: 16. Best value: 0.546442:  51%|█████     | 51/100 [05:11<04:59,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  51%|█████     | 51/100 [05:17<04:59,  6.10s/it]Best trial: 16. Best value: 0.546442:  51%|█████     | 51/100 [05:17<04:59,  6.10s/it]Best trial: 16. Best value: 0.546442:  52%|█████▏    | 52/100 [05:17<04:52,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  52%|█████▏    | 52/100 [05:23<04:52,  6.10s/it]Best trial: 16. Best value: 0.546442:  52%|█████▏    | 52/100 [05:23<04:52,  6.10s/it]Best trial: 16. Best value: 0.546442:  53%|█████▎    | 53/100 [05:23<04:46,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  53%|█████▎    | 53/100 [05:29<04:46,  6.10s/it]Best trial: 16. Best value: 0.546442:  53%|█████▎    | 53/100 [05:29<04:46,  6.10s/it]Best trial: 16. Best value: 0.546442:  54%|█████▍    | 54/100 [05:29<04:40,  6.09s/it]                                                                                      Best trial: 16. Best value: 0.546442:  54%|█████▍    | 54/100 [05:35<04:40,  6.09s/it]Best trial: 16. Best value: 0.546442:  54%|█████▍    | 54/100 [05:35<04:40,  6.09s/it]Best trial: 16. Best value: 0.546442:  55%|█████▌    | 55/100 [05:35<04:34,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  55%|█████▌    | 55/100 [05:42<04:34,  6.10s/it]Best trial: 16. Best value: 0.546442:  55%|█████▌    | 55/100 [05:42<04:34,  6.10s/it]Best trial: 16. Best value: 0.546442:  56%|█████▌    | 56/100 [05:42<04:28,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  56%|█████▌    | 56/100 [05:48<04:28,  6.10s/it]Best trial: 16. Best value: 0.546442:  56%|█████▌    | 56/100 [05:48<04:28,  6.10s/it]Best trial: 16. Best value: 0.546442:  57%|█████▋    | 57/100 [05:48<04:22,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  57%|█████▋    | 57/100 [05:54<04:22,  6.10s/it]Best trial: 16. Best value: 0.546442:  57%|█████▋    | 57/100 [05:54<04:22,  6.10s/it]Best trial: 16. Best value: 0.546442:  58%|█████▊    | 58/100 [05:54<04:16,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  58%|█████▊    | 58/100 [06:00<04:16,  6.10s/it]Best trial: 16. Best value: 0.546442:  58%|█████▊    | 58/100 [06:00<04:16,  6.10s/it]Best trial: 16. Best value: 0.546442:  59%|█████▉    | 59/100 [06:00<04:12,  6.15s/it]                                                                                      Best trial: 16. Best value: 0.546442:  59%|█████▉    | 59/100 [06:06<04:12,  6.15s/it]Best trial: 16. Best value: 0.546442:  59%|█████▉    | 59/100 [06:06<04:12,  6.15s/it]Best trial: 16. Best value: 0.546442:  60%|██████    | 60/100 [06:06<04:05,  6.14s/it]                                                                                      Best trial: 16. Best value: 0.546442:  60%|██████    | 60/100 [06:12<04:05,  6.14s/it]Best trial: 16. Best value: 0.546442:  60%|██████    | 60/100 [06:12<04:05,  6.14s/it]Best trial: 16. Best value: 0.546442:  61%|██████    | 61/100 [06:12<03:58,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  61%|██████    | 61/100 [06:18<03:58,  6.11s/it]Best trial: 16. Best value: 0.546442:  61%|██████    | 61/100 [06:18<03:58,  6.11s/it]Best trial: 16. Best value: 0.546442:  62%|██████▏   | 62/100 [06:18<03:51,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  62%|██████▏   | 62/100 [06:24<03:51,  6.10s/it]Best trial: 16. Best value: 0.546442:  62%|██████▏   | 62/100 [06:24<03:51,  6.10s/it]Best trial: 16. Best value: 0.546442:  63%|██████▎   | 63/100 [06:24<03:45,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  63%|██████▎   | 63/100 [06:30<03:45,  6.11s/it]Best trial: 16. Best value: 0.546442:  63%|██████▎   | 63/100 [06:30<03:45,  6.11s/it]Best trial: 16. Best value: 0.546442:  64%|██████▍   | 64/100 [06:30<03:39,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  64%|██████▍   | 64/100 [06:37<03:39,  6.11s/it]Best trial: 16. Best value: 0.546442:  64%|██████▍   | 64/100 [06:37<03:39,  6.11s/it]Best trial: 16. Best value: 0.546442:  65%|██████▌   | 65/100 [06:37<03:33,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  65%|██████▌   | 65/100 [06:43<03:33,  6.11s/it]Best trial: 16. Best value: 0.546442:  65%|██████▌   | 65/100 [06:43<03:33,  6.11s/it]Best trial: 16. Best value: 0.546442:  66%|██████▌   | 66/100 [06:43<03:27,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  66%|██████▌   | 66/100 [06:49<03:27,  6.11s/it]Best trial: 16. Best value: 0.546442:  66%|██████▌   | 66/100 [06:49<03:27,  6.11s/it]Best trial: 16. Best value: 0.546442:  67%|██████▋   | 67/100 [06:49<03:21,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  67%|██████▋   | 67/100 [06:55<03:21,  6.11s/it]Best trial: 16. Best value: 0.546442:  67%|██████▋   | 67/100 [06:55<03:21,  6.11s/it]Best trial: 16. Best value: 0.546442:  68%|██████▊   | 68/100 [06:55<03:15,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  68%|██████▊   | 68/100 [07:01<03:15,  6.10s/it]Best trial: 16. Best value: 0.546442:  68%|██████▊   | 68/100 [07:01<03:15,  6.10s/it]Best trial: 16. Best value: 0.546442:  69%|██████▉   | 69/100 [07:01<03:09,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  69%|██████▉   | 69/100 [07:07<03:09,  6.10s/it]Best trial: 16. Best value: 0.546442:  69%|██████▉   | 69/100 [07:07<03:09,  6.10s/it]Best trial: 16. Best value: 0.546442:  70%|███████   | 70/100 [07:07<03:02,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  70%|███████   | 70/100 [07:13<03:02,  6.10s/it]Best trial: 16. Best value: 0.546442:  70%|███████   | 70/100 [07:13<03:02,  6.10s/it]Best trial: 16. Best value: 0.546442:  71%|███████   | 71/100 [07:13<02:56,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  71%|███████   | 71/100 [07:19<02:56,  6.10s/it]Best trial: 16. Best value: 0.546442:  71%|███████   | 71/100 [07:19<02:56,  6.10s/it]Best trial: 16. Best value: 0.546442:  72%|███████▏  | 72/100 [07:19<02:50,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  72%|███████▏  | 72/100 [07:25<02:50,  6.10s/it]Best trial: 16. Best value: 0.546442:  72%|███████▏  | 72/100 [07:25<02:50,  6.10s/it]Best trial: 16. Best value: 0.546442:  73%|███████▎  | 73/100 [07:25<02:44,  6.10s/it]                                                                                      Best trial: 16. Best value: 0.546442:  73%|███████▎  | 73/100 [07:31<02:44,  6.10s/it]Best trial: 16. Best value: 0.546442:  73%|███████▎  | 73/100 [07:31<02:44,  6.10s/it]Best trial: 16. Best value: 0.546442:  74%|███████▍  | 74/100 [07:31<02:38,  6.09s/it]                                                                                      Best trial: 16. Best value: 0.546442:  74%|███████▍  | 74/100 [07:38<02:38,  6.09s/it]Best trial: 16. Best value: 0.546442:  74%|███████▍  | 74/100 [07:38<02:38,  6.09s/it]Best trial: 16. Best value: 0.546442:  75%|███████▌  | 75/100 [07:38<02:33,  6.15s/it]                                                                                      Best trial: 16. Best value: 0.546442:  75%|███████▌  | 75/100 [07:44<02:33,  6.15s/it]Best trial: 16. Best value: 0.546442:  75%|███████▌  | 75/100 [07:44<02:33,  6.15s/it]Best trial: 16. Best value: 0.546442:  76%|███████▌  | 76/100 [07:44<02:27,  6.14s/it]                                                                                      Best trial: 16. Best value: 0.546442:  76%|███████▌  | 76/100 [07:50<02:27,  6.14s/it]Best trial: 16. Best value: 0.546442:  76%|███████▌  | 76/100 [07:50<02:27,  6.14s/it]Best trial: 16. Best value: 0.546442:  77%|███████▋  | 77/100 [07:50<02:20,  6.13s/it]                                                                                      Best trial: 16. Best value: 0.546442:  77%|███████▋  | 77/100 [07:56<02:20,  6.13s/it]Best trial: 16. Best value: 0.546442:  77%|███████▋  | 77/100 [07:56<02:20,  6.13s/it]Best trial: 16. Best value: 0.546442:  78%|███████▊  | 78/100 [07:56<02:14,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  78%|███████▊  | 78/100 [08:02<02:14,  6.12s/it]Best trial: 16. Best value: 0.546442:  78%|███████▊  | 78/100 [08:02<02:14,  6.12s/it]Best trial: 16. Best value: 0.546442:  79%|███████▉  | 79/100 [08:02<02:08,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  79%|███████▉  | 79/100 [08:08<02:08,  6.12s/it]Best trial: 16. Best value: 0.546442:  79%|███████▉  | 79/100 [08:08<02:08,  6.12s/it]Best trial: 16. Best value: 0.546442:  80%|████████  | 80/100 [08:08<02:02,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  80%|████████  | 80/100 [08:14<02:02,  6.12s/it]Best trial: 16. Best value: 0.546442:  80%|████████  | 80/100 [08:14<02:02,  6.12s/it]Best trial: 16. Best value: 0.546442:  81%|████████  | 81/100 [08:14<01:56,  6.12s/it]                                                                                      Best trial: 16. Best value: 0.546442:  81%|████████  | 81/100 [08:20<01:56,  6.12s/it]Best trial: 16. Best value: 0.546442:  81%|████████  | 81/100 [08:20<01:56,  6.12s/it]Best trial: 16. Best value: 0.546442:  82%|████████▏ | 82/100 [08:20<01:50,  6.11s/it]                                                                                      Best trial: 16. Best value: 0.546442:  82%|████████▏ | 82/100 [08:27<01:50,  6.11s/it]Best trial: 82. Best value: 0.546442:  82%|████████▏ | 82/100 [08:27<01:50,  6.11s/it]Best trial: 82. Best value: 0.546442:  83%|████████▎ | 83/100 [08:27<01:43,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  83%|████████▎ | 83/100 [08:33<01:43,  6.12s/it]Best trial: 82. Best value: 0.546442:  83%|████████▎ | 83/100 [08:33<01:43,  6.12s/it]Best trial: 82. Best value: 0.546442:  84%|████████▍ | 84/100 [08:33<01:37,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  84%|████████▍ | 84/100 [08:39<01:37,  6.12s/it]Best trial: 82. Best value: 0.546442:  84%|████████▍ | 84/100 [08:39<01:37,  6.12s/it]Best trial: 82. Best value: 0.546442:  85%|████████▌ | 85/100 [08:39<01:31,  6.11s/it]                                                                                      Best trial: 82. Best value: 0.546442:  85%|████████▌ | 85/100 [08:45<01:31,  6.11s/it]Best trial: 82. Best value: 0.546442:  85%|████████▌ | 85/100 [08:45<01:31,  6.11s/it]Best trial: 82. Best value: 0.546442:  86%|████████▌ | 86/100 [08:45<01:25,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  86%|████████▌ | 86/100 [08:51<01:25,  6.12s/it]Best trial: 82. Best value: 0.546442:  86%|████████▌ | 86/100 [08:51<01:25,  6.12s/it]Best trial: 82. Best value: 0.546442:  87%|████████▋ | 87/100 [08:51<01:19,  6.11s/it]                                                                                      Best trial: 82. Best value: 0.546442:  87%|████████▋ | 87/100 [08:57<01:19,  6.11s/it]Best trial: 82. Best value: 0.546442:  87%|████████▋ | 87/100 [08:57<01:19,  6.11s/it]Best trial: 82. Best value: 0.546442:  88%|████████▊ | 88/100 [08:57<01:13,  6.11s/it]                                                                                      Best trial: 82. Best value: 0.546442:  88%|████████▊ | 88/100 [09:03<01:13,  6.11s/it]Best trial: 82. Best value: 0.546442:  88%|████████▊ | 88/100 [09:03<01:13,  6.11s/it]Best trial: 82. Best value: 0.546442:  89%|████████▉ | 89/100 [09:03<01:07,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  89%|████████▉ | 89/100 [09:09<01:07,  6.12s/it]Best trial: 82. Best value: 0.546442:  89%|████████▉ | 89/100 [09:09<01:07,  6.12s/it]Best trial: 82. Best value: 0.546442:  90%|█████████ | 90/100 [09:09<01:01,  6.11s/it]                                                                                      Best trial: 82. Best value: 0.546442:  90%|█████████ | 90/100 [09:16<01:01,  6.11s/it]Best trial: 82. Best value: 0.546442:  90%|█████████ | 90/100 [09:16<01:01,  6.11s/it]Best trial: 82. Best value: 0.546442:  91%|█████████ | 91/100 [09:16<00:54,  6.11s/it]                                                                                      Best trial: 82. Best value: 0.546442:  91%|█████████ | 91/100 [09:22<00:54,  6.11s/it]Best trial: 82. Best value: 0.546442:  91%|█████████ | 91/100 [09:22<00:54,  6.11s/it]Best trial: 82. Best value: 0.546442:  92%|█████████▏| 92/100 [09:22<00:49,  6.16s/it]                                                                                      Best trial: 82. Best value: 0.546442:  92%|█████████▏| 92/100 [09:28<00:49,  6.16s/it]Best trial: 82. Best value: 0.546442:  92%|█████████▏| 92/100 [09:28<00:49,  6.16s/it]Best trial: 82. Best value: 0.546442:  93%|█████████▎| 93/100 [09:28<00:43,  6.14s/it]                                                                                      Best trial: 82. Best value: 0.546442:  93%|█████████▎| 93/100 [09:34<00:43,  6.14s/it]Best trial: 82. Best value: 0.546442:  93%|█████████▎| 93/100 [09:34<00:43,  6.14s/it]Best trial: 82. Best value: 0.546442:  94%|█████████▍| 94/100 [09:34<00:36,  6.13s/it]                                                                                      Best trial: 82. Best value: 0.546442:  94%|█████████▍| 94/100 [09:40<00:36,  6.13s/it]Best trial: 82. Best value: 0.546442:  94%|█████████▍| 94/100 [09:40<00:36,  6.13s/it]Best trial: 82. Best value: 0.546442:  95%|█████████▌| 95/100 [09:40<00:30,  6.13s/it]                                                                                      Best trial: 82. Best value: 0.546442:  95%|█████████▌| 95/100 [09:46<00:30,  6.13s/it]Best trial: 82. Best value: 0.546442:  95%|█████████▌| 95/100 [09:46<00:30,  6.13s/it]Best trial: 82. Best value: 0.546442:  96%|█████████▌| 96/100 [09:46<00:24,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  96%|█████████▌| 96/100 [09:52<00:24,  6.12s/it]Best trial: 82. Best value: 0.546442:  96%|█████████▌| 96/100 [09:52<00:24,  6.12s/it]Best trial: 82. Best value: 0.546442:  97%|█████████▋| 97/100 [09:52<00:18,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  97%|█████████▋| 97/100 [09:58<00:18,  6.12s/it]Best trial: 82. Best value: 0.546442:  97%|█████████▋| 97/100 [09:58<00:18,  6.12s/it]Best trial: 82. Best value: 0.546442:  98%|█████████▊| 98/100 [09:58<00:12,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  98%|█████████▊| 98/100 [10:05<00:12,  6.12s/it]Best trial: 82. Best value: 0.546442:  98%|█████████▊| 98/100 [10:05<00:12,  6.12s/it]Best trial: 82. Best value: 0.546442:  99%|█████████▉| 99/100 [10:05<00:06,  6.12s/it]                                                                                      Best trial: 82. Best value: 0.546442:  99%|█████████▉| 99/100 [10:11<00:06,  6.12s/it]Best trial: 82. Best value: 0.546442:  99%|█████████▉| 99/100 [10:11<00:06,  6.12s/it]Best trial: 82. Best value: 0.546442: 100%|██████████| 100/100 [10:11<00:00,  6.12s/it]Best trial: 82. Best value: 0.546442: 100%|██████████| 100/100 [10:11<00:00,  6.11s/it]
[I 2025-05-15 03:24:14,250] Trial 0 finished with value: 0.5374864214903362 and parameters: {'threshold_scale_factor': 0.5532596218575241}. Best is trial 0 with value: 0.5374864214903362.
[I 2025-05-15 03:24:20,338] Trial 1 finished with value: 0.5179543752506526 and parameters: {'threshold_scale_factor': 0.030369627471602767}. Best is trial 0 with value: 0.5374864214903362.
[I 2025-05-15 03:24:26,424] Trial 2 finished with value: 0.5417787165180927 and parameters: {'threshold_scale_factor': 0.674201633976032}. Best is trial 2 with value: 0.5417787165180927.
[I 2025-05-15 03:24:32,498] Trial 3 finished with value: 0.5306062576954738 and parameters: {'threshold_scale_factor': 0.3791961482987082}. Best is trial 2 with value: 0.5417787165180927.
[I 2025-05-15 03:24:38,559] Trial 4 finished with value: 0.5425432191882023 and parameters: {'threshold_scale_factor': 0.6976220000680351}. Best is trial 4 with value: 0.5425432191882023.
[I 2025-05-15 03:24:44,635] Trial 5 finished with value: 0.5370083571966312 and parameters: {'threshold_scale_factor': 0.5409538998049729}. Best is trial 4 with value: 0.5425432191882023.
[I 2025-05-15 03:24:50,718] Trial 6 finished with value: 0.546388506216184 and parameters: {'threshold_scale_factor': 0.9539563765887242}. Best is trial 6 with value: 0.546388506216184.
[I 2025-05-15 03:24:56,793] Trial 7 finished with value: 0.5291010997051975 and parameters: {'threshold_scale_factor': 0.3412361057064829}. Best is trial 6 with value: 0.546388506216184.
[I 2025-05-15 03:25:03,043] Trial 8 finished with value: 0.5201275010729689 and parameters: {'threshold_scale_factor': 0.09982429453915564}. Best is trial 6 with value: 0.546388506216184.
[I 2025-05-15 03:25:09,127] Trial 9 finished with value: 0.5462057862927341 and parameters: {'threshold_scale_factor': 0.8751273423557744}. Best is trial 6 with value: 0.546388506216184.
[I 2025-05-15 03:25:15,240] Trial 10 finished with value: 0.5464403689605921 and parameters: {'threshold_scale_factor': 0.9339062475162133}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:21,286] Trial 11 finished with value: 0.5461732989045163 and parameters: {'threshold_scale_factor': 0.9909362533033904}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:27,374] Trial 12 finished with value: 0.5461035172273077 and parameters: {'threshold_scale_factor': 0.9991617317404721}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:33,473] Trial 13 finished with value: 0.545477599926827 and parameters: {'threshold_scale_factor': 0.8164907525039788}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:39,573] Trial 14 finished with value: 0.5457357935396717 and parameters: {'threshold_scale_factor': 0.8354526068314191}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:45,673] Trial 15 finished with value: 0.5428321482596796 and parameters: {'threshold_scale_factor': 0.7100536856850832}. Best is trial 10 with value: 0.5464403689605921.
[I 2025-05-15 03:25:51,787] Trial 16 finished with value: 0.5464415833503367 and parameters: {'threshold_scale_factor': 0.9258609967457134}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:25:57,884] Trial 17 finished with value: 0.5254920178148019 and parameters: {'threshold_scale_factor': 0.24640890074470456}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:03,996] Trial 18 finished with value: 0.5446753737801575 and parameters: {'threshold_scale_factor': 0.7799670720028974}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:10,101] Trial 19 finished with value: 0.5396841672002195 and parameters: {'threshold_scale_factor': 0.6139317009003229}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:16,201] Trial 20 finished with value: 0.5463819136136889 and parameters: {'threshold_scale_factor': 0.900406741523178}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:22,305] Trial 21 finished with value: 0.5464405758149287 and parameters: {'threshold_scale_factor': 0.9291804418774848}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:28,399] Trial 22 finished with value: 0.5441121572655827 and parameters: {'threshold_scale_factor': 0.7593767579836828}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:34,497] Trial 23 finished with value: 0.546440840363332 and parameters: {'threshold_scale_factor': 0.918203863900824}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:40,745] Trial 24 finished with value: 0.5462185535675338 and parameters: {'threshold_scale_factor': 0.8764556037346777}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:46,824] Trial 25 finished with value: 0.531563638666282 and parameters: {'threshold_scale_factor': 0.40206776344766665}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:52,931] Trial 26 finished with value: 0.5402617931597352 and parameters: {'threshold_scale_factor': 0.6306845034547395}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:26:59,024] Trial 27 finished with value: 0.5445786771172667 and parameters: {'threshold_scale_factor': 0.776144993671154}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:05,123] Trial 28 finished with value: 0.5462401733636346 and parameters: {'threshold_scale_factor': 0.8795656121550357}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:11,226] Trial 29 finished with value: 0.5362527506701658 and parameters: {'threshold_scale_factor': 0.5221730391175987}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:17,334] Trial 30 finished with value: 0.5463829661786124 and parameters: {'threshold_scale_factor': 0.9549602779870412}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:23,440] Trial 31 finished with value: 0.5464248689570743 and parameters: {'threshold_scale_factor': 0.9373473218704409}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:29,555] Trial 32 finished with value: 0.5458111448050715 and parameters: {'threshold_scale_factor': 0.841997687834078}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:35,673] Trial 33 finished with value: 0.5464411541627676 and parameters: {'threshold_scale_factor': 0.9254398375175755}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:41,773] Trial 34 finished with value: 0.5441971729907338 and parameters: {'threshold_scale_factor': 0.762048363003339}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:47,887] Trial 35 finished with value: 0.5396050841137277 and parameters: {'threshold_scale_factor': 0.6116482076855703}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:27:53,989] Trial 36 finished with value: 0.5428636027833869 and parameters: {'threshold_scale_factor': 0.7114616657746669}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:00,106] Trial 37 finished with value: 0.5331268959888551 and parameters: {'threshold_scale_factor': 0.4435429247494755}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:06,206] Trial 38 finished with value: 0.5464255542500124 and parameters: {'threshold_scale_factor': 0.911219983832845}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:12,315] Trial 39 finished with value: 0.5461635894152495 and parameters: {'threshold_scale_factor': 0.9925780082176332}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:18,421] Trial 40 finished with value: 0.5455892041736732 and parameters: {'threshold_scale_factor': 0.8233428413899105}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:24,684] Trial 41 finished with value: 0.5464235856158842 and parameters: {'threshold_scale_factor': 0.9377691453869007}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:30,798] Trial 42 finished with value: 0.5464206516615188 and parameters: {'threshold_scale_factor': 0.9411684276564194}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:36,918] Trial 43 finished with value: 0.5460720711466345 and parameters: {'threshold_scale_factor': 0.8637897683259524}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:43,019] Trial 44 finished with value: 0.5254832820888067 and parameters: {'threshold_scale_factor': 0.24616460121159411}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:49,125] Trial 45 finished with value: 0.5463190327097214 and parameters: {'threshold_scale_factor': 0.968328712423942}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:28:55,220] Trial 46 finished with value: 0.5450945113242196 and parameters: {'threshold_scale_factor': 0.7999622294264801}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:01,337] Trial 47 finished with value: 0.5463422651253439 and parameters: {'threshold_scale_factor': 0.8951545573978743}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:07,450] Trial 48 finished with value: 0.5414837295696163 and parameters: {'threshold_scale_factor': 0.6666067097616066}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:13,541] Trial 49 finished with value: 0.519319877013136 and parameters: {'threshold_scale_factor': 0.07545289230729602}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:19,636] Trial 50 finished with value: 0.5433567055280766 and parameters: {'threshold_scale_factor': 0.731143015453683}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:25,734] Trial 51 finished with value: 0.5464396133090361 and parameters: {'threshold_scale_factor': 0.9163782492306278}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:31,827] Trial 52 finished with value: 0.5464343209337996 and parameters: {'threshold_scale_factor': 0.9146779046377492}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:37,903] Trial 53 finished with value: 0.5461317887271422 and parameters: {'threshold_scale_factor': 0.9963379286852616}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:44,024] Trial 54 finished with value: 0.5458697408692104 and parameters: {'threshold_scale_factor': 0.846804347596169}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:50,117] Trial 55 finished with value: 0.5464373702762982 and parameters: {'threshold_scale_factor': 0.9155296561013005}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:29:56,224] Trial 56 finished with value: 0.5463288027073996 and parameters: {'threshold_scale_factor': 0.9665296483441266}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:02,331] Trial 57 finished with value: 0.5453427210491877 and parameters: {'threshold_scale_factor': 0.8104749762966945}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:08,596] Trial 58 finished with value: 0.5461147098762391 and parameters: {'threshold_scale_factor': 0.8678474295296242}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:14,718] Trial 59 finished with value: 0.5463408396597457 and parameters: {'threshold_scale_factor': 0.9640306138354415}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:20,763] Trial 60 finished with value: 0.5464153044065603 and parameters: {'threshold_scale_factor': 0.9080692524315571}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:26,836] Trial 61 finished with value: 0.546441140091044 and parameters: {'threshold_scale_factor': 0.9285994853528448}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:32,954] Trial 62 finished with value: 0.5460614526240246 and parameters: {'threshold_scale_factor': 0.8627910253183446}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:39,056] Trial 63 finished with value: 0.5464386761322461 and parameters: {'threshold_scale_factor': 0.9302557754054527}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:45,170] Trial 64 finished with value: 0.5457232879989306 and parameters: {'threshold_scale_factor': 0.8343532111262685}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:51,290] Trial 65 finished with value: 0.5461021170908119 and parameters: {'threshold_scale_factor': 0.9992662627167883}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:30:57,401] Trial 66 finished with value: 0.5449666331290588 and parameters: {'threshold_scale_factor': 0.7944681807306738}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:03,481] Trial 67 finished with value: 0.5436199030458245 and parameters: {'threshold_scale_factor': 0.739887795650685}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:09,576] Trial 68 finished with value: 0.5463583899133886 and parameters: {'threshold_scale_factor': 0.89743627005101}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:15,664] Trial 69 finished with value: 0.5463105784181976 and parameters: {'threshold_scale_factor': 0.9697023372502657}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:21,781] Trial 70 finished with value: 0.5461392636267054 and parameters: {'threshold_scale_factor': 0.8701003256605016}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:27,865] Trial 71 finished with value: 0.5464386550246607 and parameters: {'threshold_scale_factor': 0.9343257090405996}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:33,966] Trial 72 finished with value: 0.5464405321925856 and parameters: {'threshold_scale_factor': 0.9169353761084059}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:40,053] Trial 73 finished with value: 0.5463896713548959 and parameters: {'threshold_scale_factor': 0.9536427558065658}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:46,329] Trial 74 finished with value: 0.5462998163640074 and parameters: {'threshold_scale_factor': 0.8882639357840538}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:52,432] Trial 75 finished with value: 0.5458666507187133 and parameters: {'threshold_scale_factor': 0.8465328254494799}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:31:58,540] Trial 76 finished with value: 0.5464403140808702 and parameters: {'threshold_scale_factor': 0.9278500754739708}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:04,649] Trial 77 finished with value: 0.5280615792695368 and parameters: {'threshold_scale_factor': 0.31430903102128516}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:10,769] Trial 78 finished with value: 0.5462566780882157 and parameters: {'threshold_scale_factor': 0.9790480938015916}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:16,888] Trial 79 finished with value: 0.546415598505583 and parameters: {'threshold_scale_factor': 0.9450082903265186}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:22,991] Trial 80 finished with value: 0.5455248555889368 and parameters: {'threshold_scale_factor': 0.8190530280976973}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:29,104] Trial 81 finished with value: 0.5463194717474971 and parameters: {'threshold_scale_factor': 0.8921113066324514}. Best is trial 16 with value: 0.5464415833503367.
[I 2025-05-15 03:32:35,221] Trial 82 finished with value: 0.5464418183481204 and parameters: {'threshold_scale_factor': 0.9258002263474023}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:32:41,338] Trial 83 finished with value: 0.5339928881509052 and parameters: {'threshold_scale_factor': 0.4684013928021657}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:32:47,434] Trial 84 finished with value: 0.5464033687706239 and parameters: {'threshold_scale_factor': 0.9495174008272455}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:32:53,562] Trial 85 finished with value: 0.5464402957876295 and parameters: {'threshold_scale_factor': 0.9224314547498429}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:32:59,674] Trial 86 finished with value: 0.5458935530398441 and parameters: {'threshold_scale_factor': 0.8488242459348161}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:05,783] Trial 87 finished with value: 0.5447226688430933 and parameters: {'threshold_scale_factor': 0.7821719585458512}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:11,915] Trial 88 finished with value: 0.5462912987497274 and parameters: {'threshold_scale_factor': 0.8870522347128985}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:18,022] Trial 89 finished with value: 0.5462580697816771 and parameters: {'threshold_scale_factor': 0.9788103881145946}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:24,121] Trial 90 finished with value: 0.5464397047752394 and parameters: {'threshold_scale_factor': 0.9228766563062927}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:30,411] Trial 91 finished with value: 0.5464402254290117 and parameters: {'threshold_scale_factor': 0.9294578386712017}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:36,510] Trial 92 finished with value: 0.5383128270796248 and parameters: {'threshold_scale_factor': 0.5759104057441458}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:42,621] Trial 93 finished with value: 0.5464027594649931 and parameters: {'threshold_scale_factor': 0.9047095714207138}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:48,732] Trial 94 finished with value: 0.5463697570516924 and parameters: {'threshold_scale_factor': 0.9584364233003543}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:33:54,849] Trial 95 finished with value: 0.5461433148759226 and parameters: {'threshold_scale_factor': 0.8704845561794319}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:34:00,962] Trial 96 finished with value: 0.5220300923808652 and parameters: {'threshold_scale_factor': 0.15219242219801177}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:34:07,080] Trial 97 finished with value: 0.5456372295590626 and parameters: {'threshold_scale_factor': 0.8272817024156061}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:34:13,184] Trial 98 finished with value: 0.5462716504020995 and parameters: {'threshold_scale_factor': 0.9766531041487537}. Best is trial 82 with value: 0.5464418183481204.
[I 2025-05-15 03:34:19,307] Trial 99 finished with value: 0.5464396541170345 and parameters: {'threshold_scale_factor': 0.9227780194680234}. Best is trial 82 with value: 0.5464418183481204.
Best hyperparameters: {'threshold_scale_factor': 0.9258002263474023}
Best optimized value: 0.5464418183481204
Running audit 1/1
Training a GraphSAGE target model on github...
Training GraphSAGE on cuda:   0%|          | 0/300 [00:00<?, ?it/s]Training GraphSAGE on cuda:   5%|▍         | 14/300 [00:00<00:02, 134.57it/s]Training GraphSAGE on cuda:  10%|▉         | 29/300 [00:00<00:01, 138.73it/s]Training GraphSAGE on cuda:  15%|█▌        | 46/300 [00:00<00:01, 148.96it/s]Training GraphSAGE on cuda:  21%|██        | 63/300 [00:00<00:01, 153.53it/s]Training GraphSAGE on cuda:  27%|██▋       | 80/300 [00:00<00:01, 156.05it/s]Training GraphSAGE on cuda:  32%|███▏      | 97/300 [00:00<00:01, 157.47it/s]Training GraphSAGE on cuda:  38%|███▊      | 114/300 [00:00<00:01, 158.44it/s]Training GraphSAGE on cuda:  44%|████▎     | 131/300 [00:00<00:01, 158.99it/s]Training GraphSAGE on cuda:  49%|████▉     | 148/300 [00:00<00:00, 159.53it/s]Training GraphSAGE on cuda:  55%|█████▌    | 165/300 [00:01<00:00, 159.89it/s]Training GraphSAGE on cuda:  61%|██████    | 182/300 [00:01<00:00, 160.22it/s]Training GraphSAGE on cuda:  66%|██████▋   | 199/300 [00:01<00:00, 160.22it/s]Training GraphSAGE on cuda:  72%|███████▏  | 216/300 [00:01<00:00, 160.36it/s]Training GraphSAGE on cuda:  78%|███████▊  | 233/300 [00:01<00:00, 160.38it/s]Training GraphSAGE on cuda:  83%|████████▎ | 250/300 [00:01<00:00, 160.44it/s]Training GraphSAGE on cuda:  89%|████████▉ | 267/300 [00:01<00:00, 160.50it/s]Training GraphSAGE on cuda:  95%|█████████▍| 284/300 [00:01<00:00, 160.61it/s]Training GraphSAGE on cuda: 100%|██████████| 300/300 [00:01<00:00, 158.11it/s]
Train accuracy: 0.9603 | Test accuracy: 0.8377
Training MLP on cuda:   0%|          | 0/1000 [00:00<?, ?it/s]Training MLP on cuda:   0%|          | 1/1000 [00:39<11:03:43, 39.86s/it]Training MLP on cuda:   0%|          | 2/1000 [01:18<10:52:45, 39.24s/it]Training MLP on cuda:   0%|          | 3/1000 [01:57<10:49:57, 39.11s/it]Training MLP on cuda:   0%|          | 4/1000 [02:36<10:47:08, 38.98s/it]Training MLP on cuda:   0%|          | 5/1000 [03:15<10:46:02, 38.96s/it]Training MLP on cuda:   1%|          | 6/1000 [03:54<10:44:31, 38.90s/it]Training MLP on cuda:   1%|          | 7/1000 [04:32<10:43:35, 38.89s/it]Training MLP on cuda:   1%|          | 8/1000 [05:11<10:42:07, 38.84s/it]Training MLP on cuda:   1%|          | 9/1000 [05:50<10:42:03, 38.87s/it]Training MLP on cuda:   1%|          | 10/1000 [06:29<10:40:47, 38.84s/it]Training MLP on cuda:   1%|          | 11/1000 [07:08<10:40:31, 38.86s/it]Training MLP on cuda:   1%|          | 12/1000 [07:47<10:39:50, 38.86s/it]Training MLP on cuda:   1%|▏         | 13/1000 [08:26<10:39:43, 38.89s/it]Training MLP on cuda:   1%|▏         | 14/1000 [09:04<10:38:04, 38.83s/it]Training MLP on cuda:   2%|▏         | 15/1000 [09:43<10:38:45, 38.91s/it]Training MLP on cuda:   2%|▏         | 16/1000 [10:22<10:37:25, 38.87s/it]Training MLP on cuda:   2%|▏         | 17/1000 [11:01<10:36:37, 38.86s/it]Training MLP on cuda:   2%|▏         | 18/1000 [11:40<10:35:07, 38.81s/it]Training MLP on cuda:   2%|▏         | 19/1000 [12:19<10:35:03, 38.84s/it]Training MLP on cuda:   2%|▏         | 20/1000 [12:57<10:33:26, 38.78s/it]Training MLP on cuda:   2%|▏         | 21/1000 [13:36<10:33:49, 38.84s/it]Training MLP on cuda:   2%|▏         | 22/1000 [14:15<10:32:56, 38.83s/it]Training MLP on cuda:   2%|▏         | 23/1000 [14:54<10:33:34, 38.91s/it]Training MLP on cuda:   2%|▏         | 24/1000 [15:33<10:31:36, 38.83s/it]Training MLP on cuda:   2%|▎         | 25/1000 [16:12<10:30:53, 38.82s/it]Training MLP on cuda:   3%|▎         | 26/1000 [16:50<10:29:18, 38.77s/it]Training MLP on cuda:   3%|▎         | 27/1000 [17:29<10:29:09, 38.80s/it]Training MLP on cuda:   3%|▎         | 28/1000 [18:08<10:28:19, 38.79s/it]Training MLP on cuda:   3%|▎         | 29/1000 [18:47<10:27:47, 38.79s/it]Training MLP on cuda:   3%|▎         | 30/1000 [19:25<10:26:41, 38.76s/it]Training MLP on cuda:   3%|▎         | 31/1000 [20:04<10:26:12, 38.77s/it]Training MLP on cuda:   3%|▎         | 32/1000 [20:43<10:25:10, 38.75s/it]Training MLP on cuda:   3%|▎         | 33/1000 [21:22<10:25:19, 38.80s/it]Training MLP on cuda:   3%|▎         | 34/1000 [22:00<10:24:01, 38.76s/it]Training MLP on cuda:   4%|▎         | 35/1000 [22:39<10:23:46, 38.78s/it]Training MLP on cuda:   4%|▎         | 36/1000 [23:18<10:23:21, 38.80s/it]Training MLP on cuda:   4%|▎         | 37/1000 [23:57<10:21:05, 38.70s/it]Training MLP on cuda:   4%|▍         | 38/1000 [24:35<10:20:50, 38.72s/it]Training MLP on cuda:   4%|▍         | 39/1000 [25:14<10:20:40, 38.75s/it]Training MLP on cuda:   4%|▍         | 40/1000 [25:53<10:20:01, 38.75s/it]Training MLP on cuda:   4%|▍         | 41/1000 [26:32<10:19:11, 38.74s/it]Training MLP on cuda:   4%|▍         | 42/1000 [27:11<10:19:09, 38.78s/it]Training MLP on cuda:   4%|▍         | 43/1000 [27:49<10:17:30, 38.71s/it]Training MLP on cuda:   4%|▍         | 44/1000 [28:28<10:17:59, 38.79s/it]Training MLP on cuda:   4%|▍         | 45/1000 [29:07<10:17:13, 38.78s/it]Training MLP on cuda:   5%|▍         | 46/1000 [29:46<10:17:12, 38.82s/it]Training MLP on cuda:   5%|▍         | 47/1000 [30:24<10:16:18, 38.80s/it]Training MLP on cuda:   5%|▍         | 48/1000 [31:03<10:16:16, 38.84s/it]Training MLP on cuda:   5%|▍         | 49/1000 [31:42<10:14:55, 38.80s/it]Training MLP on cuda:   5%|▌         | 50/1000 [32:21<10:15:05, 38.85s/it]Training MLP on cuda:   5%|▌         | 51/1000 [33:00<10:14:45, 38.87s/it]Training MLP on cuda:   5%|▌         | 52/1000 [33:39<10:13:18, 38.82s/it]Training MLP on cuda:   5%|▌         | 53/1000 [34:18<10:12:57, 38.84s/it]Training MLP on cuda:   5%|▌         | 54/1000 [34:56<10:12:28, 38.85s/it]Training MLP on cuda:   6%|▌         | 55/1000 [35:35<10:11:58, 38.86s/it]Training MLP on cuda:   6%|▌         | 56/1000 [36:14<10:10:49, 38.82s/it]Training MLP on cuda:   6%|▌         | 57/1000 [36:53<10:10:26, 38.84s/it]Training MLP on cuda:   6%|▌         | 58/1000 [37:32<10:09:22, 38.81s/it]Training MLP on cuda:   6%|▌         | 59/1000 [38:11<10:09:36, 38.87s/it]Training MLP on cuda:   6%|▌         | 60/1000 [38:49<10:08:07, 38.82s/it]Training MLP on cuda:   6%|▌         | 61/1000 [39:28<10:07:51, 38.84s/it]Training MLP on cuda:   6%|▌         | 62/1000 [40:07<10:06:37, 38.80s/it]Training MLP on cuda:   6%|▋         | 63/1000 [40:46<10:06:30, 38.84s/it]Training MLP on cuda:   6%|▋         | 64/1000 [41:25<10:05:12, 38.80s/it]Training MLP on cuda:   6%|▋         | 65/1000 [42:04<10:05:24, 38.85s/it]Training MLP on cuda:   7%|▋         | 66/1000 [42:42<10:04:23, 38.83s/it]Training MLP on cuda:   7%|▋         | 67/1000 [43:21<10:03:45, 38.83s/it]Training MLP on cuda:   7%|▋         | 68/1000 [44:00<10:02:33, 38.79s/it]Training MLP on cuda:   7%|▋         | 69/1000 [44:39<10:02:50, 38.85s/it]Training MLP on cuda:   7%|▋         | 70/1000 [45:18<10:01:15, 38.79s/it]Training MLP on cuda:   7%|▋         | 71/1000 [45:57<10:01:30, 38.85s/it]Training MLP on cuda:   7%|▋         | 72/1000 [46:35<10:00:43, 38.84s/it]Training MLP on cuda:   7%|▋         | 73/1000 [47:14<10:00:13, 38.85s/it]Training MLP on cuda:   7%|▋         | 74/1000 [47:53<9:58:36, 38.79s/it] Training MLP on cuda:   8%|▊         | 75/1000 [48:32<9:58:10, 38.80s/it]Training MLP on cuda:   8%|▊         | 76/1000 [49:10<9:56:42, 38.75s/it]Training MLP on cuda:   8%|▊         | 77/1000 [49:49<9:56:18, 38.76s/it]Training MLP on cuda:   8%|▊         | 78/1000 [50:28<9:55:04, 38.73s/it]Training MLP on cuda:   8%|▊         | 79/1000 [51:07<9:55:18, 38.78s/it]Training MLP on cuda:   8%|▊         | 80/1000 [51:45<9:53:40, 38.72s/it]Training MLP on cuda:   8%|▊         | 81/1000 [52:24<9:53:48, 38.77s/it]Training MLP on cuda:   8%|▊         | 82/1000 [53:03<9:52:49, 38.75s/it]Training MLP on cuda:   8%|▊         | 83/1000 [53:42<9:52:52, 38.79s/it]Training MLP on cuda:   8%|▊         | 84/1000 [54:20<9:51:27, 38.74s/it]Training MLP on cuda:   8%|▊         | 85/1000 [54:59<9:50:56, 38.75s/it]Training MLP on cuda:   9%|▊         | 86/1000 [55:38<9:49:55, 38.73s/it]Training MLP on cuda:   9%|▊         | 87/1000 [56:17<9:50:11, 38.79s/it]Training MLP on cuda:   9%|▉         | 88/1000 [56:56<9:49:43, 38.80s/it]Training MLP on cuda:   9%|▉         | 89/1000 [57:35<9:50:18, 38.88s/it]Training MLP on cuda:   9%|▉         | 90/1000 [58:13<9:49:25, 38.86s/it]Training MLP on cuda:   9%|▉         | 91/1000 [58:52<9:49:30, 38.91s/it]Training MLP on cuda:   9%|▉         | 92/1000 [59:31<9:48:32, 38.89s/it]Training MLP on cuda:   9%|▉         | 93/1000 [1:00:10<9:48:23, 38.92s/it]Training MLP on cuda:   9%|▉         | 94/1000 [1:00:49<9:47:14, 38.89s/it]Training MLP on cuda:  10%|▉         | 95/1000 [1:01:28<9:47:20, 38.94s/it]Training MLP on cuda:  10%|▉         | 96/1000 [1:02:07<9:46:32, 38.93s/it]Training MLP on cuda:  10%|▉         | 97/1000 [1:02:46<9:46:16, 38.96s/it]Training MLP on cuda:  10%|▉         | 98/1000 [1:03:25<9:45:16, 38.93s/it]Training MLP on cuda:  10%|▉         | 99/1000 [1:04:04<9:44:56, 38.95s/it]Training MLP on cuda:  10%|█         | 100/1000 [1:04:43<9:43:50, 38.92s/it]Training MLP on cuda:  10%|█         | 101/1000 [1:05:22<9:43:22, 38.94s/it]Training MLP on cuda:  10%|█         | 102/1000 [1:06:01<9:42:40, 38.93s/it]Training MLP on cuda:  10%|█         | 103/1000 [1:06:40<9:42:27, 38.96s/it]Training MLP on cuda:  10%|█         | 104/1000 [1:07:19<9:41:14, 38.92s/it]Training MLP on cuda:  10%|█         | 105/1000 [1:07:58<9:40:59, 38.95s/it]Training MLP on cuda:  11%|█         | 106/1000 [1:08:37<9:40:40, 38.97s/it]Training MLP on cuda:  11%|█         | 107/1000 [1:09:15<9:38:29, 38.87s/it]Training MLP on cuda:  11%|█         | 108/1000 [1:09:54<9:38:08, 38.89s/it]Training MLP on cuda:  11%|█         | 109/1000 [1:10:33<9:37:28, 38.89s/it]Training MLP on cuda:  11%|█         | 110/1000 [1:11:12<9:37:52, 38.96s/it]Training MLP on cuda:  11%|█         | 111/1000 [1:11:51<9:37:04, 38.95s/it]Training MLP on cuda:  11%|█         | 112/1000 [1:12:30<9:36:20, 38.94s/it]Training MLP on cuda:  11%|█▏        | 113/1000 [1:13:09<9:35:43, 38.94s/it]Training MLP on cuda:  11%|█▏        | 114/1000 [1:13:48<9:35:09, 38.95s/it]Training MLP on cuda:  12%|█▏        | 115/1000 [1:14:27<9:34:12, 38.93s/it]Training MLP on cuda:  12%|█▏        | 116/1000 [1:15:06<9:33:54, 38.95s/it]Training MLP on cuda:  12%|█▏        | 117/1000 [1:15:45<9:33:06, 38.94s/it]Training MLP on cuda:  12%|█▏        | 118/1000 [1:16:24<9:33:32, 39.02s/it]Training MLP on cuda:  12%|█▏        | 119/1000 [1:17:03<9:32:43, 39.01s/it]Training MLP on cuda:  12%|█▏        | 120/1000 [1:17:42<9:32:46, 39.05s/it]Training MLP on cuda:  12%|█▏        | 121/1000 [1:18:21<9:31:27, 39.01s/it]Training MLP on cuda:  12%|█▏        | 122/1000 [1:19:00<9:31:09, 39.03s/it]Training MLP on cuda:  12%|█▏        | 123/1000 [1:19:39<9:30:55, 39.06s/it]Training MLP on cuda:  12%|█▏        | 124/1000 [1:20:18<9:29:25, 39.00s/it]Training MLP on cuda:  12%|█▎        | 125/1000 [1:20:57<9:29:17, 39.04s/it]Training MLP on cuda:  13%|█▎        | 126/1000 [1:21:36<9:28:57, 39.06s/it]Training MLP on cuda:  13%|█▎        | 127/1000 [1:22:15<9:28:54, 39.10s/it]Training MLP on cuda:  13%|█▎        | 128/1000 [1:22:55<9:27:57, 39.08s/it]Training MLP on cuda:  13%|█▎        | 129/1000 [1:23:34<9:27:46, 39.11s/it]Training MLP on cuda:  13%|█▎        | 130/1000 [1:24:13<9:26:26, 39.06s/it]Training MLP on cuda:  13%|█▎        | 131/1000 [1:24:52<9:26:35, 39.12s/it]Training MLP on cuda:  13%|█▎        | 132/1000 [1:25:31<9:25:39, 39.10s/it]Training MLP on cuda:  13%|█▎        | 133/1000 [1:26:10<9:25:32, 39.14s/it]Training MLP on cuda:  13%|█▎        | 134/1000 [1:26:49<9:23:42, 39.06s/it]Training MLP on cuda:  14%|█▎        | 135/1000 [1:27:28<9:23:45, 39.10s/it]Training MLP on cuda:  14%|█▎        | 136/1000 [1:28:07<9:22:27, 39.06s/it]Training MLP on cuda:  14%|█▎        | 137/1000 [1:28:46<9:21:53, 39.07s/it]Training MLP on cuda:  14%|█▍        | 138/1000 [1:29:25<9:20:38, 39.02s/it]Training MLP on cuda:  14%|█▍        | 139/1000 [1:30:04<9:20:16, 39.04s/it]Training MLP on cuda:  14%|█▍        | 140/1000 [1:30:43<9:19:04, 39.00s/it]Training MLP on cuda:  14%|█▍        | 141/1000 [1:31:22<9:19:07, 39.05s/it]Training MLP on cuda:  14%|█▍        | 142/1000 [1:32:01<9:17:35, 38.99s/it]Training MLP on cuda:  14%|█▍        | 143/1000 [1:32:40<9:17:39, 39.04s/it]Training MLP on cuda:  14%|█▍        | 144/1000 [1:33:19<9:16:26, 39.00s/it]Training MLP on cuda:  14%|█▍        | 145/1000 [1:33:58<9:16:12, 39.03s/it]Training MLP on cuda:  15%|█▍        | 146/1000 [1:34:37<9:15:03, 39.00s/it]Training MLP on cuda:  15%|█▍        | 147/1000 [1:35:16<9:14:48, 39.02s/it]Training MLP on cuda:  15%|█▍        | 148/1000 [1:35:55<9:13:54, 39.01s/it]Training MLP on cuda:  15%|█▍        | 149/1000 [1:36:34<9:13:28, 39.02s/it]Training MLP on cuda:  15%|█▌        | 150/1000 [1:37:13<9:11:56, 38.96s/it]Training MLP on cuda:  15%|█▌        | 151/1000 [1:37:52<9:12:12, 39.03s/it]Training MLP on cuda:  15%|█▌        | 152/1000 [1:38:31<9:11:09, 39.00s/it]Training MLP on cuda:  15%|█▌        | 153/1000 [1:39:11<9:11:07, 39.04s/it]Training MLP on cuda:  15%|█▌        | 154/1000 [1:39:49<9:10:14, 39.02s/it]Training MLP on cuda:  16%|█▌        | 155/1000 [1:40:29<9:10:06, 39.06s/it]Training MLP on cuda:  16%|█▌        | 156/1000 [1:41:08<9:08:52, 39.02s/it]Training MLP on cuda:  16%|█▌        | 157/1000 [1:41:47<9:08:15, 39.02s/it]Training MLP on cuda:  16%|█▌        | 158/1000 [1:42:26<9:07:21, 39.00s/it]Training MLP on cuda:  16%|█▌        | 159/1000 [1:43:05<9:07:11, 39.04s/it]Training MLP on cuda:  16%|█▌        | 160/1000 [1:43:44<9:06:20, 39.02s/it]Training MLP on cuda:  16%|█▌        | 161/1000 [1:44:23<9:05:40, 39.02s/it]Training MLP on cuda:  16%|█▌        | 162/1000 [1:45:02<9:04:36, 38.99s/it]Training MLP on cuda:  16%|█▋        | 163/1000 [1:45:41<9:04:15, 39.01s/it]Training MLP on cuda:  16%|█▋        | 164/1000 [1:46:20<9:03:19, 38.99s/it]Training MLP on cuda:  16%|█▋        | 165/1000 [1:46:59<9:03:12, 39.03s/it]Training MLP on cuda:  17%|█▋        | 166/1000 [1:47:38<9:02:15, 39.01s/it]Training MLP on cuda:  17%|█▋        | 167/1000 [1:48:17<9:01:35, 39.01s/it]Training MLP on cuda:  17%|█▋        | 168/1000 [1:48:56<9:00:37, 38.99s/it]Training MLP on cuda:  17%|█▋        | 169/1000 [1:49:35<9:00:35, 39.03s/it]Training MLP on cuda:  17%|█▋        | 170/1000 [1:50:14<8:59:23, 38.99s/it]Training MLP on cuda:  17%|█▋        | 171/1000 [1:50:53<8:59:02, 39.01s/it]Training MLP on cuda:  17%|█▋        | 172/1000 [1:51:32<8:58:02, 38.99s/it]Training MLP on cuda:  17%|█▋        | 173/1000 [1:52:11<8:57:45, 39.02s/it]Training MLP on cuda:  17%|█▋        | 174/1000 [1:52:50<8:57:07, 39.02s/it]Training MLP on cuda:  18%|█▊        | 175/1000 [1:53:29<8:56:42, 39.03s/it]Training MLP on cuda:  18%|█▊        | 176/1000 [1:54:08<8:55:43, 39.01s/it]Training MLP on cuda:  18%|█▊        | 177/1000 [1:54:47<8:55:21, 39.03s/it]Training MLP on cuda:  18%|█▊        | 178/1000 [1:55:26<8:54:03, 38.98s/it]Training MLP on cuda:  18%|█▊        | 179/1000 [1:56:05<8:53:53, 39.02s/it]Training MLP on cuda:  18%|█▊        | 180/1000 [1:56:44<8:52:30, 38.96s/it]Training MLP on cuda:  18%|█▊        | 181/1000 [1:57:23<8:52:29, 39.01s/it]Training MLP on cuda:  18%|█▊        | 181/1000 [1:58:02<8:54:05, 39.13s/it]
Training MLP on cuda:   0%|          | 0/1000 [00:00<?, ?it/s]Training MLP on cuda:   0%|          | 1/1000 [00:39<11:01:46, 39.75s/it]Training MLP on cuda:   0%|          | 2/1000 [01:18<10:53:48, 39.31s/it]Training MLP on cuda:   0%|          | 3/1000 [01:57<10:48:31, 39.03s/it]Training MLP on cuda:   0%|          | 4/1000 [02:36<10:46:04, 38.92s/it]Training MLP on cuda:   0%|          | 5/1000 [03:16<10:53:17, 39.39s/it]Training MLP on cuda:   1%|          | 6/1000 [03:55<10:48:30, 39.15s/it]Training MLP on cuda:   1%|          | 7/1000 [04:33<10:46:05, 39.04s/it]Training MLP on cuda:   1%|          | 8/1000 [05:14<10:51:30, 39.41s/it]Training MLP on cuda:   1%|          | 9/1000 [05:52<10:47:17, 39.19s/it]Training MLP on cuda:   1%|          | 10/1000 [06:31<10:45:11, 39.10s/it]Training MLP on cuda:   1%|          | 11/1000 [07:11<10:49:54, 39.43s/it]Training MLP on cuda:   1%|          | 12/1000 [07:50<10:45:03, 39.17s/it]Training MLP on cuda:   1%|▏         | 13/1000 [08:29<10:42:31, 39.06s/it]Training MLP on cuda:   1%|▏         | 14/1000 [09:09<10:47:44, 39.42s/it]Training MLP on cuda:   2%|▏         | 15/1000 [09:48<10:42:57, 39.16s/it]Training MLP on cuda:   2%|▏         | 16/1000 [10:26<10:40:53, 39.08s/it]Training MLP on cuda:   2%|▏         | 17/1000 [11:07<10:45:55, 39.43s/it]Training MLP on cuda:   2%|▏         | 18/1000 [11:45<10:41:31, 39.20s/it]Training MLP on cuda:   2%|▏         | 19/1000 [12:24<10:39:12, 39.10s/it]Training MLP on cuda:   2%|▏         | 20/1000 [13:05<10:44:25, 39.45s/it]Training MLP on cuda:   2%|▏         | 21/1000 [13:43<10:39:38, 39.20s/it]Training MLP on cuda:   2%|▏         | 22/1000 [14:22<10:36:47, 39.07s/it]Training MLP on cuda:   2%|▏         | 23/1000 [15:02<10:41:38, 39.40s/it]Training MLP on cuda:   2%|▏         | 24/1000 [15:41<10:37:04, 39.16s/it]Training MLP on cuda:   2%|▎         | 25/1000 [16:19<10:34:36, 39.05s/it]Training MLP on cuda:   3%|▎         | 26/1000 [17:00<10:39:27, 39.39s/it]Training MLP on cuda:   3%|▎         | 27/1000 [17:38<10:35:09, 39.17s/it]Training MLP on cuda:   3%|▎         | 28/1000 [18:17<10:33:20, 39.09s/it]Training MLP on cuda:   3%|▎         | 29/1000 [18:57<10:38:00, 39.42s/it]Training MLP on cuda:   3%|▎         | 30/1000 [19:36<10:33:58, 39.22s/it]Training MLP on cuda:   3%|▎         | 31/1000 [20:15<10:31:16, 39.09s/it]Training MLP on cuda:   3%|▎         | 32/1000 [20:55<10:36:41, 39.46s/it]Training MLP on cuda:   3%|▎         | 33/1000 [21:34<10:32:04, 39.22s/it]Training MLP on cuda:   3%|▎         | 34/1000 [22:13<10:29:26, 39.10s/it]Training MLP on cuda:   4%|▎         | 35/1000 [22:53<10:34:37, 39.46s/it]Training MLP on cuda:   4%|▎         | 36/1000 [23:32<10:30:45, 39.26s/it]Training MLP on cuda:   4%|▎         | 37/1000 [24:11<10:28:35, 39.16s/it]Training MLP on cuda:   4%|▍         | 38/1000 [24:51<10:33:22, 39.50s/it]Training MLP on cuda:   4%|▍         | 39/1000 [25:30<10:28:57, 39.27s/it]Training MLP on cuda:   4%|▍         | 40/1000 [26:08<10:25:29, 39.09s/it]Training MLP on cuda:   4%|▍         | 41/1000 [26:49<10:30:26, 39.44s/it]Training MLP on cuda:   4%|▍         | 42/1000 [27:27<10:26:27, 39.23s/it]Training MLP on cuda:   4%|▍         | 43/1000 [28:06<10:24:00, 39.12s/it]Training MLP on cuda:   4%|▍         | 44/1000 [28:47<10:29:01, 39.48s/it]Training MLP on cuda:   4%|▍         | 45/1000 [29:25<10:24:28, 39.23s/it]Training MLP on cuda:   5%|▍         | 46/1000 [30:04<10:22:03, 39.12s/it]Training MLP on cuda:   5%|▍         | 47/1000 [30:44<10:26:14, 39.43s/it]Training MLP on cuda:   5%|▍         | 48/1000 [31:23<10:22:15, 39.22s/it]Training MLP on cuda:   5%|▍         | 49/1000 [32:02<10:19:39, 39.10s/it]Training MLP on cuda:   5%|▌         | 50/1000 [32:42<10:24:26, 39.44s/it]Training MLP on cuda:   5%|▌         | 51/1000 [33:21<10:20:33, 39.23s/it]Training MLP on cuda:   5%|▌         | 52/1000 [34:00<10:17:56, 39.11s/it]Training MLP on cuda:   5%|▌         | 53/1000 [34:40<10:22:33, 39.44s/it]Training MLP on cuda:   5%|▌         | 54/1000 [35:18<10:17:50, 39.19s/it]Training MLP on cuda:   6%|▌         | 55/1000 [35:57<10:15:20, 39.07s/it]Training MLP on cuda:   6%|▌         | 56/1000 [36:38<10:20:12, 39.42s/it]Training MLP on cuda:   6%|▌         | 57/1000 [37:16<10:16:37, 39.23s/it]Training MLP on cuda:   6%|▌         | 58/1000 [37:55<10:13:44, 39.09s/it]Training MLP on cuda:   6%|▌         | 59/1000 [38:35<10:18:35, 39.44s/it]Training MLP on cuda:   6%|▌         | 60/1000 [39:14<10:14:01, 39.19s/it]Training MLP on cuda:   6%|▌         | 61/1000 [39:53<10:11:44, 39.09s/it]Training MLP on cuda:   6%|▌         | 62/1000 [40:33<10:16:01, 39.41s/it]Training MLP on cuda:   6%|▋         | 63/1000 [41:12<10:11:43, 39.17s/it]Training MLP on cuda:   6%|▋         | 64/1000 [41:50<10:09:02, 39.04s/it]Training MLP on cuda:   6%|▋         | 65/1000 [42:30<10:13:25, 39.36s/it]Training MLP on cuda:   7%|▋         | 66/1000 [43:09<10:09:07, 39.13s/it]Training MLP on cuda:   7%|▋         | 67/1000 [43:48<10:06:38, 39.01s/it]Training MLP on cuda:   7%|▋         | 68/1000 [44:28<10:10:34, 39.31s/it]Training MLP on cuda:   7%|▋         | 69/1000 [45:06<10:06:50, 39.11s/it]Training MLP on cuda:   7%|▋         | 70/1000 [45:45<10:04:27, 39.00s/it]Training MLP on cuda:   7%|▋         | 71/1000 [46:25<10:08:43, 39.32s/it]Training MLP on cuda:   7%|▋         | 72/1000 [47:04<10:04:02, 39.05s/it]Training MLP on cuda:   7%|▋         | 73/1000 [47:42<10:01:33, 38.94s/it]Training MLP on cuda:   7%|▋         | 74/1000 [48:22<10:06:28, 39.30s/it]Training MLP on cuda:   8%|▊         | 75/1000 [49:01<10:01:43, 39.03s/it]Training MLP on cuda:   8%|▊         | 76/1000 [49:39<9:59:13, 38.91s/it] Training MLP on cuda:   8%|▊         | 77/1000 [50:19<10:03:31, 39.23s/it]Training MLP on cuda:   8%|▊         | 78/1000 [50:58<9:59:51, 39.04s/it] Training MLP on cuda:   8%|▊         | 79/1000 [51:37<9:58:02, 38.96s/it]Training MLP on cuda:   8%|▊         | 80/1000 [52:17<10:02:45, 39.31s/it]Training MLP on cuda:   8%|▊         | 81/1000 [52:56<9:58:47, 39.09s/it] Training MLP on cuda:   8%|▊         | 82/1000 [53:34<9:56:12, 38.97s/it]Training MLP on cuda:   8%|▊         | 83/1000 [54:14<10:00:39, 39.30s/it]Training MLP on cuda:   8%|▊         | 84/1000 [54:53<9:56:56, 39.10s/it] Training MLP on cuda:   8%|▊         | 85/1000 [55:32<9:54:14, 38.97s/it]Training MLP on cuda:   9%|▊         | 86/1000 [56:12<9:59:01, 39.32s/it]Training MLP on cuda:   9%|▊         | 87/1000 [56:50<9:54:52, 39.09s/it]Training MLP on cuda:   9%|▉         | 88/1000 [57:29<9:53:24, 39.04s/it]Training MLP on cuda:   9%|▉         | 89/1000 [58:09<9:57:43, 39.37s/it]Training MLP on cuda:   9%|▉         | 90/1000 [58:48<9:53:53, 39.16s/it]Training MLP on cuda:   9%|▉         | 91/1000 [59:27<9:51:12, 39.02s/it]Training MLP on cuda:   9%|▉         | 92/1000 [1:00:07<9:55:45, 39.37s/it]Training MLP on cuda:   9%|▉         | 93/1000 [1:00:46<9:52:24, 39.19s/it]Training MLP on cuda:   9%|▉         | 94/1000 [1:01:24<9:50:01, 39.07s/it]Training MLP on cuda:  10%|▉         | 95/1000 [1:02:05<9:54:51, 39.44s/it]Training MLP on cuda:  10%|▉         | 96/1000 [1:02:44<9:51:12, 39.24s/it]Training MLP on cuda:  10%|▉         | 97/1000 [1:03:22<9:49:12, 39.15s/it]Training MLP on cuda:  10%|▉         | 98/1000 [1:04:03<9:53:08, 39.45s/it]Training MLP on cuda:  10%|▉         | 99/1000 [1:04:41<9:49:29, 39.26s/it]Training MLP on cuda:  10%|█         | 100/1000 [1:05:20<9:46:44, 39.12s/it]Training MLP on cuda:  10%|█         | 101/1000 [1:06:00<9:51:03, 39.45s/it]Training MLP on cuda:  10%|█         | 102/1000 [1:06:39<9:47:05, 39.23s/it]Training MLP on cuda:  10%|█         | 103/1000 [1:07:18<9:44:35, 39.10s/it]Training MLP on cuda:  10%|█         | 104/1000 [1:07:58<9:48:24, 39.40s/it]Training MLP on cuda:  10%|█         | 105/1000 [1:08:37<9:44:19, 39.17s/it]Training MLP on cuda:  11%|█         | 106/1000 [1:09:16<9:42:15, 39.08s/it]Training MLP on cuda:  11%|█         | 107/1000 [1:09:56<9:46:44, 39.42s/it]Training MLP on cuda:  11%|█         | 108/1000 [1:10:35<9:43:04, 39.22s/it]Training MLP on cuda:  11%|█         | 109/1000 [1:11:13<9:40:08, 39.07s/it]Training MLP on cuda:  11%|█         | 110/1000 [1:11:53<9:44:07, 39.38s/it]Training MLP on cuda:  11%|█         | 111/1000 [1:12:32<9:40:48, 39.20s/it]Training MLP on cuda:  11%|█         | 112/1000 [1:13:11<9:38:18, 39.08s/it]Training MLP on cuda:  11%|█▏        | 113/1000 [1:13:51<9:41:45, 39.35s/it]Training MLP on cuda:  11%|█▏        | 114/1000 [1:14:29<9:37:03, 39.08s/it]Training MLP on cuda:  12%|█▏        | 115/1000 [1:15:08<9:34:30, 38.95s/it]Training MLP on cuda:  12%|█▏        | 116/1000 [1:15:48<9:38:08, 39.24s/it]Training MLP on cuda:  12%|█▏        | 117/1000 [1:16:26<9:34:10, 39.01s/it]Training MLP on cuda:  12%|█▏        | 118/1000 [1:17:05<9:31:32, 38.88s/it]Training MLP on cuda:  12%|█▏        | 119/1000 [1:17:45<9:36:02, 39.23s/it]Training MLP on cuda:  12%|█▏        | 120/1000 [1:18:24<9:32:11, 39.01s/it]Training MLP on cuda:  12%|█▏        | 121/1000 [1:19:02<9:29:20, 38.86s/it]Training MLP on cuda:  12%|█▏        | 122/1000 [1:19:42<9:33:47, 39.21s/it]Training MLP on cuda:  12%|█▏        | 123/1000 [1:20:21<9:30:39, 39.04s/it]Training MLP on cuda:  12%|█▏        | 124/1000 [1:20:59<9:28:35, 38.94s/it]Training MLP on cuda:  12%|█▎        | 125/1000 [1:21:39<9:32:27, 39.25s/it]Training MLP on cuda:  13%|█▎        | 126/1000 [1:22:18<9:28:44, 39.04s/it]Training MLP on cuda:  13%|█▎        | 127/1000 [1:22:57<9:26:03, 38.90s/it]Training MLP on cuda:  13%|█▎        | 128/1000 [1:23:37<9:30:03, 39.22s/it]Training MLP on cuda:  13%|█▎        | 129/1000 [1:24:15<9:26:08, 39.00s/it]Training MLP on cuda:  13%|█▎        | 130/1000 [1:24:54<9:23:31, 38.86s/it]Training MLP on cuda:  13%|█▎        | 131/1000 [1:25:34<9:27:50, 39.21s/it]Training MLP on cuda:  13%|█▎        | 132/1000 [1:26:12<9:23:50, 38.98s/it]Training MLP on cuda:  13%|█▎        | 133/1000 [1:26:51<9:22:08, 38.90s/it]Training MLP on cuda:  13%|█▎        | 134/1000 [1:27:31<9:26:01, 39.22s/it]Training MLP on cuda:  14%|█▎        | 135/1000 [1:28:09<9:22:38, 39.03s/it]Training MLP on cuda:  14%|█▎        | 136/1000 [1:28:48<9:19:55, 38.88s/it]Training MLP on cuda:  14%|█▎        | 137/1000 [1:29:28<9:24:26, 39.24s/it]Training MLP on cuda:  14%|█▍        | 138/1000 [1:30:07<9:21:21, 39.07s/it]Training MLP on cuda:  14%|█▍        | 139/1000 [1:30:45<9:19:58, 39.02s/it]Training MLP on cuda:  14%|█▍        | 140/1000 [1:31:26<9:23:55, 39.34s/it]Training MLP on cuda:  14%|█▍        | 141/1000 [1:32:04<9:20:28, 39.15s/it]Training MLP on cuda:  14%|█▍        | 142/1000 [1:32:43<9:18:10, 39.03s/it]Training MLP on cuda:  14%|█▍        | 143/1000 [1:33:23<9:21:11, 39.29s/it]Training MLP on cuda:  14%|█▍        | 144/1000 [1:34:01<9:17:16, 39.06s/it]Training MLP on cuda:  14%|█▍        | 145/1000 [1:34:40<9:14:40, 38.92s/it]Training MLP on cuda:  15%|█▍        | 146/1000 [1:35:20<9:18:19, 39.23s/it]Training MLP on cuda:  15%|█▍        | 147/1000 [1:35:58<9:14:19, 38.99s/it]Training MLP on cuda:  15%|█▍        | 148/1000 [1:36:37<9:12:06, 38.88s/it]Training MLP on cuda:  15%|█▍        | 149/1000 [1:37:17<9:16:09, 39.21s/it]Training MLP on cuda:  15%|█▌        | 150/1000 [1:37:55<9:12:04, 38.97s/it]Training MLP on cuda:  15%|█▌        | 151/1000 [1:38:34<9:10:22, 38.90s/it]Training MLP on cuda:  15%|█▌        | 152/1000 [1:39:14<9:14:21, 39.22s/it]Training MLP on cuda:  15%|█▌        | 153/1000 [1:39:53<9:10:30, 39.00s/it]Training MLP on cuda:  15%|█▌        | 154/1000 [1:40:31<9:07:55, 38.86s/it]Training MLP on cuda:  16%|█▌        | 155/1000 [1:41:11<9:11:52, 39.19s/it]Training MLP on cuda:  16%|█▌        | 156/1000 [1:41:50<9:08:17, 38.98s/it]Training MLP on cuda:  16%|█▌        | 157/1000 [1:42:28<9:05:43, 38.84s/it]Training MLP on cuda:  16%|█▌        | 158/1000 [1:43:08<9:09:57, 39.19s/it]Training MLP on cuda:  16%|█▌        | 159/1000 [1:43:47<9:06:12, 38.97s/it]Training MLP on cuda:  16%|█▌        | 160/1000 [1:44:25<9:04:25, 38.89s/it]Training MLP on cuda:  16%|█▌        | 161/1000 [1:45:05<9:08:46, 39.24s/it]Training MLP on cuda:  16%|█▌        | 162/1000 [1:45:44<9:05:06, 39.03s/it]Training MLP on cuda:  16%|█▋        | 163/1000 [1:46:23<9:03:28, 38.96s/it]Training MLP on cuda:  16%|█▋        | 164/1000 [1:47:03<9:06:48, 39.24s/it]Training MLP on cuda:  16%|█▋        | 165/1000 [1:47:41<9:02:57, 39.01s/it]Training MLP on cuda:  17%|█▋        | 166/1000 [1:48:20<9:00:29, 38.88s/it]Training MLP on cuda:  17%|█▋        | 167/1000 [1:49:00<9:04:14, 39.20s/it]Training MLP on cuda:  17%|█▋        | 168/1000 [1:49:38<9:00:40, 38.99s/it]Training MLP on cuda:  17%|█▋        | 169/1000 [1:50:17<8:58:31, 38.88s/it]Training MLP on cuda:  17%|█▋        | 170/1000 [1:50:57<9:02:26, 39.21s/it]Training MLP on cuda:  17%|█▋        | 171/1000 [1:51:35<8:58:31, 38.98s/it]Training MLP on cuda:  17%|█▋        | 172/1000 [1:52:14<8:56:35, 38.88s/it]Training MLP on cuda:  17%|█▋        | 173/1000 [1:52:54<9:00:16, 39.20s/it]Training MLP on cuda:  17%|█▋        | 174/1000 [1:53:32<8:57:06, 39.01s/it]Training MLP on cuda:  18%|█▊        | 175/1000 [1:54:11<8:54:41, 38.89s/it]Training MLP on cuda:  18%|█▊        | 176/1000 [1:54:51<8:58:50, 39.24s/it]Training MLP on cuda:  18%|█▊        | 177/1000 [1:55:29<8:55:08, 39.01s/it]Training MLP on cuda:  18%|█▊        | 178/1000 [1:56:08<8:52:38, 38.88s/it]Training MLP on cuda:  18%|█▊        | 179/1000 [1:56:48<8:56:15, 39.19s/it]Training MLP on cuda:  18%|█▊        | 180/1000 [1:57:26<8:52:56, 39.00s/it]Training MLP on cuda:  18%|█▊        | 181/1000 [1:58:05<8:51:14, 38.92s/it]Training MLP on cuda:  18%|█▊        | 182/1000 [1:58:45<8:55:03, 39.25s/it]Training MLP on cuda:  18%|█▊        | 183/1000 [1:59:24<8:51:02, 39.00s/it]Training MLP on cuda:  18%|█▊        | 184/1000 [2:00:02<8:48:52, 38.89s/it]Training MLP on cuda:  18%|█▊        | 185/1000 [2:00:42<8:52:45, 39.22s/it]Training MLP on cuda:  19%|█▊        | 186/1000 [2:01:21<8:48:57, 38.99s/it]Training MLP on cuda:  19%|█▊        | 187/1000 [2:01:59<8:46:30, 38.86s/it]Training MLP on cuda:  19%|█▉        | 188/1000 [2:02:39<8:51:13, 39.25s/it]Training MLP on cuda:  19%|█▉        | 189/1000 [2:03:18<8:48:05, 39.07s/it]Training MLP on cuda:  19%|█▉        | 190/1000 [2:03:57<8:45:54, 38.96s/it]Training MLP on cuda:  19%|█▉        | 191/1000 [2:04:37<8:49:25, 39.26s/it]Training MLP on cuda:  19%|█▉        | 192/1000 [2:05:15<8:44:56, 38.98s/it]Training MLP on cuda:  19%|█▉        | 193/1000 [2:05:54<8:42:40, 38.86s/it]Training MLP on cuda:  19%|█▉        | 194/1000 [2:06:34<8:46:09, 39.17s/it]Training MLP on cuda:  20%|█▉        | 195/1000 [2:07:12<8:42:47, 38.97s/it]Training MLP on cuda:  20%|█▉        | 196/1000 [2:07:51<8:40:56, 38.88s/it]Training MLP on cuda:  20%|█▉        | 197/1000 [2:08:31<8:44:28, 39.19s/it]Training MLP on cuda:  20%|█▉        | 198/1000 [2:09:09<8:40:59, 38.98s/it]Training MLP on cuda:  20%|█▉        | 199/1000 [2:09:48<8:39:01, 38.88s/it]Training MLP on cuda:  20%|██        | 200/1000 [2:10:28<8:42:37, 39.20s/it]Training MLP on cuda:  20%|██        | 201/1000 [2:11:06<8:38:43, 38.95s/it]Training MLP on cuda:  20%|██        | 202/1000 [2:11:45<8:36:42, 38.85s/it]Training MLP on cuda:  20%|██        | 203/1000 [2:12:25<8:40:26, 39.18s/it]Training MLP on cuda:  20%|██        | 204/1000 [2:13:03<8:36:47, 38.95s/it]Training MLP on cuda:  20%|██        | 205/1000 [2:13:42<8:34:49, 38.85s/it]Training MLP on cuda:  21%|██        | 206/1000 [2:14:22<8:38:27, 39.18s/it]Training MLP on cuda:  21%|██        | 207/1000 [2:15:00<8:34:41, 38.94s/it]Training MLP on cuda:  21%|██        | 208/1000 [2:15:39<8:32:55, 38.86s/it]Training MLP on cuda:  21%|██        | 209/1000 [2:16:19<8:36:47, 39.20s/it]Training MLP on cuda:  21%|██        | 210/1000 [2:16:57<8:33:13, 38.98s/it]Training MLP on cuda:  21%|██        | 211/1000 [2:17:36<8:30:48, 38.84s/it]Training MLP on cuda:  21%|██        | 212/1000 [2:18:16<8:34:26, 39.17s/it]Training MLP on cuda:  21%|██▏       | 213/1000 [2:18:54<8:31:00, 38.96s/it]Training MLP on cuda:  21%|██▏       | 214/1000 [2:19:32<8:28:16, 38.80s/it]Training MLP on cuda:  22%|██▏       | 215/1000 [2:20:12<8:32:08, 39.14s/it]Training MLP on cuda:  22%|██▏       | 216/1000 [2:20:51<8:28:46, 38.94s/it]Training MLP on cuda:  22%|██▏       | 217/1000 [2:21:29<8:26:17, 38.80s/it]Training MLP on cuda:  22%|██▏       | 218/1000 [2:22:09<8:29:59, 39.13s/it]Training MLP on cuda:  22%|██▏       | 219/1000 [2:22:48<8:26:20, 38.90s/it]Training MLP on cuda:  22%|██▏       | 220/1000 [2:23:26<8:24:11, 38.78s/it]Training MLP on cuda:  22%|██▏       | 221/1000 [2:24:06<8:27:46, 39.11s/it]Training MLP on cuda:  22%|██▏       | 222/1000 [2:24:45<8:25:13, 38.96s/it]Training MLP on cuda:  22%|██▏       | 223/1000 [2:25:23<8:23:46, 38.90s/it]Training MLP on cuda:  22%|██▏       | 224/1000 [2:26:03<8:27:44, 39.26s/it]Training MLP on cuda:  22%|██▎       | 225/1000 [2:26:42<8:23:25, 38.97s/it]Training MLP on cuda:  23%|██▎       | 226/1000 [2:27:20<8:20:42, 38.81s/it]Training MLP on cuda:  23%|██▎       | 227/1000 [2:28:00<8:24:24, 39.15s/it]Training MLP on cuda:  23%|██▎       | 228/1000 [2:28:39<8:20:47, 38.92s/it]Training MLP on cuda:  23%|██▎       | 229/1000 [2:29:17<8:18:48, 38.82s/it]Training MLP on cuda:  23%|██▎       | 230/1000 [2:29:57<8:22:16, 39.14s/it]Training MLP on cuda:  23%|██▎       | 231/1000 [2:30:35<8:18:28, 38.89s/it]Training MLP on cuda:  23%|██▎       | 232/1000 [2:31:14<8:16:22, 38.78s/it]Training MLP on cuda:  23%|██▎       | 233/1000 [2:31:54<8:20:26, 39.15s/it]Training MLP on cuda:  23%|██▎       | 234/1000 [2:32:32<8:16:35, 38.90s/it]Training MLP on cuda:  24%|██▎       | 235/1000 [2:33:11<8:15:01, 38.83s/it]Training MLP on cuda:  24%|██▎       | 236/1000 [2:33:51<8:18:22, 39.14s/it]Training MLP on cuda:  24%|██▎       | 237/1000 [2:34:29<8:14:59, 38.92s/it]Training MLP on cuda:  24%|██▍       | 238/1000 [2:35:08<8:12:44, 38.80s/it]Training MLP on cuda:  24%|██▍       | 239/1000 [2:35:48<8:16:30, 39.15s/it]Training MLP on cuda:  24%|██▍       | 240/1000 [2:36:26<8:13:02, 38.92s/it]Training MLP on cuda:  24%|██▍       | 241/1000 [2:37:05<8:11:03, 38.82s/it]Training MLP on cuda:  24%|██▍       | 242/1000 [2:37:45<8:14:57, 39.18s/it]Training MLP on cuda:  24%|██▍       | 243/1000 [2:38:23<8:11:13, 38.93s/it]Training MLP on cuda:  24%|██▍       | 244/1000 [2:39:02<8:09:15, 38.83s/it]Training MLP on cuda:  24%|██▍       | 245/1000 [2:39:41<8:12:39, 39.15s/it]Training MLP on cuda:  25%|██▍       | 246/1000 [2:40:20<8:09:24, 38.95s/it]Training MLP on cuda:  25%|██▍       | 247/1000 [2:40:59<8:07:35, 38.85s/it]Training MLP on cuda:  25%|██▍       | 248/1000 [2:41:39<8:11:35, 39.22s/it]Training MLP on cuda:  25%|██▍       | 249/1000 [2:42:17<8:08:32, 39.03s/it]Training MLP on cuda:  25%|██▌       | 250/1000 [2:42:56<8:07:02, 38.96s/it]Training MLP on cuda:  25%|██▌       | 251/1000 [2:43:36<8:10:31, 39.29s/it]Training MLP on cuda:  25%|██▌       | 252/1000 [2:44:15<8:07:30, 39.11s/it]Training MLP on cuda:  25%|██▌       | 253/1000 [2:44:53<8:05:28, 38.99s/it]Training MLP on cuda:  25%|██▌       | 254/1000 [2:45:34<8:09:11, 39.35s/it]Training MLP on cuda:  26%|██▌       | 255/1000 [2:46:12<8:05:25, 39.09s/it]Training MLP on cuda:  26%|██▌       | 256/1000 [2:46:51<8:03:17, 38.98s/it]Training MLP on cuda:  26%|██▌       | 257/1000 [2:47:31<8:06:40, 39.30s/it]Training MLP on cuda:  26%|██▌       | 258/1000 [2:48:09<8:03:27, 39.09s/it]Training MLP on cuda:  26%|██▌       | 259/1000 [2:48:48<8:01:22, 38.98s/it]Training MLP on cuda:  26%|██▌       | 260/1000 [2:49:28<8:04:48, 39.31s/it]Training MLP on cuda:  26%|██▌       | 261/1000 [2:50:07<8:01:28, 39.09s/it]Training MLP on cuda:  26%|██▌       | 262/1000 [2:50:46<7:59:33, 38.99s/it]Training MLP on cuda:  26%|██▋       | 263/1000 [2:51:26<8:02:42, 39.30s/it]Training MLP on cuda:  26%|██▋       | 264/1000 [2:52:04<7:59:31, 39.09s/it]Training MLP on cuda:  26%|██▋       | 265/1000 [2:52:43<7:57:17, 38.96s/it]Training MLP on cuda:  27%|██▋       | 266/1000 [2:53:23<8:00:26, 39.27s/it]Training MLP on cuda:  27%|██▋       | 267/1000 [2:54:01<7:57:06, 39.05s/it]Training MLP on cuda:  27%|██▋       | 268/1000 [2:54:40<7:55:07, 38.95s/it]Training MLP on cuda:  27%|██▋       | 269/1000 [2:55:20<7:58:18, 39.26s/it]Training MLP on cuda:  27%|██▋       | 270/1000 [2:55:59<7:55:16, 39.06s/it]Training MLP on cuda:  27%|██▋       | 271/1000 [2:56:37<7:53:17, 38.95s/it]Training MLP on cuda:  27%|██▋       | 272/1000 [2:57:18<7:56:46, 39.29s/it]Training MLP on cuda:  27%|██▋       | 273/1000 [2:57:56<7:53:27, 39.07s/it]Training MLP on cuda:  27%|██▋       | 274/1000 [2:58:35<7:51:34, 38.97s/it]Training MLP on cuda:  28%|██▊       | 275/1000 [2:59:15<7:54:51, 39.30s/it]Training MLP on cuda:  28%|██▊       | 276/1000 [2:59:53<7:51:07, 39.04s/it]Training MLP on cuda:  28%|██▊       | 277/1000 [3:00:32<7:49:01, 38.92s/it]Training MLP on cuda:  28%|██▊       | 278/1000 [3:01:12<7:52:24, 39.26s/it]Training MLP on cuda:  28%|██▊       | 279/1000 [3:01:51<7:49:28, 39.07s/it]Training MLP on cuda:  28%|██▊       | 280/1000 [3:02:29<7:47:25, 38.95s/it]Training MLP on cuda:  28%|██▊       | 281/1000 [3:03:09<7:50:35, 39.27s/it]Training MLP on cuda:  28%|██▊       | 282/1000 [3:03:48<7:46:57, 39.02s/it]Training MLP on cuda:  28%|██▊       | 283/1000 [3:04:26<7:44:07, 38.84s/it]Training MLP on cuda:  28%|██▊       | 284/1000 [3:05:06<7:47:05, 39.14s/it]Training MLP on cuda:  28%|██▊       | 285/1000 [3:05:44<7:44:00, 38.94s/it]Training MLP on cuda:  29%|██▊       | 286/1000 [3:06:23<7:41:40, 38.80s/it]Training MLP on cuda:  29%|██▊       | 287/1000 [3:07:03<7:45:04, 39.14s/it]Training MLP on cuda:  29%|██▉       | 288/1000 [3:07:41<7:41:49, 38.92s/it]Training MLP on cuda:  29%|██▉       | 289/1000 [3:08:20<7:39:35, 38.78s/it]Training MLP on cuda:  29%|██▉       | 290/1000 [3:09:00<7:42:52, 39.12s/it]Training MLP on cuda:  29%|██▉       | 291/1000 [3:09:38<7:39:32, 38.89s/it]Training MLP on cuda:  29%|██▉       | 292/1000 [3:10:17<7:37:46, 38.79s/it]Training MLP on cuda:  29%|██▉       | 293/1000 [3:10:56<7:40:50, 39.11s/it]Training MLP on cuda:  29%|██▉       | 294/1000 [3:11:35<7:38:15, 38.95s/it]Training MLP on cuda:  30%|██▉       | 295/1000 [3:12:14<7:36:08, 38.82s/it]Training MLP on cuda:  30%|██▉       | 296/1000 [3:12:53<7:39:18, 39.15s/it]Training MLP on cuda:  30%|██▉       | 297/1000 [3:13:32<7:35:30, 38.88s/it]Training MLP on cuda:  30%|██▉       | 298/1000 [3:14:10<7:33:52, 38.79s/it]Training MLP on cuda:  30%|██▉       | 299/1000 [3:14:50<7:37:22, 39.15s/it]Training MLP on cuda:  30%|███       | 300/1000 [3:15:29<7:33:51, 38.90s/it]Training MLP on cuda:  30%|███       | 301/1000 [3:16:07<7:32:14, 38.82s/it]Training MLP on cuda:  30%|███       | 302/1000 [3:16:47<7:35:36, 39.16s/it]Training MLP on cuda:  30%|███       | 303/1000 [3:17:26<7:32:14, 38.93s/it]Training MLP on cuda:  30%|███       | 304/1000 [3:18:04<7:30:07, 38.80s/it]Training MLP on cuda:  30%|███       | 305/1000 [3:18:44<7:32:53, 39.10s/it]Training MLP on cuda:  31%|███       | 306/1000 [3:19:22<7:30:06, 38.91s/it]Training MLP on cuda:  31%|███       | 307/1000 [3:20:01<7:27:59, 38.79s/it]Training MLP on cuda:  31%|███       | 308/1000 [3:20:41<7:30:57, 39.10s/it]Training MLP on cuda:  31%|███       | 309/1000 [3:21:19<7:27:59, 38.90s/it]Training MLP on cuda:  31%|███       | 310/1000 [3:21:58<7:26:14, 38.80s/it]Training MLP on cuda:  31%|███       | 311/1000 [3:22:38<7:29:43, 39.16s/it]Training MLP on cuda:  31%|███       | 312/1000 [3:23:16<7:26:25, 38.93s/it]Training MLP on cuda:  31%|███▏      | 313/1000 [3:23:55<7:24:25, 38.81s/it]Training MLP on cuda:  31%|███▏      | 314/1000 [3:24:35<7:27:38, 39.15s/it]Training MLP on cuda:  32%|███▏      | 315/1000 [3:25:13<7:24:29, 38.93s/it]Training MLP on cuda:  32%|███▏      | 316/1000 [3:25:52<7:22:52, 38.85s/it]Training MLP on cuda:  32%|███▏      | 317/1000 [3:26:32<7:25:48, 39.16s/it]Training MLP on cuda:  32%|███▏      | 318/1000 [3:27:10<7:22:06, 38.90s/it]Training MLP on cuda:  32%|███▏      | 319/1000 [3:27:48<7:20:20, 38.80s/it]Training MLP on cuda:  32%|███▏      | 320/1000 [3:28:28<7:23:25, 39.13s/it]Training MLP on cuda:  32%|███▏      | 321/1000 [3:29:07<7:20:34, 38.93s/it]Training MLP on cuda:  32%|███▏      | 322/1000 [3:29:45<7:18:43, 38.83s/it]Training MLP on cuda:  32%|███▏      | 323/1000 [3:30:25<7:21:55, 39.17s/it]Training MLP on cuda:  32%|███▏      | 324/1000 [3:31:04<7:18:23, 38.91s/it]Training MLP on cuda:  32%|███▎      | 325/1000 [3:31:42<7:16:08, 38.77s/it]Training MLP on cuda:  33%|███▎      | 326/1000 [3:32:22<7:19:41, 39.14s/it]Training MLP on cuda:  33%|███▎      | 327/1000 [3:33:00<7:16:12, 38.89s/it]Training MLP on cuda:  33%|███▎      | 328/1000 [3:33:39<7:14:19, 38.78s/it]Training MLP on cuda:  33%|███▎      | 329/1000 [3:34:19<7:17:37, 39.13s/it]Training MLP on cuda:  33%|███▎      | 330/1000 [3:34:57<7:14:12, 38.88s/it]Training MLP on cuda:  33%|███▎      | 331/1000 [3:35:36<7:12:10, 38.76s/it]Training MLP on cuda:  33%|███▎      | 332/1000 [3:36:16<7:15:35, 39.12s/it]Training MLP on cuda:  33%|███▎      | 333/1000 [3:36:54<7:12:18, 38.89s/it]Training MLP on cuda:  33%|███▎      | 334/1000 [3:37:32<7:10:31, 38.79s/it]Training MLP on cuda:  34%|███▎      | 335/1000 [3:38:12<7:13:35, 39.12s/it]Training MLP on cuda:  34%|███▎      | 336/1000 [3:38:51<7:11:00, 38.95s/it]Training MLP on cuda:  34%|███▎      | 337/1000 [3:39:29<7:08:57, 38.82s/it]Training MLP on cuda:  34%|███▍      | 338/1000 [3:40:09<7:11:51, 39.14s/it]Training MLP on cuda:  34%|███▍      | 339/1000 [3:40:48<7:08:41, 38.91s/it]Training MLP on cuda:  34%|███▍      | 340/1000 [3:41:26<7:06:55, 38.81s/it]Training MLP on cuda:  34%|███▍      | 341/1000 [3:42:06<7:10:00, 39.15s/it]Training MLP on cuda:  34%|███▍      | 342/1000 [3:42:45<7:06:47, 38.92s/it]Training MLP on cuda:  34%|███▍      | 343/1000 [3:43:23<7:04:45, 38.79s/it]Training MLP on cuda:  34%|███▍      | 344/1000 [3:44:03<7:07:37, 39.11s/it]Training MLP on cuda:  34%|███▍      | 345/1000 [3:44:41<7:04:29, 38.88s/it]Training MLP on cuda:  35%|███▍      | 346/1000 [3:45:20<7:02:36, 38.77s/it]Training MLP on cuda:  35%|███▍      | 347/1000 [3:46:00<7:05:51, 39.13s/it]Training MLP on cuda:  35%|███▍      | 348/1000 [3:46:38<7:02:37, 38.89s/it]Training MLP on cuda:  35%|███▍      | 349/1000 [3:47:17<7:00:30, 38.76s/it]Training MLP on cuda:  35%|███▌      | 350/1000 [3:47:56<7:03:44, 39.11s/it]Training MLP on cuda:  35%|███▌      | 351/1000 [3:48:35<7:00:43, 38.90s/it]Training MLP on cuda:  35%|███▌      | 352/1000 [3:49:14<6:59:25, 38.84s/it]Training MLP on cuda:  35%|███▌      | 353/1000 [3:49:53<7:02:05, 39.14s/it]Training MLP on cuda:  35%|███▌      | 354/1000 [3:50:32<6:58:55, 38.91s/it]Training MLP on cuda:  36%|███▌      | 355/1000 [3:51:10<6:57:13, 38.81s/it]Training MLP on cuda:  36%|███▌      | 356/1000 [3:51:50<7:00:13, 39.15s/it]Training MLP on cuda:  36%|███▌      | 357/1000 [3:52:29<6:57:17, 38.94s/it]Training MLP on cuda:  36%|███▌      | 358/1000 [3:53:07<6:55:34, 38.84s/it]Training MLP on cuda:  36%|███▌      | 359/1000 [3:53:47<6:58:23, 39.16s/it]Training MLP on cuda:  36%|███▌      | 360/1000 [3:54:26<6:55:09, 38.92s/it]Training MLP on cuda:  36%|███▌      | 361/1000 [3:55:04<6:52:59, 38.78s/it]Training MLP on cuda:  36%|███▌      | 362/1000 [3:55:44<6:56:04, 39.13s/it]Training MLP on cuda:  36%|███▋      | 363/1000 [3:56:22<6:53:04, 38.91s/it]Training MLP on cuda:  36%|███▋      | 364/1000 [3:57:01<6:51:52, 38.86s/it]Training MLP on cuda:  36%|███▋      | 365/1000 [3:57:41<6:55:13, 39.23s/it]Training MLP on cuda:  37%|███▋      | 366/1000 [3:58:20<6:52:28, 39.04s/it]Training MLP on cuda:  37%|███▋      | 367/1000 [3:58:59<6:50:35, 38.92s/it]Training MLP on cuda:  37%|███▋      | 368/1000 [3:59:39<6:53:34, 39.26s/it]Training MLP on cuda:  37%|███▋      | 369/1000 [4:00:17<6:50:32, 39.04s/it]Training MLP on cuda:  37%|███▋      | 370/1000 [4:00:56<6:48:49, 38.93s/it]Training MLP on cuda:  37%|███▋      | 371/1000 [4:01:36<6:51:40, 39.27s/it]Training MLP on cuda:  37%|███▋      | 372/1000 [4:02:14<6:48:43, 39.05s/it]Training MLP on cuda:  37%|███▋      | 373/1000 [4:02:53<6:46:42, 38.92s/it]Training MLP on cuda:  37%|███▋      | 374/1000 [4:03:33<6:49:42, 39.27s/it]Training MLP on cuda:  38%|███▊      | 375/1000 [4:04:12<6:46:45, 39.05s/it]Training MLP on cuda:  38%|███▊      | 376/1000 [4:04:50<6:45:02, 38.95s/it]Training MLP on cuda:  38%|███▊      | 377/1000 [4:05:30<6:47:50, 39.28s/it]Training MLP on cuda:  38%|███▊      | 378/1000 [4:06:09<6:44:48, 39.05s/it]Training MLP on cuda:  38%|███▊      | 379/1000 [4:06:48<6:42:56, 38.93s/it]Training MLP on cuda:  38%|███▊      | 380/1000 [4:07:28<6:46:00, 39.29s/it]Training MLP on cuda:  38%|███▊      | 381/1000 [4:08:06<6:42:47, 39.04s/it]Training MLP on cuda:  38%|███▊      | 382/1000 [4:08:45<6:40:54, 38.92s/it]Training MLP on cuda:  38%|███▊      | 383/1000 [4:09:25<6:43:50, 39.27s/it]Training MLP on cuda:  38%|███▊      | 384/1000 [4:10:03<6:41:07, 39.07s/it]Training MLP on cuda:  38%|███▊      | 385/1000 [4:10:42<6:39:31, 38.98s/it]Training MLP on cuda:  39%|███▊      | 386/1000 [4:11:22<6:41:41, 39.25s/it]Training MLP on cuda:  39%|███▊      | 387/1000 [4:12:01<6:39:03, 39.06s/it]Training MLP on cuda:  39%|███▉      | 388/1000 [4:12:39<6:37:19, 38.95s/it]Training MLP on cuda:  39%|███▉      | 389/1000 [4:13:19<6:40:02, 39.28s/it]Training MLP on cuda:  39%|███▉      | 390/1000 [4:13:58<6:36:56, 39.04s/it]Training MLP on cuda:  39%|███▉      | 391/1000 [4:14:37<6:35:17, 38.95s/it]Training MLP on cuda:  39%|███▉      | 392/1000 [4:15:17<6:37:47, 39.26s/it]Training MLP on cuda:  39%|███▉      | 393/1000 [4:15:55<6:34:14, 38.97s/it]Training MLP on cuda:  39%|███▉      | 394/1000 [4:16:33<6:32:03, 38.82s/it]Training MLP on cuda:  40%|███▉      | 395/1000 [4:17:13<6:34:35, 39.13s/it]Training MLP on cuda:  40%|███▉      | 396/1000 [4:17:52<6:31:23, 38.88s/it]Training MLP on cuda:  40%|███▉      | 397/1000 [4:18:30<6:29:29, 38.76s/it]Training MLP on cuda:  40%|███▉      | 398/1000 [4:19:10<6:32:15, 39.10s/it]Training MLP on cuda:  40%|███▉      | 399/1000 [4:19:48<6:29:30, 38.89s/it]Training MLP on cuda:  40%|████      | 400/1000 [4:20:27<6:27:48, 38.78s/it]Training MLP on cuda:  40%|████      | 401/1000 [4:21:07<6:30:05, 39.07s/it]Training MLP on cuda:  40%|████      | 402/1000 [4:21:45<6:27:24, 38.87s/it]Training MLP on cuda:  40%|████      | 403/1000 [4:22:24<6:25:45, 38.77s/it]Training MLP on cuda:  40%|████      | 404/1000 [4:23:03<6:27:52, 39.05s/it]Training MLP on cuda:  40%|████      | 405/1000 [4:23:42<6:25:13, 38.85s/it]Training MLP on cuda:  41%|████      | 406/1000 [4:24:20<6:23:16, 38.71s/it]Training MLP on cuda:  41%|████      | 407/1000 [4:25:00<6:25:51, 39.04s/it]Training MLP on cuda:  41%|████      | 408/1000 [4:25:38<6:23:07, 38.83s/it]Training MLP on cuda:  41%|████      | 409/1000 [4:26:17<6:21:14, 38.70s/it]Training MLP on cuda:  41%|████      | 410/1000 [4:26:56<6:23:50, 39.03s/it]Training MLP on cuda:  41%|████      | 411/1000 [4:27:35<6:20:41, 38.78s/it]Training MLP on cuda:  41%|████      | 412/1000 [4:28:13<6:19:16, 38.70s/it]Training MLP on cuda:  41%|████▏     | 413/1000 [4:28:53<6:22:16, 39.07s/it]Training MLP on cuda:  41%|████▏     | 414/1000 [4:29:31<6:19:42, 38.88s/it]Training MLP on cuda:  42%|████▏     | 415/1000 [4:30:10<6:17:52, 38.76s/it]Training MLP on cuda:  42%|████▏     | 416/1000 [4:30:50<6:20:36, 39.10s/it]Training MLP on cuda:  42%|████▏     | 417/1000 [4:31:28<6:17:31, 38.85s/it]Training MLP on cuda:  42%|████▏     | 418/1000 [4:32:07<6:15:38, 38.73s/it]Training MLP on cuda:  42%|████▏     | 419/1000 [4:32:46<6:18:06, 39.05s/it]Training MLP on cuda:  42%|████▏     | 420/1000 [4:33:25<6:15:31, 38.85s/it]Training MLP on cuda:  42%|████▏     | 421/1000 [4:34:03<6:14:00, 38.76s/it]Training MLP on cuda:  42%|████▏     | 422/1000 [4:34:43<6:16:26, 39.08s/it]Training MLP on cuda:  42%|████▏     | 423/1000 [4:35:21<6:13:32, 38.84s/it]Training MLP on cuda:  42%|████▏     | 424/1000 [4:36:00<6:12:04, 38.76s/it]Training MLP on cuda:  42%|████▎     | 425/1000 [4:36:40<6:14:48, 39.11s/it]Training MLP on cuda:  43%|████▎     | 426/1000 [4:37:18<6:12:19, 38.92s/it]Training MLP on cuda:  43%|████▎     | 427/1000 [4:37:57<6:10:28, 38.79s/it]Training MLP on cuda:  43%|████▎     | 428/1000 [4:38:37<6:12:55, 39.12s/it]Training MLP on cuda:  43%|████▎     | 429/1000 [4:39:15<6:10:25, 38.92s/it]Training MLP on cuda:  43%|████▎     | 430/1000 [4:39:54<6:08:14, 38.76s/it]Training MLP on cuda:  43%|████▎     | 431/1000 [4:40:34<6:10:57, 39.12s/it]Training MLP on cuda:  43%|████▎     | 432/1000 [4:41:12<6:08:14, 38.90s/it]Training MLP on cuda:  43%|████▎     | 433/1000 [4:41:50<6:06:26, 38.78s/it]Training MLP on cuda:  43%|████▎     | 434/1000 [4:42:30<6:08:24, 39.05s/it]Training MLP on cuda:  44%|████▎     | 435/1000 [4:43:09<6:06:00, 38.87s/it]Training MLP on cuda:  44%|████▎     | 436/1000 [4:43:47<6:04:37, 38.79s/it]Training MLP on cuda:  44%|████▎     | 437/1000 [4:44:27<6:07:16, 39.14s/it]Training MLP on cuda:  44%|████▍     | 438/1000 [4:45:06<6:04:46, 38.94s/it]Training MLP on cuda:  44%|████▍     | 439/1000 [4:45:44<6:03:20, 38.86s/it]Training MLP on cuda:  44%|████▍     | 440/1000 [4:46:24<6:05:40, 39.18s/it]Training MLP on cuda:  44%|████▍     | 441/1000 [4:47:03<6:02:50, 38.94s/it]Training MLP on cuda:  44%|████▍     | 441/1000 [4:47:41<6:04:40, 39.14s/it]
Computing expactation over sampled graphs:   0%|          | 0/16 [00:00<?, ?it/s]Computing expactation over sampled graphs:   6%|▋         | 1/16 [54:41<13:40:24, 3281.64s/it]Computing expactation over sampled graphs:  12%|█▎        | 2/16 [1:49:19<12:45:12, 3279.44s/it]Computing expactation over sampled graphs:  19%|█▉        | 3/16 [2:36:52<11:08:19, 3084.55s/it]Computing expactation over sampled graphs:  25%|██▌       | 4/16 [3:31:46<10:33:28, 3167.34s/it]Computing expactation over sampled graphs:  31%|███▏      | 5/16 [4:13:32<8:56:56, 2928.81s/it] Computing expactation over sampled graphs:  38%|███▊      | 6/16 [5:06:29<8:22:11, 3013.15s/it]Computing expactation over sampled graphs:  44%|████▍     | 7/16 [6:07:15<8:03:01, 3220.19s/it]Computing expactation over sampled graphs:  50%|█████     | 8/16 [6:56:59<6:59:19, 3144.93s/it]Computing expactation over sampled graphs:  56%|█████▋    | 9/16 [7:49:25<6:06:57, 3145.35s/it]Computing expactation over sampled graphs:  62%|██████▎   | 10/16 [8:39:36<5:10:23, 3103.93s/it]Computing expactation over sampled graphs:  69%|██████▉   | 11/16 [9:31:04<4:18:14, 3098.97s/it]Computing expactation over sampled graphs:  75%|███████▌  | 12/16 [10:25:02<3:29:25, 3141.32s/it]Computing expactation over sampled graphs:  81%|████████▏ | 13/16 [11:14:17<2:34:14, 3084.92s/it]Computing expactation over sampled graphs:  88%|████████▊ | 14/16 [12:12:14<1:46:46, 3203.33s/it]Computing expactation over sampled graphs:  94%|█████████▍| 15/16 [12:59:28<51:31, 3091.91s/it]  Computing expactation over sampled graphs: 100%|██████████| 16/16 [13:51:19<00:00, 3097.65s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [13:51:19<00:00, 3117.47s/it]
Computing expactation over sampled graphs:   0%|          | 0/16 [00:00<?, ?it/s]Computing expactation over sampled graphs:   6%|▋         | 1/16 [30:08<7:32:04, 1808.27s/it]Computing expactation over sampled graphs:  12%|█▎        | 2/16 [1:02:37<7:21:18, 1891.32s/it]Computing expactation over sampled graphs:  19%|█▉        | 3/16 [1:33:03<6:43:15, 1861.22s/it]Computing expactation over sampled graphs:  25%|██▌       | 4/16 [1:59:56<5:52:39, 1763.31s/it]Computing expactation over sampled graphs:  31%|███▏      | 5/16 [2:29:21<5:23:24, 1764.00s/it]Computing expactation over sampled graphs:  38%|███▊      | 6/16 [2:54:29<4:39:29, 1676.96s/it]Computing expactation over sampled graphs:  44%|████▍     | 7/16 [3:22:11<4:10:47, 1671.94s/it]Computing expactation over sampled graphs:  50%|█████     | 8/16 [3:50:59<3:45:20, 1690.03s/it]Computing expactation over sampled graphs:  56%|█████▋    | 9/16 [4:14:50<3:07:43, 1609.03s/it]Computing expactation over sampled graphs:  62%|██████▎   | 10/16 [4:35:17<2:29:05, 1490.93s/it]Computing expactation over sampled graphs:  69%|██████▉   | 11/16 [5:00:24<2:04:40, 1496.03s/it]Computing expactation over sampled graphs:  75%|███████▌  | 12/16 [5:25:09<1:39:30, 1492.57s/it]Computing expactation over sampled graphs:  81%|████████▏ | 13/16 [5:54:06<1:18:19, 1566.61s/it]Computing expactation over sampled graphs:  88%|████████▊ | 14/16 [6:20:14<52:14, 1567.11s/it]  Computing expactation over sampled graphs:  94%|█████████▍| 15/16 [6:43:51<25:21, 1521.63s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [7:05:32<00:00, 1455.47s/it]Computing expactation over sampled graphs: 100%|██████████| 16/16 [7:05:33<00:00, 1595.82s/it]
                                               train_acc         test_acc  \
github-GraphSAGE_MLP-attack-0hop         0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_MLP-attack-comb         0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_lira                    0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_rmia                    0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_lset                    0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_graph-lset-MIA          0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_lira-offline            0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_rmia-offline            0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_lset-offline            0.9603 (0.0000)  0.8377 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline  0.9603 (0.0000)  0.8377 (0.0000)   

                                                     AUC      TPR@0.01FPR  \
github-GraphSAGE_MLP-attack-0hop         0.4881 (0.0000)  0.0122 (0.0000)   
github-GraphSAGE_MLP-attack-comb         0.5041 (0.0000)  0.0058 (0.0000)   
github-GraphSAGE_lira                    0.5377 (0.0000)  0.0175 (0.0000)   
github-GraphSAGE_rmia                    0.5562 (0.0000)  0.0244 (0.0000)   
github-GraphSAGE_lset                    0.5562 (0.0000)  0.0244 (0.0000)   
github-GraphSAGE_graph-lset-MIA          0.5875 (0.0000)  0.0345 (0.0000)   
github-GraphSAGE_lira-offline            0.5424 (0.0000)  0.0103 (0.0000)   
github-GraphSAGE_rmia-offline            0.5544 (0.0000)  0.0281 (0.0000)   
github-GraphSAGE_lset-offline            0.5544 (0.0000)  0.0284 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline  0.5907 (0.0000)  0.0419 (0.0000)   

                                        threshold@0.01FPR     TPR@0.001FPR  \
github-GraphSAGE_MLP-attack-0hop          0.0707 (0.0000)  0.0021 (0.0000)   
github-GraphSAGE_MLP-attack-comb          0.1996 (0.0000)  0.0003 (0.0000)   
github-GraphSAGE_lira                     1.4503 (0.0000)  0.0029 (0.0000)   
github-GraphSAGE_rmia                     0.9356 (0.0000)  0.0050 (0.0000)   
github-GraphSAGE_lset                     0.6256 (0.0000)  0.0050 (0.0000)   
github-GraphSAGE_graph-lset-MIA           0.6000 (0.0000)  0.0056 (0.0000)   
github-GraphSAGE_lira-offline            -0.0011 (0.0000)  0.0008 (0.0000)   
github-GraphSAGE_rmia-offline             0.9406 (0.0000)  0.0056 (0.0000)   
github-GraphSAGE_lset-offline             0.6264 (0.0000)  0.0050 (0.0000)   
github-GraphSAGE_graph-lset-MIA-offline   0.6168 (0.0000)  0.0066 (0.0000)   

                                        threshold@0.001FPR  
github-GraphSAGE_MLP-attack-0hop           0.1145 (0.0000)  
github-GraphSAGE_MLP-attack-comb           0.2961 (0.0000)  
github-GraphSAGE_lira                      2.7491 (0.0000)  
github-GraphSAGE_rmia                      0.9766 (0.0000)  
github-GraphSAGE_lset                      0.7229 (0.0000)  
github-GraphSAGE_graph-lset-MIA            0.6895 (0.0000)  
github-GraphSAGE_lira-offline             -0.0000 (0.0000)  
github-GraphSAGE_rmia-offline              0.9800 (0.0000)  
github-GraphSAGE_lset-offline              0.7338 (0.0000)  
github-GraphSAGE_graph-lset-MIA-offline    0.7390 (0.0000)  
Done.
